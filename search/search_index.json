{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting Started","text":"<p>Required Installations:</p> <ul> <li>Node.js 18.x</li> <li>Golang 1.20</li> <li>Wire <pre><code>go install github.com/google/wire/cmd/wire@latest \n</code></pre></li> <li>Python 3.10</li> <li>Poetry <pre><code>pip install poetry==1.2.0b3\n</code></pre></li> <li>docker</li> <li>docker-compose</li> </ul>"},{"location":"#install-dependencies","title":"Install dependencies","text":"<pre><code>npm install\n</code></pre> <pre><code>poetry install\n</code></pre>"},{"location":"#terminal-virtual-environment","title":"Terminal virtual environment","text":"<pre><code>poetry shell\n</code></pre>"},{"location":"#environment-setup","title":"Environment Setup","text":"<ol> <li> <p>Create Configs and Schemas: Each service and source has it own config and schema you will need to create before run a service.</p> </li> <li> <p>Create a directory for the target source under the <code>.configs/</code> then create all the configs and schemas.</p> </li> </ol> <p>Config Example: - File Downloader</p> <pre><code>{\n  \"name\": \"ceaf-config\",\n  \"active\": true,\n  \"frequency\": \"daily\",\n  \"service\": \"file-downloader\",\n  \"source\": \"ceaf\",\n  \"context\": \"br\",\n  \"depends_on\": [{\n    \"service\": \"source-watcher\",\n    \"source\": \"ceaf\"\n  }],\n  \"service_parameters\": {\n    \"job_handler\": \"default\"\n  },\n  \"job_parameters\": {\n    \"url\": \"https://portaldatransparencia.gov.br/download-de-dados/ceaf/{}\"\n  }\n}\n</code></pre> <p>Schema Example - File Downloader (Schema Type: Input) <pre><code>{\n    \"schema_type\": \"service-input\",\n    \"service\": \"file-downloader\",\n    \"source\": \"ceaf\",\n    \"context\": \"br\",\n    \"json_schema\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"documentUri\": {\n                \"type\": \"string\"\n            },\n            \"partition\": {\n                \"type\": \"string\"\n            }\n        },\n        \"required\": [\n            \"documentUri\",\n            \"partition\"\n        ]\n    }\n}\n</code></pre></p> <p>You can check all configs and schemas example for one source here</p> <ol> <li> <p>Make sure all the <code>.env.&lt;ENVIRONMEMNT&gt;</code> files for all the service are created. (each project has it own example)</p> </li> <li> <p>Create Buckets and Post the configs and schemas to each API:</p> </li> <li>Some buckets are needed for each responsibility, service and also source</li> <li>The configs created in the directory under the <code>.configs/</code> needed to be saved in the mongoDB the you need to post the configs and the schemas in each API.</li> </ol> <p>To Create and to make the Post Request run the commmand:</p> <pre><code>make setup-env context=&lt;CONTEXT&gt; source=&lt;SOOURCE&gt;\n</code></pre> <p>Thats it... The source has been added to the environment then all the services can start:</p> <p><pre><code>make run\n</code></pre>  - if get an error in the compose, run:</p> <p><pre><code>make reload\n</code></pre> This comand will try to make the compose up again.</p>"},{"location":"#diagram","title":"Diagram","text":"<p>This repo was structured with a monorepo approach and optimize with NX framework.</p> <p>Feel free to take a look in the nx cloud ui of the workspace</p> <p></p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Required Installations:</p> <ul> <li>Node.js 18.x</li> <li>Golang 1.20</li> <li>Wire <pre><code>go install github.com/google/wire/cmd/wire@latest \n</code></pre></li> <li>Python 3.10</li> <li>Poetry <pre><code>pip install poetry==1.2.0b3\n</code></pre></li> <li>docker</li> <li>docker-compose</li> </ul>"},{"location":"getting-started/#install-dependencies","title":"Install dependencies","text":"<pre><code>npm install\n</code></pre> <pre><code>poetry install\n</code></pre>"},{"location":"getting-started/#terminal-virtual-environment","title":"Terminal virtual environment","text":"<pre><code>poetry shell\n</code></pre>"},{"location":"getting-started/#environment-setup","title":"Environment Setup","text":"<ol> <li> <p>Create Configs and Schemas: Each service and source has it own config and schema you will need to create before run a service.</p> </li> <li> <p>Create a directory for the target source under the <code>.configs/</code> then create all the configs and schemas.</p> </li> </ol> <p>Config Example: - File Downloader</p> <pre><code>{\n  \"name\": \"ceaf-config\",\n  \"active\": true,\n  \"frequency\": \"daily\",\n  \"service\": \"file-downloader\",\n  \"source\": \"ceaf\",\n  \"context\": \"br\",\n  \"depends_on\": [{\n    \"service\": \"source-watcher\",\n    \"source\": \"ceaf\"\n  }],\n  \"service_parameters\": {\n    \"job_handler\": \"default\"\n  },\n  \"job_parameters\": {\n    \"url\": \"https://portaldatransparencia.gov.br/download-de-dados/ceaf/{}\"\n  }\n}\n</code></pre> <p>Schema Example - File Downloader (Schema Type: Input) <pre><code>{\n    \"schema_type\": \"service-input\",\n    \"service\": \"file-downloader\",\n    \"source\": \"ceaf\",\n    \"context\": \"br\",\n    \"json_schema\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"documentUri\": {\n                \"type\": \"string\"\n            },\n            \"partition\": {\n                \"type\": \"string\"\n            }\n        },\n        \"required\": [\n            \"documentUri\",\n            \"partition\"\n        ]\n    }\n}\n</code></pre></p> <p>You can check all configs and schemas example for one source here</p> <ol> <li> <p>Make sure all the <code>.env.&lt;ENVIRONMEMNT&gt;</code> files for all the service are created. (each project has it own example)</p> </li> <li> <p>Create Buckets and Post the configs and schemas to each API:</p> </li> <li>Some buckets are needed for each responsibility, service and also source</li> <li>The configs created in the directory under the <code>.configs/</code> needed to be saved in the mongoDB the you need to post the configs and the schemas in each API.</li> </ol> <p>To Create and to make the Post Request run the commmand:</p> <pre><code>make setup-env context=&lt;CONTEXT&gt; source=&lt;SOOURCE&gt;\n</code></pre> <p>Thats it... The source has been added to the environment then all the services can start:</p> <p><pre><code>make run\n</code></pre>  - if get an error in the compose, run:</p> <p><pre><code>make reload\n</code></pre> This comand will try to make the compose up again.</p> <p>This repo was structured with a monorepo approach and optimize with NX framework.</p> <p>Feel free to take a look in the nx cloud ui of the workspace</p> <p></p>"},{"location":"summary/","title":"Summary","text":"<ul> <li>Architecture</li> <li>Applications</li> <li>Libraries</li> <li>Dependency Graph</li> </ul>"},{"location":"reference/apps/client-layer/streamlit-genai/","title":"streamlit-genai","text":""},{"location":"reference/apps/client-layer/streamlit-genai/#chat-with-your-knowledge-graph","title":"Chat with your Knowledge Graph","text":"<p>This application provides a simple interface for users to interact with a <code>knowledge graph</code> structured in Neo4J. The underlying technology leverages language models and vector embeddings to retrieve relevant information from semantic queries in the <code>Neo4J knowledge graph</code>.</p>"},{"location":"reference/apps/client-layer/streamlit-genai/#how-to-run-the-service","title":"How to Run the Service","text":"<p>To run your service, follow these steps:</p> <ol> <li> <p>Setup Configuration:</p> <ul> <li>Create a <code>.env.{ENVIRONMENT}</code> file based on the example provided in the <code>envs</code> folder.</li> </ul> </li> <li> <p>Build The Service:</p> </li> </ol> <pre><code>npx nx image client-layer-streamlit-genai --env=&lt;ENVIRONMENT&gt;\n</code></pre> <ol> <li>Run the Application:</li> </ol> <pre><code>docker-compose up -d\n</code></pre> <p>This will launch the application, and you can access it through your web browser.</p> <ul> <li>Endpoint: http://localhost:8503</li> </ul>"},{"location":"reference/apps/client-layer/streamlit-genai/#application-structure","title":"Application Structure","text":"<ul> <li><code>main.py</code>: Contains the Streamlit application code, user interface, and integration with language models and vector stores.</li> <li><code>chains.py</code>: Defines functions for loading embedding models and language models.</li> <li><code>streamlit_genai/utils.py</code>: Contains a utility class for logging information.</li> </ul>"},{"location":"reference/apps/client-layer/streamlit-genai/#embedding-models","title":"Embedding Models","text":"<p>The application supports two types of embedding models:</p> <ul> <li>Ollama: Leveraging the OllamaEmbeddings class with the \"llama2\" model.</li> <li>Sentence Transformer: Using the SentenceTransformerEmbeddings class with the \"all-MiniLM-L6-v2\" model.</li> </ul> <p>You can choose the desired embedding model by setting the <code>EMBEDDING_MODEL</code> environment variable.</p>"},{"location":"reference/apps/client-layer/streamlit-genai/#language-model","title":"Language Model","text":"<p>The application uses the ChatOllama language model, configurable by the <code>LLM</code> environment variable. Adjust parameters such as temperature, top_k, top_p, and num_ctx in the <code>load_llm</code> function.</p>"},{"location":"reference/apps/client-layer/streamlit-genai/#logging","title":"Logging","text":"<p>The application uses a simple logging mechanism provided by the <code>BaseLogger</code> class in <code>streamlit_genai/utils.py</code>. You can extend or replace this logger based on your requirements.</p> <p>Feel free to explore and customize the code to fit your specific use case. Enjoy chatting with your PDF file!</p>"},{"location":"reference/apps/client-layer/streamlit-genai/code_reference/streamlit_genai/chains/","title":"Chains","text":""},{"location":"reference/apps/client-layer/streamlit-genai/code_reference/streamlit_genai/chains/#apps.client-layer.streamlit-genai.streamlit_genai.chains.load_embedding_model","title":"<code>load_embedding_model(embedding_model_name, logger=BaseLogger(), config={})</code>","text":"<p>Load the embedding model based on the specified name.</p> <p>Parameters:</p> Name Type Description Default <code>embedding_model_name</code> <code>str</code> <p>The name of the embedding model.</p> required <code>logger</code> <code>BaseLogger</code> <p>The logger instance. Defaults to BaseLogger().</p> <code>BaseLogger()</code> <code>config</code> <code>dict</code> <p>Additional configuration for loading the model. Defaults to {}.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Tuple</code> <p>A tuple containing embeddings and dimension.</p> Source code in <code>apps/client-layer/streamlit-genai/streamlit_genai/chains.py</code> <pre><code>def load_embedding_model(embedding_model_name: str, logger=BaseLogger(), config={}):\n    \"\"\"\n    Load the embedding model based on the specified name.\n\n    Args:\n        embedding_model_name (str): The name of the embedding model.\n        logger (BaseLogger, optional): The logger instance. Defaults to BaseLogger().\n        config (dict, optional): Additional configuration for loading the model. Defaults to {}.\n\n    Returns:\n        Tuple: A tuple containing embeddings and dimension.\n    \"\"\"\n    if embedding_model_name == \"ollama\":\n        embeddings = OllamaEmbeddings(\n            base_url=config[\"ollama_base_url\"], model=\"llama2\"\n        )\n        dimension = 4096\n        logger.info(\"Embedding: Using Ollama\")\n    else:\n        embeddings = SentenceTransformerEmbeddings(\n            model_name=\"all-MiniLM-L6-v2\", cache_folder=\"/embedding_model\"\n        )\n        dimension = 384\n        logger.info(\"Embedding: Using SentenceTransformer\")\n    return embeddings, dimension\n</code></pre>"},{"location":"reference/apps/client-layer/streamlit-genai/code_reference/streamlit_genai/utils/","title":"Utils","text":""},{"location":"reference/apps/client-layer/streamlit-genai/code_reference/streamlit_genai/utils/#apps.client-layer.streamlit-genai.streamlit_genai.utils.BaseLogger","title":"<code>BaseLogger</code>","text":"<p>A simple base logger class.</p> <p>This class is used for logging information.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>Initializes the BaseLogger instance.</p> <p>Attributes:</p> Name Type Description <code>info</code> <code>callable</code> <p>A callable method for logging information.</p> Source code in <code>apps/client-layer/streamlit-genai/streamlit_genai/utils.py</code> <pre><code>class BaseLogger:\n    \"\"\"\n    A simple base logger class.\n\n    This class is used for logging information.\n\n    Methods:\n        __init__(self) -&gt; None:\n            Initializes the BaseLogger instance.\n\n    Attributes:\n        info (callable): A callable method for logging information.\n\n    \"\"\"\n    def __init__(self) -&gt; None:\n        self.info = print\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/","title":"source-watcher","text":"<p><code>source-watcher</code> is a Python-based service that performs the following tasks:</p> <ul> <li>Search for the source input to trigger a future job.</li> <li>Store the file downloaded in a bucket (process-input layer).</li> <li>Publishes the bucket location to a message queue for further consumption.</li> </ul>"},{"location":"reference/apps/process-input/source-watcher/#service-components","title":"Service Components","text":"<p>The service consists of multiple Python modules and classes, each serving a specific purpose. Here's an overview of these components:</p>"},{"location":"reference/apps/process-input/source-watcher/#main-module","title":"Main Module","text":"<ul> <li><code>main.py</code>: The entry point of the service.</li> <li>It initializes various configurations, including the service name and context environment.</li> <li>Creates consumers for specific configurations and starts processing data.</li> <li>Each config has it owns queue consumption.</li> </ul>"},{"location":"reference/apps/process-input/source-watcher/#consumer-module","title":"Consumer Module","text":"<ul> <li><code>source_watcher/consumer/consumer.py</code>: Contains the <code>EventConsumer</code> class responsible for consume an input message and trigger the callback.</li> <li>This class listens to a RabbitMQ queue, processes incoming data, and trigger the results to the controller.</li> </ul>"},{"location":"reference/apps/process-input/source-watcher/#controller-module","title":"Controller Module","text":"<ul> <li> <p><code>source_watcher/controller/controller.py</code>: This module contains the <code>EventController</code> class, which is responsible for handling the business logic related to event processing.</p> </li> <li> <p>The <code>EventController</code> class receives the processed data from the <code>EventConsumer</code>.</p> </li> <li>It checks if the controller should be active based on the configuration.</li> <li>If active, it parses and processes the data using the job handler.</li> <li>It triggers the job dispatcher to execute the job and collect the results.</li> <li>It publishes the results, including the storage URI, to a message queue for further consumption.</li> </ul> <p>The <code>EventController</code> class plays a crucial role in orchestrating the event-driven processing of data within the service.</p> <p>This class ensures that the service processes incoming data efficiently, initiates the appropriate job handler for the task, and communicates the results to the relevant channels.</p>"},{"location":"reference/apps/process-input/source-watcher/#job-handling-module","title":"Job Handling Module","text":"<ul> <li><code>source_watcher/jobs/job_handler.py</code>: Handles the execution of jobs related to downloading and storing the file in a bucket.</li> <li>It uses a specific job handler module based on the configuration.</li> </ul>"},{"location":"reference/apps/process-input/source-watcher/#job-handler-module","title":"Job Handler Module","text":"<ul> <li><code>source_watcher/jobs/handlers/default/job.py</code>: An example job handler module.</li> <li>It defines the logic for making HTTP requests to download data from a specific URL.</li> <li>It search the input in the source to trigger future jobs.</li> <li>It uploads the downloaded data to a Minio storage bucket.</li> <li>It returns the job result, including the storage URI and status.</li> </ul>"},{"location":"reference/apps/process-input/source-watcher/#libraries-dependencies","title":"Libraries Dependencies:","text":""},{"location":"reference/apps/process-input/source-watcher/#configuration-module","title":"Configuration Module","text":"<ul> <li><code>config_loader</code>: Loads configurations for the service, such as the source, job handler, service parameters and job parameters also.</li> </ul>"},{"location":"reference/apps/process-input/source-watcher/#rabbitmq-module","title":"RabbitMQ Module","text":"<ul> <li><code>pyrabbitmq</code>: Handles the interaction with RabbitMQ, including creating channels, queues, and publishing messages.</li> </ul>"},{"location":"reference/apps/process-input/source-watcher/#service-discovery-module","title":"Service Discovery Module","text":"<ul> <li><code>pysd</code>: Manages service discovery and RabbitMQ endpoints.</li> </ul>"},{"location":"reference/apps/process-input/source-watcher/#architecture-diagram","title":"Architecture Diagram","text":""},{"location":"reference/apps/process-input/source-watcher/#c4-diagram","title":"C4 Diagram","text":""},{"location":"reference/apps/process-input/source-watcher/#service-diagram","title":"Service Diagram","text":""},{"location":"reference/apps/process-input/source-watcher/#how-to-run-the-service","title":"How to Run the Service","text":"<p>To run your service, follow these steps:</p> <ol> <li> <p>Setup Configuration:</p> <ul> <li>Create a <code>.env.{ENVIRONMENT}</code> file based on the example provided in the <code>envs</code> folder.</li> </ul> </li> <li> <p>Build The Service:</p> </li> </ol> <pre><code>npx nx image process-input-source-watcher --env=&lt;ENVIRONMENT&gt;\n</code></pre> <ol> <li>Run the Application:</li> </ol> <pre><code>docker-compose up -d\n</code></pre> <p>Please note that this README provides a high-level overview of your service's structure and components. To run the service effectively, make sure to provide the required configurations and customize the job handler logic according to your specific use case.</p> <p>If you have any questions or need further assistance, feel free to ask.</p>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/consumer/consumer/","title":"Consumer","text":""},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/consumer/consumer/#apps.process-input.source-watcher.source_watcher.consumer.consumer.Consumer","title":"<code>Consumer</code>","text":"<p>The base class for creating data consumers.</p> <p>Parameters:</p> Name Type Description Default <code>sd</code> <code>ServiceDiscovery</code> <p>An instance of the ServiceDiscovery class.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>The configuration data.</p> <code>_rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>The RabbitMQ consumer service.</p> <code>_queue_active_jobs</code> <code>Queue</code> <p>The asyncio queue for active jobs.</p> <code>_exchange_name</code> <code>str</code> <p>The name of the RabbitMQ exchange.</p> <code>_queue_name</code> <code>str</code> <p>The name of the RabbitMQ queue.</p> <code>_routing_key</code> <code>str</code> <p>The routing key for the RabbitMQ queue.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue) -&gt; None: Initializes a Consumer instance with the provided parameters.</p> <code>async _run</code> <p>callable) -&gt; None:</p> Source code in <code>apps/process-input/source-watcher/source_watcher/consumer/consumer.py</code> <pre><code>class Consumer:\n    \"\"\"\n    The base class for creating data consumers.\n\n    Args:\n        sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    Attributes:\n        _config (ConfigDTO): The configuration data.\n        _rabbitmq_service (RabbitMQConsumer): The RabbitMQ consumer service.\n        _queue_active_jobs (asyncio.Queue): The asyncio queue for active jobs.\n        _exchange_name (str): The name of the RabbitMQ exchange.\n        _queue_name (str): The name of the RabbitMQ queue.\n        _routing_key (str): The routing key for the RabbitMQ queue.\n\n    Methods:\n        __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue) -&gt; None:\n            Initializes a Consumer instance with the provided parameters.\n\n        async _run(self, controller: callable) -&gt; None:\n    \"\"\"\n    def __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue):\n        \"\"\"\n        Initializes a Consumer instance with the provided ServiceDiscovery, RabbitMQConsumer, configuration, and active jobs queue.\n\n        Args:\n            sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n            rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n            config (ConfigDTO): The configuration data.\n            queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n        Returns:\n            None\n\n        Raises:\n            None\n        \"\"\"\n        self._config = config\n        self._rabbitmq_service = rabbitmq_service\n        self._queue_active_jobs = queue_active_jobs\n        self._exchange_name = sd.services_rabbitmq_exchange()\n        self._queue_name = _get_queue_name(config)\n        self._routing_key = _get_routing_key(config)\n\n    async def _run(self, controller: callable) -&gt; None:\n        \"\"\"\n        Run the consumer with the specified controller.\n\n        Args:\n            controller (callable): The controller class responsible for processing data.\n\n        \"\"\"\n        channel = await self._rabbitmq_service.create_channel()\n        queue = await self._rabbitmq_service.create_queue(\n            channel,\n            self._queue_name,\n            self._exchange_name,\n            self._routing_key\n        )\n        await self._rabbitmq_service.listen(queue, controller(self._config, self._rabbitmq_service, self._queue_active_jobs).run)\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/consumer/consumer/#apps.process-input.source-watcher.source_watcher.consumer.consumer.Consumer.__init__","title":"<code>__init__(sd, rabbitmq_service, config, queue_active_jobs)</code>","text":"<p>Initializes a Consumer instance with the provided ServiceDiscovery, RabbitMQConsumer, configuration, and active jobs queue.</p> <p>Parameters:</p> Name Type Description Default <code>sd</code> <code>ServiceDiscovery</code> <p>An instance of the ServiceDiscovery class.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>apps/process-input/source-watcher/source_watcher/consumer/consumer.py</code> <pre><code>def __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue):\n    \"\"\"\n    Initializes a Consumer instance with the provided ServiceDiscovery, RabbitMQConsumer, configuration, and active jobs queue.\n\n    Args:\n        sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    Returns:\n        None\n\n    Raises:\n        None\n    \"\"\"\n    self._config = config\n    self._rabbitmq_service = rabbitmq_service\n    self._queue_active_jobs = queue_active_jobs\n    self._exchange_name = sd.services_rabbitmq_exchange()\n    self._queue_name = _get_queue_name(config)\n    self._routing_key = _get_routing_key(config)\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/consumer/consumer/#apps.process-input.source-watcher.source_watcher.consumer.consumer.EventConsumer","title":"<code>EventConsumer</code>","text":"<p>             Bases: <code>Consumer</code></p> <p>The EventConsumer class for processing event data.</p> <p>Parameters:</p> Name Type Description Default <code>sd</code> <code>ServiceDiscovery</code> <p>An instance of the ServiceDiscovery class.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required Source code in <code>apps/process-input/source-watcher/source_watcher/consumer/consumer.py</code> <pre><code>class EventConsumer(Consumer):\n    \"\"\"\n    The EventConsumer class for processing event data.\n\n    Args:\n        sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    \"\"\"\n\n    def __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue):\n        super().__init__(sd, rabbitmq_service, config, queue_active_jobs)\n\n    async def run(self) -&gt; None:\n        \"\"\"\n        Run the EventConsumer to process event data.\n\n        This method triggers the processing of incoming event data using the specified controller.\n\n        \"\"\"\n        await self._run(EventController)\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/consumer/consumer/#apps.process-input.source-watcher.source_watcher.consumer.consumer.EventConsumer.run","title":"<code>run()</code>  <code>async</code>","text":"<p>Run the EventConsumer to process event data.</p> <p>This method triggers the processing of incoming event data using the specified controller.</p> Source code in <code>apps/process-input/source-watcher/source_watcher/consumer/consumer.py</code> <pre><code>async def run(self) -&gt; None:\n    \"\"\"\n    Run the EventConsumer to process event data.\n\n    This method triggers the processing of incoming event data using the specified controller.\n\n    \"\"\"\n    await self._run(EventController)\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/controller/controller/","title":"Controller","text":""},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/controller/controller/#apps.process-input.source-watcher.source_watcher.controller.controller.Controller","title":"<code>Controller</code>","text":"<p>Base class for handling event data processing.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>The configuration data.</p> <code>_config_id</code> <code>str</code> <p>The ID associated with the configuration.</p> <code>_service_name</code> <code>str</code> <p>The service name from the configuration.</p> <code>_source_name</code> <code>str</code> <p>The source name from the configuration.</p> <code>_context_env</code> <code>str</code> <p>The context environment from the configuration.</p> <code>_repository_schema_type</code> <code>str</code> <p>The repository schema type for service input.</p> <code>_queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> <code>_active</code> <code>bool</code> <p>The activation status based on the configuration.</p> <code>_schema_handler_client</code> <p>The schema handler client for retrieving JSON schemas.</p> <code>_input_body_dto</code> <p>The input data DTO.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>ConfigDTO, queue_active_jobs: asyncio.Queue) -&gt; None: Initializes a Controller instance with the provided configuration and active jobs queue.</p> <code>_should_cotroller_active</code> <p>Check if the controller should be active based on the configuration.</p> <code>async _get_event_parser</code> <p>Get the event parser JSON schema for data processing.</p> <code>async _parse_event</code> <p>str) -&gt; type[warlock.model.Model]: Parse the incoming event message and transform it into the appropriate data format.</p> <code>_get_metadata</code> <p>Generate metadata information for the processed event data.</p> <code>async job_dispatcher</code> <p>Dispatch a job to process the event input data and collect the results.</p> Source code in <code>apps/process-input/source-watcher/source_watcher/controller/controller.py</code> <pre><code>class Controller:\n    \"\"\"\n    Base class for handling event data processing.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    Attributes:\n        _config (ConfigDTO): The configuration data.\n        _config_id (str): The ID associated with the configuration.\n        _service_name (str): The service name from the configuration.\n        _source_name (str): The source name from the configuration.\n        _context_env (str): The context environment from the configuration.\n        _repository_schema_type (str): The repository schema type for service input.\n        _queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        _active (bool): The activation status based on the configuration.\n        _schema_handler_client: The schema handler client for retrieving JSON schemas.\n        _input_body_dto: The input data DTO.\n\n    Methods:\n        __init__(self, config: ConfigDTO, queue_active_jobs: asyncio.Queue) -&gt; None:\n            Initializes a Controller instance with the provided configuration and active jobs queue.\n\n        _should_cotroller_active(self) -&gt; bool:\n            Check if the controller should be active based on the configuration.\n\n        async _get_event_parser(self) -&gt; Dict[str, any]:\n            Get the event parser JSON schema for data processing.\n\n        async _parse_event(self, message: str) -&gt; type[warlock.model.Model]:\n            Parse the incoming event message and transform it into the appropriate data format.\n\n        _get_metadata(self) -&gt; MetadataDTO:\n            Generate metadata information for the processed event data.\n\n        async job_dispatcher(self, event_input) -&gt; ServiceFeedbackDTO:\n            Dispatch a job to process the event input data and collect the results.\n    \"\"\"\n    def __init__(self, config: ConfigDTO, queue_active_jobs: asyncio.Queue):\n        \"\"\"\n        Initializes a Controller instance with the provided configuration and active jobs queue.\n\n        Args:\n            config (ConfigDTO): The configuration data.\n            queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n        Returns:\n            None\n        \"\"\"\n        self._config = config\n        self._config_id = config.id\n        self._service_name = config.service\n        self._source_name = config.source\n        self._context_env = config.context\n        self._repository_schema_type = _REPOSITORY_SCHEMA_TYPE\n        self._queue_active_jobs = queue_active_jobs\n        self._active = config.active\n        self._schema_handler_client = async_py_schema_handler_client()\n        self._input_body_dto = None\n\n    def _should_cotroller_active(self) -&gt; bool:\n        \"\"\"\n        Check if the controller should be active based on the configuration.\n\n        Returns:\n            bool: True if the controller is active, False otherwise.\n\n        \"\"\"\n        if self._active:\n            return True\n        return False\n\n    async def _get_event_parser(self) -&gt; Dict[str, any]:\n        \"\"\"\n        Get the event parser JSON schema for data processing.\n\n        Returns:\n            Dict[str, any]: The JSON schema for data processing.\n\n        \"\"\"\n        self.schema_input = await self._schema_handler_client.list_one_schema_by_service_n_source_n_context_n_schema_type(\n            context=self._context_env,\n            service_name=self._service_name,\n            source_name=self._source_name,\n            schema_type=self._repository_schema_type\n        )\n        json_schema = self.schema_input.json_schema\n        return json_schema\n\n    async def _parse_event(self, message: str) -&gt; type[warlock.model.Model]:\n        \"\"\"\n        Parse the incoming event message and transform it into the appropriate data format.\n\n        Args:\n            message (str): The incoming event message.\n\n        Returns:\n            object: The parsed event data in the required data format.\n\n        Raises:\n            ValueError: If the message body cannot be parsed.\n\n        \"\"\"\n        message_body = message.body.decode()\n        event_parser_class = await self._get_event_parser()\n        try:\n            input_body = json.loads(message_body)\n            self._input_body_dto = serialize_to_dataclass(input_body, InputDTO)\n\n            input_data = self._input_body_dto.data\n            Input_dataclass = warlock.model_factory(event_parser_class)\n            return Input_dataclass(**input_data)\n        except json.JSONDecodeError as e:\n            logger.error(f\"Failed to parse message body: {e}\")\n            raise ValueError(\"Invalid message body\")\n\n    def _get_metadata(self) -&gt; MetadataDTO:\n        \"\"\"\n        Generate metadata information for the processed event data.\n\n        Returns:\n            MetadataDTO: Metadata information for the event data.\n\n        \"\"\"\n        return MetadataDTO(\n            input=MetadataInputDTO(\n                id=self._input_body_dto.id,\n                data=self._input_body_dto.data,\n                processing_id=self._input_body_dto.metadata[\"processing_id\"],\n                processing_timestamp=self._input_body_dto.metadata[\"processing_timestamp\"],\n                input_schema_id=self.schema_input.schema_id\n            ),\n            context=self._config.context,\n            service=self._config.service,\n            source=self._config.source,\n            processing_timestamp=datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n            job_frequency=self._config.frequency,\n            job_config_id=self._config.config_id,\n        )\n\n    async def job_dispatcher(self, event_input) -&gt; ServiceFeedbackDTO:\n        \"\"\"\n        Dispatch a job to process the event input data and collect the results.\n\n        Args:\n            event_input: The input data for the job.\n\n        Returns:\n            ServiceFeedbackDTO: Feedback and result information from the job processing.\n\n        \"\"\"\n        await self._queue_active_jobs.put(1)\n        job_data, status_data = await JobHandler(self._config).run(event_input)\n        return ServiceFeedbackDTO(\n            data=job_data,\n            metadata=self._get_metadata(),\n            status=status_data,\n        )\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/controller/controller/#apps.process-input.source-watcher.source_watcher.controller.controller.Controller.__init__","title":"<code>__init__(config, queue_active_jobs)</code>","text":"<p>Initializes a Controller instance with the provided configuration and active jobs queue.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>apps/process-input/source-watcher/source_watcher/controller/controller.py</code> <pre><code>def __init__(self, config: ConfigDTO, queue_active_jobs: asyncio.Queue):\n    \"\"\"\n    Initializes a Controller instance with the provided configuration and active jobs queue.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    Returns:\n        None\n    \"\"\"\n    self._config = config\n    self._config_id = config.id\n    self._service_name = config.service\n    self._source_name = config.source\n    self._context_env = config.context\n    self._repository_schema_type = _REPOSITORY_SCHEMA_TYPE\n    self._queue_active_jobs = queue_active_jobs\n    self._active = config.active\n    self._schema_handler_client = async_py_schema_handler_client()\n    self._input_body_dto = None\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/controller/controller/#apps.process-input.source-watcher.source_watcher.controller.controller.Controller.job_dispatcher","title":"<code>job_dispatcher(event_input)</code>  <code>async</code>","text":"<p>Dispatch a job to process the event input data and collect the results.</p> <p>Parameters:</p> Name Type Description Default <code>event_input</code> <p>The input data for the job.</p> required <p>Returns:</p> Name Type Description <code>ServiceFeedbackDTO</code> <code>ServiceFeedbackDTO</code> <p>Feedback and result information from the job processing.</p> Source code in <code>apps/process-input/source-watcher/source_watcher/controller/controller.py</code> <pre><code>async def job_dispatcher(self, event_input) -&gt; ServiceFeedbackDTO:\n    \"\"\"\n    Dispatch a job to process the event input data and collect the results.\n\n    Args:\n        event_input: The input data for the job.\n\n    Returns:\n        ServiceFeedbackDTO: Feedback and result information from the job processing.\n\n    \"\"\"\n    await self._queue_active_jobs.put(1)\n    job_data, status_data = await JobHandler(self._config).run(event_input)\n    return ServiceFeedbackDTO(\n        data=job_data,\n        metadata=self._get_metadata(),\n        status=status_data,\n    )\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/controller/controller/#apps.process-input.source-watcher.source_watcher.controller.controller.EventController","title":"<code>EventController</code>","text":"<p>             Bases: <code>Controller</code></p> <p>EventController class for processing event data.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <p>Methods:</p> Name Description <code>__init__</code> <p>ConfigDTO, rabbitmq_service: RabbitMQConsumer, queue_active_jobs: asyncio.Queue) -&gt; None: Initializes an EventController instance with the provided configuration, RabbitMQ service, and active jobs queue.</p> <code>async run</code> <p>Run the EventController to process event data.</p> <p>This method initiates the processing of incoming event data using the specified controller logic.</p> <p>Args:     message: The incoming event message.</p> Source code in <code>apps/process-input/source-watcher/source_watcher/controller/controller.py</code> <pre><code>class EventController(Controller):\n    \"\"\"\n    EventController class for processing event data.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    Methods:\n        __init__(self, config: ConfigDTO, rabbitmq_service: RabbitMQConsumer, queue_active_jobs: asyncio.Queue) -&gt; None:\n            Initializes an EventController instance with the provided configuration, RabbitMQ service, and active jobs queue.\n\n        async run(self, message) -&gt; None:\n            Run the EventController to process event data.\n\n            This method initiates the processing of incoming event data using the specified controller logic.\n\n            Args:\n                message: The incoming event message.\n    \"\"\"\n    def __init__(self, config: ConfigDTO, rabbitmq_service: RabbitMQConsumer, queue_active_jobs: asyncio.Queue) -&gt; None:\n        \"\"\"\n        Initializes an EventController instance with the provided configuration, RabbitMQ service, and active jobs queue.\n\n        Args:\n            config (ConfigDTO): The configuration data.\n            rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n            queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n        Returns:\n            None\n        \"\"\"\n        self._rabbitmq_service = rabbitmq_service\n        super().__init__(config, queue_active_jobs)\n\n    async def run(self, message) -&gt; None:\n        \"\"\"\n        Run the EventController to process event data.\n\n        This method initiates the processing of incoming event data using the specified controller logic.\n\n        Args:\n            message: The incoming event message.\n\n        Returns:\n            None\n        \"\"\"\n        if not self._should_cotroller_active():\n            logger.info(f\"Controller for config_id {self._config_id} is not active\")\n            return\n\n        await self._rabbitmq_service.publish_message(\n            \"services\",\n            \"input-processing\",\n            json.dumps(json.loads(message.body.decode()))\n        )\n\n        event_input = await self._parse_event(message)\n        job_result = await self.job_dispatcher(event_input)\n        await self._queue_active_jobs.get()\n        output = serialize_to_json(job_result)\n        logger.info(f\"sleeping for 5 seconds...\")\n        time.sleep(5)\n        logger.info(f\"Output: {output}\")\n        await self._rabbitmq_service.publish_message(\n            \"services\",\n            \"feedback\",\n            output\n        )\n        await message.ack()\n        logger.info(\"Published message to service\")\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/controller/controller/#apps.process-input.source-watcher.source_watcher.controller.controller.EventController.__init__","title":"<code>__init__(config, rabbitmq_service, queue_active_jobs)</code>","text":"<p>Initializes an EventController instance with the provided configuration, RabbitMQ service, and active jobs queue.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>apps/process-input/source-watcher/source_watcher/controller/controller.py</code> <pre><code>def __init__(self, config: ConfigDTO, rabbitmq_service: RabbitMQConsumer, queue_active_jobs: asyncio.Queue) -&gt; None:\n    \"\"\"\n    Initializes an EventController instance with the provided configuration, RabbitMQ service, and active jobs queue.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    Returns:\n        None\n    \"\"\"\n    self._rabbitmq_service = rabbitmq_service\n    super().__init__(config, queue_active_jobs)\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/controller/controller/#apps.process-input.source-watcher.source_watcher.controller.controller.EventController.run","title":"<code>run(message)</code>  <code>async</code>","text":"<p>Run the EventController to process event data.</p> <p>This method initiates the processing of incoming event data using the specified controller logic.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <p>The incoming event message.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>apps/process-input/source-watcher/source_watcher/controller/controller.py</code> <pre><code>async def run(self, message) -&gt; None:\n    \"\"\"\n    Run the EventController to process event data.\n\n    This method initiates the processing of incoming event data using the specified controller logic.\n\n    Args:\n        message: The incoming event message.\n\n    Returns:\n        None\n    \"\"\"\n    if not self._should_cotroller_active():\n        logger.info(f\"Controller for config_id {self._config_id} is not active\")\n        return\n\n    await self._rabbitmq_service.publish_message(\n        \"services\",\n        \"input-processing\",\n        json.dumps(json.loads(message.body.decode()))\n    )\n\n    event_input = await self._parse_event(message)\n    job_result = await self.job_dispatcher(event_input)\n    await self._queue_active_jobs.get()\n    output = serialize_to_json(job_result)\n    logger.info(f\"sleeping for 5 seconds...\")\n    time.sleep(5)\n    logger.info(f\"Output: {output}\")\n    await self._rabbitmq_service.publish_message(\n        \"services\",\n        \"feedback\",\n        output\n    )\n    await message.ack()\n    logger.info(\"Published message to service\")\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/job_handler/","title":"Job handler","text":""},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/job_handler/#apps.process-input.source-watcher.source_watcher.jobs.job_handler.JobHandler","title":"<code>JobHandler</code>","text":"<p>Represents a job handler that runs a specific job based on configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data for the job handler.</p> required <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>The configuration data for the job handler.</p> <code>_job_handler</code> <code>str</code> <p>The name of the job handler.</p> <code>_config_id</code> <code>int</code> <p>The unique identifier for the configuration.</p> <code>_module</code> <code>module</code> <p>The imported module for the specified job handler.</p> <p>Methods:</p> Name Description <code>_import_job_handler_as_module</code> <p>Imports the job handler module based on the provided configuration.</p> <code>run</code> <p>Runs the job associated with the configuration.</p> <p>Args:     source_input: The input data for the job.</p> <p>Returns:     tuple: A tuple containing job_data, job_status, and target_endpoint.</p> Source code in <code>apps/process-input/source-watcher/source_watcher/jobs/job_handler.py</code> <pre><code>class JobHandler:\n    \"\"\"\n    Represents a job handler that runs a specific job based on configuration.\n\n    Args:\n        config (ConfigDTO): The configuration data for the job handler.\n\n    Attributes:\n        _config (ConfigDTO): The configuration data for the job handler.\n        _job_handler (str): The name of the job handler.\n        _config_id (int): The unique identifier for the configuration.\n        _module (module): The imported module for the specified job handler.\n\n    Methods:\n        _import_job_handler_as_module(self):\n            Imports the job handler module based on the provided configuration.\n\n        run(self, source_input):\n            Runs the job associated with the configuration.\n\n            Args:\n                source_input: The input data for the job.\n\n            Returns:\n                tuple: A tuple containing job_data, job_status, and target_endpoint.\n\n    \"\"\"\n\n    def __init__(self, config: ConfigDTO) -&gt; None:\n        self._config = config\n        self._job_handler = config.service_parameters[\"job_handler\"]\n        self._config_id = config.id\n        self._module = self._import_job_handler_as_module()\n\n    def _import_job_handler_as_module(self):\n        \"\"\"\n        Import the job handler module based on the specified job handler name.\n\n        Returns:\n            module: The imported module for the job handler.\n        \"\"\"\n        return importlib.import_module(f\"jobs.handlers.{self._job_handler}.job\")\n\n    async def run(self, source_input: type[warlock.model.Model]) -&gt; Tuple[dict, StatusDTO]:\n        \"\"\"\n        Run the job associated with the configuration.\n\n        Args:\n            source_input: The input data for the job.\n\n        Returns:\n            tuple: A tuple containing job_data and job_status.\n        \"\"\"\n        logger.info(f\"[RUNNING JOB] - Config ID: {self._config_id} - handler: {self._job_handler}\")\n        job_data, job_status = await self._module.Job(self._config, source_input).run()\n        return job_data, job_status\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/job_handler/#apps.process-input.source-watcher.source_watcher.jobs.job_handler.JobHandler.run","title":"<code>run(source_input)</code>  <code>async</code>","text":"<p>Run the job associated with the configuration.</p> <p>Parameters:</p> Name Type Description Default <code>source_input</code> <code>type[Model]</code> <p>The input data for the job.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>Tuple[dict, StatusDTO]</code> <p>A tuple containing job_data and job_status.</p> Source code in <code>apps/process-input/source-watcher/source_watcher/jobs/job_handler.py</code> <pre><code>async def run(self, source_input: type[warlock.model.Model]) -&gt; Tuple[dict, StatusDTO]:\n    \"\"\"\n    Run the job associated with the configuration.\n\n    Args:\n        source_input: The input data for the job.\n\n    Returns:\n        tuple: A tuple containing job_data and job_status.\n    \"\"\"\n    logger.info(f\"[RUNNING JOB] - Config ID: {self._config_id} - handler: {self._job_handler}\")\n    job_data, job_status = await self._module.Job(self._config, source_input).run()\n    return job_data, job_status\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/handlers/annual_reports/html_utils/","title":"Html utils","text":""},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/handlers/annual_reports/html_utils/#apps.process-input.source-watcher.source_watcher.jobs.handlers.annual_reports.html_utils.get_href_data_from_html","title":"<code>get_href_data_from_html(html)</code>","text":"<p>Extract all href content from the  tags under <li> tags in the given HTML. <p>Parameters:</p> Name Type Description Default <code>html</code> <code>str</code> <p>The HTML content.</p> required <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>List[str]: List of href content.</p> Source code in <code>apps/process-input/source-watcher/source_watcher/jobs/handlers/annual_reports/html_utils.py</code> <pre><code>def get_href_data_from_html(html: str) -&gt; Dict[str, str]:\n    \"\"\"\n    Extract all href content from the &lt;a&gt; tags under &lt;li&gt; tags in the given HTML.\n\n    Args:\n        html (str): The HTML content.\n\n    Returns:\n        List[str]: List of href content.\n\n    \"\"\"\n    logger.info(\"Getting href data from HTML\")\n    soup = _get_soup(html)\n\n    # Find all \"a\" tags within \"li\" tags in the HTML\n    li_a_tags = _find_all_by_tag_within_parent(soup, \"li\", \"a\")\n\n    # Extract href content from each \"a\" tag\n    hrefs = [a.get(\"href\") for a in li_a_tags if a is not None and a.get(\"href\") is not None]\n    hrefs = [href for href in hrefs if \"/Company\" in href]\n\n    return hrefs\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/handlers/annual_reports/html_utils/#apps.process-input.source-watcher.source_watcher.jobs.handlers.annual_reports.html_utils.get_document_download_target","title":"<code>get_document_download_target(html)</code>","text":"<p>Extracts the target file name for document download from the provided HTML content.</p> <p>Parameters:</p> Name Type Description Default <code>html</code> <code>str</code> <p>The HTML content containing information about the document.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The target file name for the document download.</p> Source code in <code>apps/process-input/source-watcher/source_watcher/jobs/handlers/annual_reports/html_utils.py</code> <pre><code>def get_document_download_target(html: str) -&gt; str:\n    \"\"\"\n    Extracts the target file name for document download from the provided HTML content.\n\n    Args:\n        html (str): The HTML content containing information about the document.\n\n    Returns:\n        str: The target file name for the document download.\n\n    Raises:\n        None\n    \"\"\"\n    logger.info(\"Getting document download target\")\n    soup = _get_soup(html)\n    # Find the first &lt;span&gt; element with class \"btn_archived view_annual_report\"\n    span = soup.find('span', class_='btn_archived view_annual_report')\n    if span is None:\n        return None\n\n    href = span.find('a')['href']\n    match = re.search(r'[a-zA-Z_]+(?=\\d*\\.)', href)\n\n    if match is None:\n        return None\n\n    pdf_target_year = _get_pdf_target_year(soup)\n    if pdf_target_year is None:\n        return None\n\n    target_file = f\"{match.group()}{pdf_target_year}.pdf\"\n    logger.info(f\"target_file: {target_file}\")\n    return target_file\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/handlers/annual_reports/job/","title":"Job","text":""},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/handlers/annual_reports/job/#apps.process-input.source-watcher.source_watcher.jobs.handlers.annual_reports.job.Job","title":"<code>Job</code>","text":"<p>Represents a job that performs tasks related to data retrieval and processing.</p> <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>The configuration data for the job.</p> <code>_source</code> <code>str</code> <p>The source identifier for the job.</p> <code>_context</code> <code>str</code> <p>The context identifier for the job.</p> <code>_input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> <code>_job_url</code> <code>str</code> <p>The URL associated with the job.</p> <code>_domain_url</code> <code>str</code> <p>The domain URL associated with the job.</p> <code>_target_endpoint</code> <code>str</code> <p>The target endpoint URL for the job.</p> <code>_partition</code> <code>str</code> <p>The formatted reference string for the job's partition.</p> <code>downloads_exceptions</code> <code>List[str]</code> <p>List of URLs with download exceptions.</p> <code>target_documents</code> <code>List[str]</code> <p>List of target document names.</p> <code>document_uris</code> <code>List[str]</code> <p>List of URIs for stored documents.</p> <code>companies_partition</code> <code>List[str]</code> <p>List of company names associated with the partition.</p> <p>Methods:</p> Name Description <code>_get_reference</code> <p>Extracts and formats the reference data.</p> <code>_get_endpoint</code> <p>Generates the target endpoint URL.</p> <code>_get_bucket_name</code> <p>Generates the bucket name for Minio storage.</p> <code>_get_status</code> <p>Extracts the status information from an HTTP response.</p> <code>make_request</code> <p>Makes an HTTP GET request to the target endpoint.</p> <code>async make_request_company</code> <p>MinioClient, company_url: str, company_name: str) -&gt; None: Asynchronously makes an HTTP GET request to a company's URL.</p> <code>async parse_response_body</code> <p>requests.Response, minio: MinioClient) -&gt; List[str]: Parses the response body to extract the document URLs.</p> <code>async run</code> <p>Runs the job, making the HTTP request and handling the response.</p> Source code in <code>apps/process-input/source-watcher/source_watcher/jobs/handlers/annual_reports/job.py</code> <pre><code>class Job:\n    \"\"\"\n    Represents a job that performs tasks related to data retrieval and processing.\n\n    Attributes:\n        _config (ConfigDTO): The configuration data for the job.\n        _source (str): The source identifier for the job.\n        _context (str): The context identifier for the job.\n        _input_data (type[warlock.model.Model]): The input data for the job.\n        _job_url (str): The URL associated with the job.\n        _domain_url (str): The domain URL associated with the job.\n        _target_endpoint (str): The target endpoint URL for the job.\n        _partition (str): The formatted reference string for the job's partition.\n        downloads_exceptions (List[str]): List of URLs with download exceptions.\n        target_documents (List[str]): List of target document names.\n        document_uris (List[str]): List of URIs for stored documents.\n        companies_partition (List[str]): List of company names associated with the partition.\n\n    Methods:\n        _get_reference(reference) -&gt; str:\n            Extracts and formats the reference data.\n\n        _get_endpoint() -&gt; str:\n            Generates the target endpoint URL.\n\n        _get_bucket_name() -&gt; str:\n            Generates the bucket name for Minio storage.\n\n        _get_status(response) -&gt; StatusDTO:\n            Extracts the status information from an HTTP response.\n\n        make_request() -&gt; requests.Response:\n            Makes an HTTP GET request to the target endpoint.\n\n        async make_request_company(minio: MinioClient, company_url: str, company_name: str) -&gt; None:\n            Asynchronously makes an HTTP GET request to a company's URL.\n\n        async parse_response_body(response: requests.Response, minio: MinioClient) -&gt; List[str]:\n            Parses the response body to extract the document URLs.\n\n        async run() -&gt; Tuple[dict, StatusDTO, str]:\n            Runs the job, making the HTTP request and handling the response.\n    \"\"\"\n    def __init__(self, config: ConfigDTO, input_data: type[warlock.model.Model]) -&gt; None:\n        \"\"\"\n        Initializes a Job instance with the provided configuration and input data.\n\n        Args:\n            config (ConfigDTO): The configuration data.\n            input_data (type[warlock.model.Model]): The input data.\n\n        Returns:\n            None\n        \"\"\"\n        self._config = config\n        self._source = config.source\n        self._context = config.context\n        self._input_data = input_data\n        self._job_url = config.job_parameters[\"url\"]\n        self._domain_url = config.job_parameters[\"domain_url\"]\n        self._target_endpoint = self._get_endpoint()\n        self._partition = self._get_reference(input_data.reference)\n        self.downloads_exceptions = []\n        self.target_documents = []\n        self.document_uris = []\n        self.companies_partition = []\n\n    def _get_reference(self, reference) -&gt; str:\n        \"\"\"\n        Extracts and formats the reference data.\n\n        Args:\n            reference: The reference data.\n\n        Returns:\n            str: The formatted reference string.\n        \"\"\"\n        logger.info(f\"Reference: {reference}\")\n        ref = datetime(reference[\"year\"], reference[\"month\"], reference[\"day\"])\n        return ref.strftime(\"%Y%m%d\")\n\n    def _get_endpoint(self) -&gt; str:\n        \"\"\"\n        Generates the target endpoint URL.\n\n        Returns:\n            str: The target endpoint URL.\n        \"\"\"\n        return self._job_url\n\n    def _get_bucket_name(self) -&gt; str:\n        \"\"\"\n        Generates the bucket name for Minio storage.\n\n        Returns:\n            str: The bucket name.\n        \"\"\"\n        return \"process-input-{context}-source-{source}\".format(\n            context=self._context,\n            source=self._source,\n        )\n\n    def _get_status(self, response) -&gt; StatusDTO:\n        \"\"\"\n        Extracts the status information from an HTTP response.\n\n        Args:\n            response: The HTTP response.\n\n        Returns:\n            StatusDTO: The status information.\n        \"\"\"\n        return StatusDTO(\n            code=response.status_code,\n            detail=response.reason,\n        )\n\n    def make_request(self) -&gt; requests.Response:\n        \"\"\"\n        Makes an HTTP GET request to the target endpoint.\n\n        Returns:\n            requests.Response: The HTTP response.\n        \"\"\"\n        logger.info(f\"endpoint: {self._target_endpoint}\")\n        return requests.get(\n            url=self._target_endpoint,\n            verify=False,\n            timeout=10*60,\n        )\n\n    async def make_request_company(self, minio: MinioClient, company_url: str, company_name: str) -&gt; None:\n        \"\"\"\n        Asynchronously makes an HTTP GET request to a company's URL.\n\n        Args:\n            minio (MinioClient): The Minio client.\n            company_url (str): The company's URL.\n            company_name (str): The company's name.\n\n        Returns:\n            None\n        \"\"\"\n        headers = {\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n            \"Accept-Encoding\": \"gzip, deflate, br\",\n            \"Accept-Language\": \"pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7\",\n            \"Referer\": f\"https://www.annualreports.com/Company/{company_name}\",\n            \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:92.0) Gecko/20100101 Firefox/92.0\",\n        }\n        response = requests.get(\n            url=company_url,\n            verify=False,\n            headers=headers,\n            timeout=10*60,\n        )\n        if response.status_code &gt;= 400:\n            self.downloads_exceptions.append(company_url)\n        else:\n            document_target = get_document_download_target(response.content)\n            if document_target is None:\n                self.downloads_exceptions.append(company_url)\n            else:\n                page_template = f\"{document_target.split('.')[0]}.html\"\n                file_path =  \"{company}/{partition}/{document_target}\".format(\n                    company=company_name,\n                    partition=self._partition,\n                    document_target=page_template\n                )\n                uri = minio.upload_bytes(self._get_bucket_name(), file_path, response.content)\n                self.companies_partition.append(company_name)\n                self.target_documents.append(document_target)\n                self.document_uris.append(uri)\n\n    async def parse_response_body(self, response: requests.Response, minio: MinioClient) -&gt; List[str]:\n        \"\"\"\n        Parses the response body to extract the document URLs.\n\n        Returns:\n            List[str]: The list of document URLs.\n        \"\"\"\n        hrefs = get_href_data_from_html(response.content)\n        if hrefs is None or len(hrefs) == 0:\n            raise Exception(\"No data found\")\n        companies_data = [(f\"{self._domain_url}{href}\", href.split(\"/\")[-1]) for href in hrefs][:10]\n        tasks = [asyncio.create_task(self.make_request_company(minio, company_url, company_name)) for company_url, company_name in companies_data]\n\n        await asyncio.gather(*tasks)\n\n    async def run(self) -&gt; Tuple[dict, StatusDTO]:\n        \"\"\"\n        Runs the job, making the HTTP request and handling the response.\n\n        Returns:\n            tuple: A tuple containing result data, status information, and the target endpoint.\n        \"\"\"\n        logger.info(f\"Job triggered with input: {self._input_data}\")\n        response = self.make_request()\n        minio = minio_client()\n        await self.parse_response_body(response, minio)\n        logger.info(f\"File storage uris: {self.document_uris}\")\n        result = {\"documentUri\": self.document_uris, \"partition\": self.companies_partition, \"totalDocuments\": len(self.document_uris), \"targetDocuments\": self.target_documents}\n        logger.info(f\"Job result: {result}\")\n        return result, self._get_status(response)\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/handlers/annual_reports/job/#apps.process-input.source-watcher.source_watcher.jobs.handlers.annual_reports.job.Job.__init__","title":"<code>__init__(config, input_data)</code>","text":"<p>Initializes a Job instance with the provided configuration and input data.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>input_data</code> <code>type[Model]</code> <p>The input data.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>apps/process-input/source-watcher/source_watcher/jobs/handlers/annual_reports/job.py</code> <pre><code>def __init__(self, config: ConfigDTO, input_data: type[warlock.model.Model]) -&gt; None:\n    \"\"\"\n    Initializes a Job instance with the provided configuration and input data.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        input_data (type[warlock.model.Model]): The input data.\n\n    Returns:\n        None\n    \"\"\"\n    self._config = config\n    self._source = config.source\n    self._context = config.context\n    self._input_data = input_data\n    self._job_url = config.job_parameters[\"url\"]\n    self._domain_url = config.job_parameters[\"domain_url\"]\n    self._target_endpoint = self._get_endpoint()\n    self._partition = self._get_reference(input_data.reference)\n    self.downloads_exceptions = []\n    self.target_documents = []\n    self.document_uris = []\n    self.companies_partition = []\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/handlers/annual_reports/job/#apps.process-input.source-watcher.source_watcher.jobs.handlers.annual_reports.job.Job.make_request","title":"<code>make_request()</code>","text":"<p>Makes an HTTP GET request to the target endpoint.</p> <p>Returns:</p> Type Description <code>Response</code> <p>requests.Response: The HTTP response.</p> Source code in <code>apps/process-input/source-watcher/source_watcher/jobs/handlers/annual_reports/job.py</code> <pre><code>def make_request(self) -&gt; requests.Response:\n    \"\"\"\n    Makes an HTTP GET request to the target endpoint.\n\n    Returns:\n        requests.Response: The HTTP response.\n    \"\"\"\n    logger.info(f\"endpoint: {self._target_endpoint}\")\n    return requests.get(\n        url=self._target_endpoint,\n        verify=False,\n        timeout=10*60,\n    )\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/handlers/annual_reports/job/#apps.process-input.source-watcher.source_watcher.jobs.handlers.annual_reports.job.Job.make_request_company","title":"<code>make_request_company(minio, company_url, company_name)</code>  <code>async</code>","text":"<p>Asynchronously makes an HTTP GET request to a company's URL.</p> <p>Parameters:</p> Name Type Description Default <code>minio</code> <code>MinioClient</code> <p>The Minio client.</p> required <code>company_url</code> <code>str</code> <p>The company's URL.</p> required <code>company_name</code> <code>str</code> <p>The company's name.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>apps/process-input/source-watcher/source_watcher/jobs/handlers/annual_reports/job.py</code> <pre><code>async def make_request_company(self, minio: MinioClient, company_url: str, company_name: str) -&gt; None:\n    \"\"\"\n    Asynchronously makes an HTTP GET request to a company's URL.\n\n    Args:\n        minio (MinioClient): The Minio client.\n        company_url (str): The company's URL.\n        company_name (str): The company's name.\n\n    Returns:\n        None\n    \"\"\"\n    headers = {\n        \"Sec-Fetch-Site\": \"same-origin\",\n        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n        \"Accept-Encoding\": \"gzip, deflate, br\",\n        \"Accept-Language\": \"pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7\",\n        \"Referer\": f\"https://www.annualreports.com/Company/{company_name}\",\n        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:92.0) Gecko/20100101 Firefox/92.0\",\n    }\n    response = requests.get(\n        url=company_url,\n        verify=False,\n        headers=headers,\n        timeout=10*60,\n    )\n    if response.status_code &gt;= 400:\n        self.downloads_exceptions.append(company_url)\n    else:\n        document_target = get_document_download_target(response.content)\n        if document_target is None:\n            self.downloads_exceptions.append(company_url)\n        else:\n            page_template = f\"{document_target.split('.')[0]}.html\"\n            file_path =  \"{company}/{partition}/{document_target}\".format(\n                company=company_name,\n                partition=self._partition,\n                document_target=page_template\n            )\n            uri = minio.upload_bytes(self._get_bucket_name(), file_path, response.content)\n            self.companies_partition.append(company_name)\n            self.target_documents.append(document_target)\n            self.document_uris.append(uri)\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/handlers/annual_reports/job/#apps.process-input.source-watcher.source_watcher.jobs.handlers.annual_reports.job.Job.parse_response_body","title":"<code>parse_response_body(response, minio)</code>  <code>async</code>","text":"<p>Parses the response body to extract the document URLs.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: The list of document URLs.</p> Source code in <code>apps/process-input/source-watcher/source_watcher/jobs/handlers/annual_reports/job.py</code> <pre><code>async def parse_response_body(self, response: requests.Response, minio: MinioClient) -&gt; List[str]:\n    \"\"\"\n    Parses the response body to extract the document URLs.\n\n    Returns:\n        List[str]: The list of document URLs.\n    \"\"\"\n    hrefs = get_href_data_from_html(response.content)\n    if hrefs is None or len(hrefs) == 0:\n        raise Exception(\"No data found\")\n    companies_data = [(f\"{self._domain_url}{href}\", href.split(\"/\")[-1]) for href in hrefs][:10]\n    tasks = [asyncio.create_task(self.make_request_company(minio, company_url, company_name)) for company_url, company_name in companies_data]\n\n    await asyncio.gather(*tasks)\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/handlers/annual_reports/job/#apps.process-input.source-watcher.source_watcher.jobs.handlers.annual_reports.job.Job.run","title":"<code>run()</code>  <code>async</code>","text":"<p>Runs the job, making the HTTP request and handling the response.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>Tuple[dict, StatusDTO]</code> <p>A tuple containing result data, status information, and the target endpoint.</p> Source code in <code>apps/process-input/source-watcher/source_watcher/jobs/handlers/annual_reports/job.py</code> <pre><code>async def run(self) -&gt; Tuple[dict, StatusDTO]:\n    \"\"\"\n    Runs the job, making the HTTP request and handling the response.\n\n    Returns:\n        tuple: A tuple containing result data, status information, and the target endpoint.\n    \"\"\"\n    logger.info(f\"Job triggered with input: {self._input_data}\")\n    response = self.make_request()\n    minio = minio_client()\n    await self.parse_response_body(response, minio)\n    logger.info(f\"File storage uris: {self.document_uris}\")\n    result = {\"documentUri\": self.document_uris, \"partition\": self.companies_partition, \"totalDocuments\": len(self.document_uris), \"targetDocuments\": self.target_documents}\n    logger.info(f\"Job result: {result}\")\n    return result, self._get_status(response)\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/handlers/default/html_utils/","title":"Html utils","text":""},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/handlers/default/html_utils/#apps.process-input.source-watcher.source_watcher.jobs.handlers.default.html_utils.get_target_input_data_by_regex_pattern","title":"<code>get_target_input_data_by_regex_pattern(html, target_pattern)</code>","text":"<p>Extracts target input data from HTML using specified regex patterns.</p> <p>Parameters:</p> Name Type Description Default <code>html</code> <code>str</code> <p>The HTML content to search for patterns.</p> required <code>target_pattern</code> <code>Dict[str, any]</code> <p>A dictionary containing variable names as keys and regex patterns as values.</p> required <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>Dict[str, str]: A dictionary mapping variable names to extracted data.</p> Source code in <code>apps/process-input/source-watcher/source_watcher/jobs/handlers/default/html_utils.py</code> <pre><code>def get_target_input_data_by_regex_pattern(html: str, target_pattern: Dict[str, any]) -&gt; Dict[str, str]:\n    \"\"\"\n    Extracts target input data from HTML using specified regex patterns.\n\n    Args:\n        html (str): The HTML content to search for patterns.\n        target_pattern (Dict[str, any]): A dictionary containing variable names as keys\n            and regex patterns as values.\n\n    Returns:\n        Dict[str, str]: A dictionary mapping variable names to extracted data.\n\n    Raises:\n        None\n            If the data for any variable is not found in the HTML.\n    \"\"\"\n    result_search = dict()\n    for var_name, _target_pattern in target_pattern.items():\n        fetch_pattern = re.findall(_target_pattern, html)\n        if fetch_pattern == []:\n            return None\n        result_search[var_name] = fetch_pattern[0].decode()\n    return result_search\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/handlers/default/job/","title":"Job","text":""},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/handlers/default/job/#apps.process-input.source-watcher.source_watcher.jobs.handlers.default.job.Job","title":"<code>Job</code>","text":"<p>Represents a job that makes HTTP requests and handles the response.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data for the job.</p> required <code>input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> required <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>The configuration data for the job.</p> <code>_source</code> <code> (str</code> <p>The source information from the configuration.</p> <code>_context</code> <code>str</code> <p>The context information from the configuration.</p> <code>_input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> <code>_job_url</code> <code>str</code> <p>The URL for the job.</p> <code>_target_endpoint</code> <code>str</code> <p>The final endpoint URL.</p> <p>Methods:</p> Name Description <code>_get_reference</code> <p>Extracts and formats the reference data.</p> <code>_get_endpoint</code> <p>Generates the target endpoint URL.</p> <code>_get_bucket_name</code> <p>Generates the bucket name for Minio storage.</p> <code>_get_status</code> <p>Extracts the status information from an HTTP response.</p> <code>make_request</code> <p>Makes an HTTP GET request to the target endpoint.</p> <code>run</code> <p>Runs the job, making the HTTP request and handling the response.</p> Source code in <code>apps/process-input/source-watcher/source_watcher/jobs/handlers/default/job.py</code> <pre><code>class Job:\n    \"\"\"\n    Represents a job that makes HTTP requests and handles the response.\n\n    Args:\n        config (ConfigDTO): The configuration data for the job.\n        input_data: The input data for the job.\n\n    Attributes:\n        _config (ConfigDTO): The configuration data for the job.\n        _source  (str): The source information from the configuration.\n        _context (str): The context information from the configuration.\n        _input_data (type[warlock.model.Model]): The input data for the job.\n        _job_url (str): The URL for the job.\n        _target_endpoint (str): The final endpoint URL.\n\n    Methods:\n        _get_reference(self, reference):\n            Extracts and formats the reference data.\n\n        _get_endpoint(self):\n            Generates the target endpoint URL.\n\n        _get_bucket_name(self):\n            Generates the bucket name for Minio storage.\n\n        _get_status(self, response) -&gt; StatusDTO:\n            Extracts the status information from an HTTP response.\n\n        make_request(self):\n            Makes an HTTP GET request to the target endpoint.\n\n        run(self):\n            Runs the job, making the HTTP request and handling the response.\n\n    \"\"\"\n\n    def __init__(self, config: ConfigDTO, input_data: type[warlock.model.Model]) -&gt; None:\n        self._config = config\n        self._source = config.source\n        self._context = config.context\n        self._input_data = input_data\n        self._job_url = config.job_parameters[\"url\"]\n        self._target_endpoint = self._get_endpoint()\n\n    def _get_reference(self, reference) -&gt; str:\n        \"\"\"\n        Extracts and formats the reference data.\n\n        Args:\n            reference: The reference data.\n\n        Returns:\n            str: The formatted reference string.\n        \"\"\"\n        logger.info(f\"Reference: {reference}\")\n        ref = datetime(reference[\"year\"], reference[\"month\"], reference[\"day\"])\n        return ref.strftime(\"%Y%m%d\")\n\n    def _get_endpoint(self) -&gt; str:\n        \"\"\"\n        Generates the target endpoint URL.\n\n        Returns:\n            str: The target endpoint URL.\n        \"\"\"\n        return self._job_url\n\n    def _get_bucket_name(self) -&gt; str:\n        \"\"\"\n        Generates the bucket name for Minio storage.\n\n        Returns:\n            str: The bucket name.\n        \"\"\"\n        return \"process-input-{context}-source-{source}\".format(\n            context=self._context,\n            source=self._source,\n        )\n\n    def _get_status(self, response) -&gt; StatusDTO:\n        \"\"\"\n        Extracts the status information from an HTTP response.\n\n        Args:\n            response: The HTTP response.\n\n        Returns:\n            StatusDTO: The status information.\n        \"\"\"\n        return StatusDTO(\n            code=response.status_code,\n            detail=response.reason,\n        )\n\n    def make_request(self) -&gt; requests.Response:\n        \"\"\"\n        Makes an HTTP GET request to the target endpoint.\n\n        Returns:\n            requests.Response: The HTTP response.\n        \"\"\"\n        logger.info(f\"endpoint: {self._target_endpoint}\")\n        headers = {\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n            \"Accept-Encoding\": \"gzip, deflate, br\",\n            \"Accept-Language\": \"pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7\",\n            \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:92.0) Gecko/20100101 Firefox/92.0\",\n        }\n        return requests.get(\n            self._target_endpoint,\n            verify=False,\n            headers=headers,\n            timeout=10*60,\n        )\n\n    def parse_response_body(self, response: requests.Response) -&gt; str:\n        \"\"\"\n        Parses the response body.\n\n        Args:\n            response: The HTTP response.\n\n        Returns:\n            str: The response body.\n        \"\"\"\n        pattern_search = {\n            \"year\": b'\"ano\" : \"([0-9]{4})\"',\n            \"month\": b'\"mes\" : \"([0][0-9]|[1][012])\"',\n            \"day\": b'\"dia\" : \"([0-9]{2})\"',\n        }\n        input_search = get_target_input_data_by_regex_pattern(response.content, pattern_search)\n        if input_search is None:\n            raise Exception(\"No data found\")\n        return \"{year}{month}{day}\".format(**input_search)\n\n\n    async def run(self) -&gt; Tuple[dict, StatusDTO]:\n        \"\"\"\n        Runs the job, making the HTTP request and handling the response.\n\n        Returns:\n            tuple: A tuple containing result data, status information, and the target endpoint.\n        \"\"\"\n        logger.info(f\"Job triggered with input: {self._input_data}\")\n        response = self.make_request()\n        input_data = self.parse_response_body(response)\n        minio = minio_client()\n        uri = minio.upload_bytes(self._get_bucket_name(), f\"{input_data}/{self._source}.html\", response.content)\n        logger.info(f\"File storage uri: {uri}\")\n        result = {\"documentUri\": uri, \"partition\": input_data}\n        logger.info(f\"Job result: {result}\")\n        return result, self._get_status(response)\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/handlers/default/job/#apps.process-input.source-watcher.source_watcher.jobs.handlers.default.job.Job.make_request","title":"<code>make_request()</code>","text":"<p>Makes an HTTP GET request to the target endpoint.</p> <p>Returns:</p> Type Description <code>Response</code> <p>requests.Response: The HTTP response.</p> Source code in <code>apps/process-input/source-watcher/source_watcher/jobs/handlers/default/job.py</code> <pre><code>def make_request(self) -&gt; requests.Response:\n    \"\"\"\n    Makes an HTTP GET request to the target endpoint.\n\n    Returns:\n        requests.Response: The HTTP response.\n    \"\"\"\n    logger.info(f\"endpoint: {self._target_endpoint}\")\n    headers = {\n        \"Sec-Fetch-Site\": \"same-origin\",\n        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n        \"Accept-Encoding\": \"gzip, deflate, br\",\n        \"Accept-Language\": \"pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7\",\n        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:92.0) Gecko/20100101 Firefox/92.0\",\n    }\n    return requests.get(\n        self._target_endpoint,\n        verify=False,\n        headers=headers,\n        timeout=10*60,\n    )\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/handlers/default/job/#apps.process-input.source-watcher.source_watcher.jobs.handlers.default.job.Job.parse_response_body","title":"<code>parse_response_body(response)</code>","text":"<p>Parses the response body.</p> <p>Parameters:</p> Name Type Description Default <code>response</code> <code>Response</code> <p>The HTTP response.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The response body.</p> Source code in <code>apps/process-input/source-watcher/source_watcher/jobs/handlers/default/job.py</code> <pre><code>def parse_response_body(self, response: requests.Response) -&gt; str:\n    \"\"\"\n    Parses the response body.\n\n    Args:\n        response: The HTTP response.\n\n    Returns:\n        str: The response body.\n    \"\"\"\n    pattern_search = {\n        \"year\": b'\"ano\" : \"([0-9]{4})\"',\n        \"month\": b'\"mes\" : \"([0][0-9]|[1][012])\"',\n        \"day\": b'\"dia\" : \"([0-9]{2})\"',\n    }\n    input_search = get_target_input_data_by_regex_pattern(response.content, pattern_search)\n    if input_search is None:\n        raise Exception(\"No data found\")\n    return \"{year}{month}{day}\".format(**input_search)\n</code></pre>"},{"location":"reference/apps/process-input/source-watcher/code_reference/source_watcher/jobs/handlers/default/job/#apps.process-input.source-watcher.source_watcher.jobs.handlers.default.job.Job.run","title":"<code>run()</code>  <code>async</code>","text":"<p>Runs the job, making the HTTP request and handling the response.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>Tuple[dict, StatusDTO]</code> <p>A tuple containing result data, status information, and the target endpoint.</p> Source code in <code>apps/process-input/source-watcher/source_watcher/jobs/handlers/default/job.py</code> <pre><code>async def run(self) -&gt; Tuple[dict, StatusDTO]:\n    \"\"\"\n    Runs the job, making the HTTP request and handling the response.\n\n    Returns:\n        tuple: A tuple containing result data, status information, and the target endpoint.\n    \"\"\"\n    logger.info(f\"Job triggered with input: {self._input_data}\")\n    response = self.make_request()\n    input_data = self.parse_response_body(response)\n    minio = minio_client()\n    uri = minio.upload_bytes(self._get_bucket_name(), f\"{input_data}/{self._source}.html\", response.content)\n    logger.info(f\"File storage uri: {uri}\")\n    result = {\"documentUri\": uri, \"partition\": input_data}\n    logger.info(f\"Job result: {result}\")\n    return result, self._get_status(response)\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/spark-batch/","title":"spark-batch","text":"<p><code>spark-batch</code> is a Python-based service that performs the following tasks:</p> <ul> <li>Apply simple Transformations and normalizations in a dataset using <code>pyspark</code>.</li> <li>This service apply the <code>pyspark</code> job in a cluster using a remote session, feature o <code>spark-connect</code></li> <li>Store the parsed data (iceberg format) in a bucket (bronze layer).</li> <li>Publishes the bucket location to a message queue for further consumption.</li> </ul>"},{"location":"reference/apps/services-bronze-layer/spark-batch/#service-components","title":"Service Components","text":"<p>The service consists of multiple Python modules and classes, each serving a specific purpose. Here's an overview of these components:</p>"},{"location":"reference/apps/services-bronze-layer/spark-batch/#main-module","title":"Main Module","text":"<ul> <li><code>main.py</code>: The entry point of the service.</li> <li>It initializes various configurations, including the service name and context environment.</li> <li>Creates consumers for specific configurations and starts processing data.</li> <li>Each config has it owns queue consumption.</li> </ul>"},{"location":"reference/apps/services-bronze-layer/spark-batch/#consumer-module","title":"Consumer Module","text":"<ul> <li><code>spark_batch/consumer/consumer.py</code>: Contains the <code>EventConsumer</code> class responsible for consume an input message and trigger the callback.</li> <li>This class listens to a RabbitMQ queue, processes incoming data, and trigger the results to the controller.</li> </ul>"},{"location":"reference/apps/services-bronze-layer/spark-batch/#controller-module","title":"Controller Module","text":"<ul> <li> <p><code>spark_batch/controller/controller.py</code>: This module contains the <code>EventController</code> class, which is responsible for handling the business logic related to event processing.</p> </li> <li> <p>The <code>EventController</code> class receives the processed data from the <code>EventConsumer</code>.</p> </li> <li>It checks if the controller should be active based on the configuration.</li> <li>If active, it parses and processes the data using the job handler.</li> <li>It triggers the job dispatcher to execute the job and collect the results.</li> <li>It publishes the results, including the storage URI, to a message queue for further consumption.</li> </ul> <p>The <code>EventController</code> class plays a crucial role in orchestrating the event-driven processing of data within the service.</p> <p>This class ensures that the service processes incoming data efficiently, initiates the appropriate job handler for the task, and communicates the results to the relevant channels.</p>"},{"location":"reference/apps/services-bronze-layer/spark-batch/#job-handling-module","title":"Job Handling Module","text":"<ul> <li><code>spark_batch/jobs/job_handler.py</code>: Handles the execution of jobs related to downloading and storing the file in a bucket.</li> <li>It uses a specific job handler module based on the configuration.</li> </ul>"},{"location":"reference/apps/services-bronze-layer/spark-batch/#job-handler-module","title":"Job Handler Module","text":""},{"location":"reference/apps/services-bronze-layer/spark-batch/#default-handler","title":"Default Handler","text":"<ul> <li><code>jobs/handlers/defualt/job.py</code>: An example job handler module.</li> <li>It defines a dummy spark-connect job.</li> <li>It uploads the parsed data to a Minio storage bucket in iceberg format.</li> <li>It returns the job result, including the storage URI and status.</li> </ul>"},{"location":"reference/apps/services-bronze-layer/spark-batch/#libraries-dependencies","title":"Libraries Dependencies:","text":""},{"location":"reference/apps/services-bronze-layer/spark-batch/#configuration-module","title":"Configuration Module","text":"<ul> <li><code>config_loader</code>: Loads configurations for the service, such as the source, job handler, service parameters and job parameters also.</li> </ul>"},{"location":"reference/apps/services-bronze-layer/spark-batch/#rabbitmq-module","title":"RabbitMQ Module","text":"<ul> <li><code>pyrabbitmq</code>: Handles the interaction with RabbitMQ, including creating channels, queues, and publishing messages.</li> </ul>"},{"location":"reference/apps/services-bronze-layer/spark-batch/#service-discovery-module","title":"Service Discovery Module","text":"<ul> <li><code>pysd</code>: Manages service discovery and RabbitMQ endpoints.</li> </ul>"},{"location":"reference/apps/services-bronze-layer/spark-batch/#architecture-diagram","title":"Architecture Diagram","text":""},{"location":"reference/apps/services-bronze-layer/spark-batch/#c4-diagram","title":"C4 Diagram","text":""},{"location":"reference/apps/services-bronze-layer/spark-batch/#service-diagram","title":"Service Diagram","text":""},{"location":"reference/apps/services-bronze-layer/spark-batch/#how-to-run-the-service","title":"How to Run the Service","text":"<p>To run your service, follow these steps:</p> <ol> <li> <p>Setup Configuration:</p> <ul> <li>Create a <code>.env.{ENVIRONMENT}</code> file based on the example provided in the <code>envs</code> folder.</li> </ul> </li> <li> <p>Build The Service:</p> </li> </ol> <pre><code>npx nx image services-bronze-layer-spark-batch --env=&lt;ENVIRONMENT&gt;\n</code></pre> <ol> <li>Run the Application:</li> </ol> <pre><code>docker-compose up -d\n</code></pre> <p>Please note that this README provides a high-level overview of your service's structure and components. To run the service effectively, make sure to provide the required configurations and customize the job handler logic according to your specific use case.</p> <p>If you have any questions or need further assistance, feel free to ask.</p>"},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/consumer/consumer/","title":"Consumer","text":""},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/consumer/consumer/#apps.services-bronze-layer.spark-batch.spark_batch_bronze.consumer.consumer.Consumer","title":"<code>Consumer</code>","text":"<p>The base class for creating data consumers.</p> <p>Parameters:</p> Name Type Description Default <code>sd</code> <code>ServiceDiscovery</code> <p>An instance of the ServiceDiscovery class.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required Source code in <code>apps/services-bronze-layer/spark-batch/spark_batch_bronze/consumer/consumer.py</code> <pre><code>class Consumer:\n    \"\"\"\n    The base class for creating data consumers.\n\n    Args:\n        sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    \"\"\"\n    def __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue):\n        self._config = config\n        self._rabbitmq_service = rabbitmq_service\n        self._queue_active_jobs = queue_active_jobs\n        self._exchange_name = sd.services_rabbitmq_exchange()\n        self._queue_name = _get_queue_name(config)\n        self._routing_key = _get_routing_key(config)\n\n    async def _run(self, controller: callable) -&gt; None:\n        \"\"\"\n        Run the consumer with the specified controller.\n\n        Args:\n            controller (callable): The controller class responsible for processing data.\n\n        \"\"\"\n        channel = await self._rabbitmq_service.create_channel()\n        queue = await self._rabbitmq_service.create_queue(\n            channel,\n            self._queue_name,\n            self._exchange_name,\n            self._routing_key\n        )\n        logger.info(f\"Listening to queue: {self._queue_name}\")\n        await self._rabbitmq_service.listen(queue, controller(self._config, self._rabbitmq_service, self._queue_active_jobs).run)\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/consumer/consumer/#apps.services-bronze-layer.spark-batch.spark_batch_bronze.consumer.consumer.EventConsumer","title":"<code>EventConsumer</code>","text":"<p>             Bases: <code>Consumer</code></p> <p>The EventConsumer class for processing event data.</p> <p>Parameters:</p> Name Type Description Default <code>sd</code> <code>ServiceDiscovery</code> <p>An instance of the ServiceDiscovery class.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required Source code in <code>apps/services-bronze-layer/spark-batch/spark_batch_bronze/consumer/consumer.py</code> <pre><code>class EventConsumer(Consumer):\n    \"\"\"\n    The EventConsumer class for processing event data.\n\n    Args:\n        sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    \"\"\"\n    def __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue):\n        super().__init__(sd, rabbitmq_service, config, queue_active_jobs)\n\n    async def run(self) -&gt; None:\n        \"\"\"\n        Run the EventConsumer to process event data.\n\n        This method triggers the processing of incoming event data using the specified controller.\n\n        \"\"\"\n        await self._run(EventController)\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/consumer/consumer/#apps.services-bronze-layer.spark-batch.spark_batch_bronze.consumer.consumer.EventConsumer.run","title":"<code>run()</code>  <code>async</code>","text":"<p>Run the EventConsumer to process event data.</p> <p>This method triggers the processing of incoming event data using the specified controller.</p> Source code in <code>apps/services-bronze-layer/spark-batch/spark_batch_bronze/consumer/consumer.py</code> <pre><code>async def run(self) -&gt; None:\n    \"\"\"\n    Run the EventConsumer to process event data.\n\n    This method triggers the processing of incoming event data using the specified controller.\n\n    \"\"\"\n    await self._run(EventController)\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/controller/controller/","title":"Controller","text":""},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/controller/controller/#apps.services-bronze-layer.spark-batch.spark_batch_bronze.controller.controller.Controller","title":"<code>Controller</code>","text":"<p>Base class for handling event data processing.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required Source code in <code>apps/services-bronze-layer/spark-batch/spark_batch_bronze/controller/controller.py</code> <pre><code>class Controller:\n    \"\"\"\n    Base class for handling event data processing.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    \"\"\"\n    def __init__(self, config: ConfigDTO, queue_active_jobs: asyncio.Queue):\n        self._config = config\n        self._config_id = config.id\n        self._service_name = config.service\n        self._source_name = config.source\n        self._context_env = config.context\n        self._repository_schema_type = _REPOSITORY_SCHEMA_TYPE\n        self._queue_active_jobs = queue_active_jobs\n        self._active = config.active\n        self._schema_handler_client = async_py_schema_handler_client()\n        self._input_body_dto = None\n\n    def _should_cotroller_active(self) -&gt; bool:\n        \"\"\"\n        Check if the controller should be active based on the configuration.\n\n        Returns:\n            bool: True if the controller is active, False otherwise.\n\n        \"\"\"\n        if self._active:\n            return True\n        return False\n\n    async def _get_event_parser(self) -&gt; Dict[str, any]:\n        \"\"\"\n        Get the event parser JSON schema for data processing.\n\n        Returns:\n            Dict[str, any]: The JSON schema for data processing.\n\n        \"\"\"\n        self.schema_input = await self._schema_handler_client.list_one_schema_by_service_n_source_n_context_n_schema_type(\n            context=self._context_env,\n            service_name=self._service_name,\n            source_name=self._source_name,\n            schema_type=self._repository_schema_type\n        )\n        json_schema = self.schema_input.json_schema\n        return json_schema\n\n    async def _parse_event(self, message: str) -&gt; type[warlock.model.Model]:\n        \"\"\"\n        Parse the incoming event message and transform it into the appropriate data format.\n\n        Args:\n            message (str): The incoming event message.\n\n        Returns:\n            object: The parsed event data in the required data format.\n\n        Raises:\n            ValueError: If the message body cannot be parsed.\n\n        \"\"\"\n        message_body = message.body.decode()\n        event_parser_class = await self._get_event_parser()\n        try:\n            input_body = json.loads(message_body)\n            self._input_body_dto = serialize_to_dataclass(input_body, InputDTO)\n\n            input_data = self._input_body_dto.data\n            Input_dataclass = warlock.model_factory(event_parser_class)\n            return Input_dataclass(**input_data)\n        except json.JSONDecodeError as e:\n            logger.error(f\"Failed to parse message body: {e}\")\n            raise ValueError(\"Invalid message body\")\n\n    def _get_metadata(self, target_endpoint: str) -&gt; MetadataDTO:\n        \"\"\"\n        Generate metadata information for the processed event data.\n\n        Args:\n            target_endpoint (str): The target endpoint for the event data.\n\n        Returns:\n            MetadataDTO: Metadata information for the event data.\n\n        \"\"\"\n        return MetadataDTO(\n            input=MetadataInputDTO(\n                id=self._input_body_dto.id,\n                data=self._input_body_dto.data,\n                processing_id=self._input_body_dto.metadata[\"processing_id\"],\n                processing_timestamp=self._input_body_dto.metadata[\"processing_timestamp\"],\n                input_schema_id=self.schema_input.schema_id\n            ),\n            context=self._config.context,\n            service=self._config.service,\n            source=self._config.source,\n            processing_timestamp=datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n            job_frequency=self._config.frequency,\n            job_config_id=self._config.config_id,\n        )\n\n    async def job_dispatcher(self, event_input) -&gt; ServiceFeedbackDTO:\n        \"\"\"\n        Dispatch a job to process the event input data and collect the results.\n\n        Args:\n            event_input: The input data for the job.\n\n        Returns:\n            ServiceFeedbackDTO: Feedback and result information from the job processing.\n\n        \"\"\"\n        await self._queue_active_jobs.put(1)\n        job_data, status_data, target_endpoint = await JobHandler(self._config).run(event_input)\n        return ServiceFeedbackDTO(\n            data=job_data,\n            metadata=self._get_metadata(target_endpoint),\n            status=status_data,\n        )\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/controller/controller/#apps.services-bronze-layer.spark-batch.spark_batch_bronze.controller.controller.Controller.job_dispatcher","title":"<code>job_dispatcher(event_input)</code>  <code>async</code>","text":"<p>Dispatch a job to process the event input data and collect the results.</p> <p>Parameters:</p> Name Type Description Default <code>event_input</code> <p>The input data for the job.</p> required <p>Returns:</p> Name Type Description <code>ServiceFeedbackDTO</code> <code>ServiceFeedbackDTO</code> <p>Feedback and result information from the job processing.</p> Source code in <code>apps/services-bronze-layer/spark-batch/spark_batch_bronze/controller/controller.py</code> <pre><code>async def job_dispatcher(self, event_input) -&gt; ServiceFeedbackDTO:\n    \"\"\"\n    Dispatch a job to process the event input data and collect the results.\n\n    Args:\n        event_input: The input data for the job.\n\n    Returns:\n        ServiceFeedbackDTO: Feedback and result information from the job processing.\n\n    \"\"\"\n    await self._queue_active_jobs.put(1)\n    job_data, status_data, target_endpoint = await JobHandler(self._config).run(event_input)\n    return ServiceFeedbackDTO(\n        data=job_data,\n        metadata=self._get_metadata(target_endpoint),\n        status=status_data,\n    )\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/controller/controller/#apps.services-bronze-layer.spark-batch.spark_batch_bronze.controller.controller.EventController","title":"<code>EventController</code>","text":"<p>             Bases: <code>Controller</code></p> <p>EventController class for processing event data.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required Source code in <code>apps/services-bronze-layer/spark-batch/spark_batch_bronze/controller/controller.py</code> <pre><code>class EventController(Controller):\n    \"\"\"\n    EventController class for processing event data.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    \"\"\"\n    def __init__(self, config: ConfigDTO, rabbitmq_service: RabbitMQConsumer, queue_active_jobs: asyncio.Queue) -&gt; None:\n        self._rabbitmq_service = rabbitmq_service\n        super().__init__(config, queue_active_jobs)\n\n    async def run(self, message) -&gt; None:\n        \"\"\"\n        Run the EventController to process event data.\n\n        This method initiates the processing of incoming event data using the specified controller logic.\n\n        Args:\n            message: The incoming event message.\n\n        \"\"\"\n        logger.info(f\"Processing message: {message}\")\n        if not self._should_cotroller_active():\n            logger.warning(f\"Controller for config_id {self._config_id} is not active\")\n            return\n\n        await self._rabbitmq_service.publish_message(\n            \"services\",\n            \"input-processing\",\n            json.dumps(json.loads(message.body.decode()))\n        )\n\n        event_input = await self._parse_event(message)\n        job_result = await self.job_dispatcher(event_input)\n        output = serialize_to_json(job_result)\n        logger.info(f\"sleeping for 5 seconds...\")\n        time.sleep(5)\n        logger.info(f\"Output: {output}\")\n        await self._rabbitmq_service.publish_message(\n                \"services\",\n                \"feedback\",\n                output\n            )\n        await message.ack()\n        await self._queue_active_jobs.get()\n        logger.info(\"Published message to service\")\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/controller/controller/#apps.services-bronze-layer.spark-batch.spark_batch_bronze.controller.controller.EventController.run","title":"<code>run(message)</code>  <code>async</code>","text":"<p>Run the EventController to process event data.</p> <p>This method initiates the processing of incoming event data using the specified controller logic.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <p>The incoming event message.</p> required Source code in <code>apps/services-bronze-layer/spark-batch/spark_batch_bronze/controller/controller.py</code> <pre><code>async def run(self, message) -&gt; None:\n    \"\"\"\n    Run the EventController to process event data.\n\n    This method initiates the processing of incoming event data using the specified controller logic.\n\n    Args:\n        message: The incoming event message.\n\n    \"\"\"\n    logger.info(f\"Processing message: {message}\")\n    if not self._should_cotroller_active():\n        logger.warning(f\"Controller for config_id {self._config_id} is not active\")\n        return\n\n    await self._rabbitmq_service.publish_message(\n        \"services\",\n        \"input-processing\",\n        json.dumps(json.loads(message.body.decode()))\n    )\n\n    event_input = await self._parse_event(message)\n    job_result = await self.job_dispatcher(event_input)\n    output = serialize_to_json(job_result)\n    logger.info(f\"sleeping for 5 seconds...\")\n    time.sleep(5)\n    logger.info(f\"Output: {output}\")\n    await self._rabbitmq_service.publish_message(\n            \"services\",\n            \"feedback\",\n            output\n        )\n    await message.ack()\n    await self._queue_active_jobs.get()\n    logger.info(\"Published message to service\")\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/jobs/job_handler/","title":"Job handler","text":""},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/jobs/job_handler/#apps.services-bronze-layer.spark-batch.spark_batch_bronze.jobs.job_handler.JobHandler","title":"<code>JobHandler</code>","text":"<p>Represents a job handler that runs a specific job based on configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data for the job handler.</p> required <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>The configuration data for the job handler.</p> <code>_job_handler</code> <code>str</code> <p>The name of the job handler.</p> <code>_config_id</code> <code>int</code> <p>The unique identifier for the configuration.</p> <code>_module</code> <code>module</code> <p>The imported module for the specified job handler.</p> <p>Methods:</p> Name Description <code>_import_job_handler_as_module</code> <p>Imports the job handler module based on the provided configuration.</p> <code>run</code> <p>Runs the job associated with the configuration.</p> <p>Args:     source_input: The input data for the job.</p> <p>Returns:     tuple: A tuple containing job_data, job_status, and target_endpoint.</p> Source code in <code>apps/services-bronze-layer/spark-batch/spark_batch_bronze/jobs/job_handler.py</code> <pre><code>class JobHandler:\n    \"\"\"\n    Represents a job handler that runs a specific job based on configuration.\n\n    Args:\n        config (ConfigDTO): The configuration data for the job handler.\n\n    Attributes:\n        _config (ConfigDTO): The configuration data for the job handler.\n        _job_handler (str): The name of the job handler.\n        _config_id (int): The unique identifier for the configuration.\n        _module (module): The imported module for the specified job handler.\n\n    Methods:\n        _import_job_handler_as_module(self):\n            Imports the job handler module based on the provided configuration.\n\n        run(self, source_input):\n            Runs the job associated with the configuration.\n\n            Args:\n                source_input: The input data for the job.\n\n            Returns:\n                tuple: A tuple containing job_data, job_status, and target_endpoint.\n\n    \"\"\"\n\n    def __init__(self, config: ConfigDTO) -&gt; None:\n        self._config = config\n        self._job_handler = config.service_parameters[\"job_handler\"]\n        self._config_id = config.id\n        self._module = self._import_job_handler_as_module()\n\n    def _import_job_handler_as_module(self):\n        \"\"\"\n        Import the job handler module based on the specified job handler name.\n\n        Returns:\n            module: The imported module for the job handler.\n        \"\"\"\n        return importlib.import_module(f\"jobs.handlers.{self._job_handler}.job\")\n\n    async def run(self, source_input: type[warlock.model.Model]) -&gt; Tuple[dict, StatusDTO, str]:\n        \"\"\"\n        Run the job associated with the configuration.\n\n        Args:\n            source_input: The input data for the job.\n\n        Returns:\n            tuple: A tuple containing job_data, job_status, and target_endpoint.\n        \"\"\"\n        logger.info(f\"[RUNNING JOB] - Config ID: {self._config_id} - handler: {self._job_handler}\")\n        job_data, job_status, target_endpoint = await self._module.Job(self._config, source_input).run()\n        return job_data, job_status, target_endpoint\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/jobs/job_handler/#apps.services-bronze-layer.spark-batch.spark_batch_bronze.jobs.job_handler.JobHandler.run","title":"<code>run(source_input)</code>  <code>async</code>","text":"<p>Run the job associated with the configuration.</p> <p>Parameters:</p> Name Type Description Default <code>source_input</code> <code>type[Model]</code> <p>The input data for the job.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>Tuple[dict, StatusDTO, str]</code> <p>A tuple containing job_data, job_status, and target_endpoint.</p> Source code in <code>apps/services-bronze-layer/spark-batch/spark_batch_bronze/jobs/job_handler.py</code> <pre><code>async def run(self, source_input: type[warlock.model.Model]) -&gt; Tuple[dict, StatusDTO, str]:\n    \"\"\"\n    Run the job associated with the configuration.\n\n    Args:\n        source_input: The input data for the job.\n\n    Returns:\n        tuple: A tuple containing job_data, job_status, and target_endpoint.\n    \"\"\"\n    logger.info(f\"[RUNNING JOB] - Config ID: {self._config_id} - handler: {self._job_handler}\")\n    job_data, job_status, target_endpoint = await self._module.Job(self._config, source_input).run()\n    return job_data, job_status, target_endpoint\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/jobs/handlers/default/job/","title":"Job","text":""},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/jobs/handlers/default/job/#apps.services-bronze-layer.spark-batch.spark_batch_bronze.jobs.handlers.default.job.FieldsDTO","title":"<code>FieldsDTO</code>  <code>dataclass</code>","text":"<p>Data class representing fields for a DTO.</p> <p>Attributes:</p> Name Type Description <code>file_names</code> <code>List[str]</code> <p>List of file names.</p> <code>job_name</code> <code>str</code> <p>Name of the job.</p> Source code in <code>apps/services-bronze-layer/spark-batch/spark_batch_bronze/jobs/handlers/default/job.py</code> <pre><code>@dataclass\nclass FieldsDTO:\n    \"\"\"\n    Data class representing fields for a DTO.\n\n    Attributes:\n        file_names (List[str]): List of file names.\n        job_name (str): Name of the job.\n    \"\"\"\n    file_names: List[str] = field(metadata={\"json_name\": \"file_names\"})\n    job_name: str = field(metadata={\"json_name\": \"job_name\"})\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/jobs/handlers/default/job/#apps.services-bronze-layer.spark-batch.spark_batch_bronze.jobs.handlers.default.job.MappingHeaderDTO","title":"<code>MappingHeaderDTO</code>  <code>dataclass</code>","text":"<p>Data class representing mapping headers for a DTO.</p> <p>Attributes:</p> Name Type Description <code>properties</code> <code>List[FieldsDTO]</code> <p>List of FieldsDTO representing properties.</p> Source code in <code>apps/services-bronze-layer/spark-batch/spark_batch_bronze/jobs/handlers/default/job.py</code> <pre><code>@dataclass\nclass MappingHeaderDTO:\n    \"\"\"\n    Data class representing mapping headers for a DTO.\n\n    Attributes:\n        properties (List[FieldsDTO]): List of FieldsDTO representing properties.\n    \"\"\"\n    properties: List[FieldsDTO] = field(metadata={\"json_name\": \"properties\"})\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/jobs/handlers/default/job/#apps.services-bronze-layer.spark-batch.spark_batch_bronze.jobs.handlers.default.job.Job","title":"<code>Job</code>","text":"<p>Class representing a job.</p> <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>Configuration data transfer object.</p> <code>_service</code> <code>str</code> <p>Service name.</p> <code>_source</code> <code>str</code> <p>Source name.</p> <code>_context</code> <code>str</code> <p>Context information.</p> <code>_input_data</code> <code>Model</code> <p>Input data model.</p> <code>_partition</code> <code>str</code> <p>Data partition.</p> <code>_file_catalog_handler_client</code> <p>File catalog handler client.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>Initializes the Job instance.</p> <code>_get_mapping_headers_from_catalog_metadata</code> <p>Retrieves mapping headers from catalog metadata.</p> <code>_get_bucket_name</code> <p>Generates the bucket name for Minio storage.</p> <code>_get_status</code> <p>Gets the status data transfer object.</p> <code>run</code> <p>Executes the job and returns results.</p> Source code in <code>apps/services-bronze-layer/spark-batch/spark_batch_bronze/jobs/handlers/default/job.py</code> <pre><code>class Job:\n    \"\"\"\n    Class representing a job.\n\n    Attributes:\n        _config (ConfigDTO): Configuration data transfer object.\n        _service (str): Service name.\n        _source (str): Source name.\n        _context (str): Context information.\n        _input_data (warlock.model.Model): Input data model.\n        _partition (str): Data partition.\n        _file_catalog_handler_client: File catalog handler client.\n\n    Methods:\n        __init__: Initializes the Job instance.\n        _get_mapping_headers_from_catalog_metadata: Retrieves mapping headers from catalog metadata.\n        _get_bucket_name: Generates the bucket name for Minio storage.\n        _get_status: Gets the status data transfer object.\n        run: Executes the job and returns results.\n\n    \"\"\"\n\n    def __init__(self, config: ConfigDTO, input_data: type[warlock.model.Model]) -&gt; None:\n        \"\"\"\n        Initializes the Job instance.\n\n        Args:\n            config (ConfigDTO): Configuration data transfer object.\n            input_data (type[warlock.model.Model]): Input data model.\n        \"\"\"\n        self._config = config\n        self._service = config.service\n        self._source = config.source\n        self._context = config.context\n        self._input_data = input_data\n        self._partition = input_data.partition\n        self._file_catalog_handler_client = async_py_file_catalog_handler_client()\n\n    async def _get_mapping_headers_from_catalog_metadata(self):\n        \"\"\"\n        Retrieves mapping headers from catalog metadata.\n\n        Returns:\n            MappingHeaderDTO: Mapping headers data transfer object.\n        \"\"\"\n        job_catalog = await self._file_catalog_handler_client.list_one_file_catalog_by_service_source(\n            service_name=self._service,\n            source_name=self._source\n        )\n        mapping_header = job_catalog.catalog\n        return serialize_to_dataclass(mapping_header, MappingHeaderDTO)\n\n    def _get_bucket_name(self) -&gt; str:\n        \"\"\"\n        Generates the bucket name for Minio storage.\n\n        Returns:\n            str: The bucket name.\n        \"\"\"\n        return \"s3a://bronze-{context}-source-{source}\".format(\n            context=self._context,\n            source=self._source,\n        )\n\n    def _get_status(self) -&gt; StatusDTO:\n        \"\"\"\n        Gets the status data transfer object.\n\n        Returns:\n            StatusDTO: Status data transfer object.\n        \"\"\"\n        return StatusDTO(\n            code=200,\n            detail=\"Success\",\n        )\n\n    async def run(self) -&gt; Tuple[dict, StatusDTO, str]:\n        \"\"\"\n        Executes the job and returns results.\n\n        Returns:\n            Tuple[dict, StatusDTO, str]: Tuple containing results, status, and URI.\n        \"\"\"\n        mapping_headers = await self._get_mapping_headers_from_catalog_metadata()\n        logger.info(f\"Mapping headers: {mapping_headers}\")\n        uri = self._input_data.documentUri\n        logger.info(f\"Input data uri: {uri}\")\n        logger.info(f\"Input data partition: {self._partition}\")\n        logger.info(\"[SPARK-CONNECT] Creating REMOTE Spark Session...\")\n        bucket_name = self._get_bucket_name()\n        spark_session = (\n            SparkSession\n            .builder\n            .remote(\"sc://spark:15002\")\n            .config(\"log4j.logger.org.apache.hadoop.metrics2\", \"WARN\")\n            # .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n            .config('spark.sql.catalog.nessie', 'org.apache.iceberg.spark.SparkCatalog')\n            .config('spark.sql.catalog.nessie.uri', \"http://nessie:19120/api/v1\")\n            .config('spark.sql.catalog.nessie.ref', 'main')\n            .config('spark.sql.catalog.nessie.authentication.type', 'NONE')\n            .config('spark.sql.catalog.nessie.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')\n            .config('spark.sql.catalog.nessie.s3.endpoint', \"http://minio:9000\")\n            .config('spark.sql.catalog.nessie.warehouse', \"s3a://warehouse/\")\n            .config('spark.sql.catalog.nessie.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')\n            .config(\"spark.hadoop.fs.s3a.access.key\", \"LyID4OINwyehOpzOIGp6\")\n            .config(\"spark.hadoop.fs.s3a.secret.key\", \"QPRtbwCBFWo2oZnKleFVnko44O78EMirFRSoZvzM\")\n            .getOrCreate()\n        )\n        logger.info(\"[SPARK-CONNECT] Spark Running...\")\n        logger.info(f\"Job triggered with input: {self._input_data}\")\n\n        # Sample data for the PySpark DataFrame\n        # data = [\n        #     {\"file_names\": \"file1.txt\", \"job_name\": \"example_job_1\"},\n        #     {\"file_names\": \"file2.txt\", \"job_name\": \"example_job_2\"},\n        #     {\"file_names\": \"file3.txt\", \"job_name\": \"example_job_3\"},\n        # ]\n\n        # df = spark_session.createDataFrame(data)\n        # logger.info(f\"Dummy dataframe lazy: {df}\")\n        # logger.info(f\"Dummy dataframe: {df.show()}\")\n\n        logger.info(\"Spark Running\")\n        ## Create a Table\n        spark_session.sql(\"CREATE TABLE nessie.names (name STRING) USING iceberg;\").show()\n        ## Insert Some Data\n        spark_session.sql(\"INSERT INTO nessie.names VALUES ('Alex Merced'), ('Dipankar Mazumdar'), ('Jason Hughes')\").show()\n        ## Query the Data\n        logger.info(f'loging nessie df: {spark_session.sql(\"SELECT * FROM nessie.names;\").show()}')\n\n        df = spark_session.read.csv(uri, header=True, inferSchema=True)\n        logger.info(f\"dataframe lazy: {df}\")\n        logger.info(f\"dataframe: {df.show()}\")\n\n\n\n        result = {\"documentUri\": \"uri\", \"partition\": self._partition}\n        spark_session.stop()\n        return result, self._get_status(), uri\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/jobs/handlers/default/job/#apps.services-bronze-layer.spark-batch.spark_batch_bronze.jobs.handlers.default.job.Job.__init__","title":"<code>__init__(config, input_data)</code>","text":"<p>Initializes the Job instance.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>Configuration data transfer object.</p> required <code>input_data</code> <code>type[Model]</code> <p>Input data model.</p> required Source code in <code>apps/services-bronze-layer/spark-batch/spark_batch_bronze/jobs/handlers/default/job.py</code> <pre><code>def __init__(self, config: ConfigDTO, input_data: type[warlock.model.Model]) -&gt; None:\n    \"\"\"\n    Initializes the Job instance.\n\n    Args:\n        config (ConfigDTO): Configuration data transfer object.\n        input_data (type[warlock.model.Model]): Input data model.\n    \"\"\"\n    self._config = config\n    self._service = config.service\n    self._source = config.source\n    self._context = config.context\n    self._input_data = input_data\n    self._partition = input_data.partition\n    self._file_catalog_handler_client = async_py_file_catalog_handler_client()\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/spark-batch/code_reference/spark_batch_bronze/jobs/handlers/default/job/#apps.services-bronze-layer.spark-batch.spark_batch_bronze.jobs.handlers.default.job.Job.run","title":"<code>run()</code>  <code>async</code>","text":"<p>Executes the job and returns results.</p> <p>Returns:</p> Type Description <code>Tuple[dict, StatusDTO, str]</code> <p>Tuple[dict, StatusDTO, str]: Tuple containing results, status, and URI.</p> Source code in <code>apps/services-bronze-layer/spark-batch/spark_batch_bronze/jobs/handlers/default/job.py</code> <pre><code>async def run(self) -&gt; Tuple[dict, StatusDTO, str]:\n    \"\"\"\n    Executes the job and returns results.\n\n    Returns:\n        Tuple[dict, StatusDTO, str]: Tuple containing results, status, and URI.\n    \"\"\"\n    mapping_headers = await self._get_mapping_headers_from_catalog_metadata()\n    logger.info(f\"Mapping headers: {mapping_headers}\")\n    uri = self._input_data.documentUri\n    logger.info(f\"Input data uri: {uri}\")\n    logger.info(f\"Input data partition: {self._partition}\")\n    logger.info(\"[SPARK-CONNECT] Creating REMOTE Spark Session...\")\n    bucket_name = self._get_bucket_name()\n    spark_session = (\n        SparkSession\n        .builder\n        .remote(\"sc://spark:15002\")\n        .config(\"log4j.logger.org.apache.hadoop.metrics2\", \"WARN\")\n        # .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n        .config('spark.sql.catalog.nessie', 'org.apache.iceberg.spark.SparkCatalog')\n        .config('spark.sql.catalog.nessie.uri', \"http://nessie:19120/api/v1\")\n        .config('spark.sql.catalog.nessie.ref', 'main')\n        .config('spark.sql.catalog.nessie.authentication.type', 'NONE')\n        .config('spark.sql.catalog.nessie.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')\n        .config('spark.sql.catalog.nessie.s3.endpoint', \"http://minio:9000\")\n        .config('spark.sql.catalog.nessie.warehouse', \"s3a://warehouse/\")\n        .config('spark.sql.catalog.nessie.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')\n        .config(\"spark.hadoop.fs.s3a.access.key\", \"LyID4OINwyehOpzOIGp6\")\n        .config(\"spark.hadoop.fs.s3a.secret.key\", \"QPRtbwCBFWo2oZnKleFVnko44O78EMirFRSoZvzM\")\n        .getOrCreate()\n    )\n    logger.info(\"[SPARK-CONNECT] Spark Running...\")\n    logger.info(f\"Job triggered with input: {self._input_data}\")\n\n    # Sample data for the PySpark DataFrame\n    # data = [\n    #     {\"file_names\": \"file1.txt\", \"job_name\": \"example_job_1\"},\n    #     {\"file_names\": \"file2.txt\", \"job_name\": \"example_job_2\"},\n    #     {\"file_names\": \"file3.txt\", \"job_name\": \"example_job_3\"},\n    # ]\n\n    # df = spark_session.createDataFrame(data)\n    # logger.info(f\"Dummy dataframe lazy: {df}\")\n    # logger.info(f\"Dummy dataframe: {df.show()}\")\n\n    logger.info(\"Spark Running\")\n    ## Create a Table\n    spark_session.sql(\"CREATE TABLE nessie.names (name STRING) USING iceberg;\").show()\n    ## Insert Some Data\n    spark_session.sql(\"INSERT INTO nessie.names VALUES ('Alex Merced'), ('Dipankar Mazumdar'), ('Jason Hughes')\").show()\n    ## Query the Data\n    logger.info(f'loging nessie df: {spark_session.sql(\"SELECT * FROM nessie.names;\").show()}')\n\n    df = spark_session.read.csv(uri, header=True, inferSchema=True)\n    logger.info(f\"dataframe lazy: {df}\")\n    logger.info(f\"dataframe: {df.show()}\")\n\n\n\n    result = {\"documentUri\": \"uri\", \"partition\": self._partition}\n    spark_session.stop()\n    return result, self._get_status(), uri\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/","title":"speech-transcriber","text":"<p><code>speech-transcriber</code> is a Python-based service that performs the following tasks:</p> <ul> <li>Get an Audio transcription from aa audio of a specific source in a event approach.</li> <li>Store the Audio in a bucket (bronze layer).</li> <li>Publishes the bucket location to a message queue for further consumption.</li> </ul>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/#service-components","title":"Service Components","text":"<p>The service consists of multiple Python modules and classes, each serving a specific purpose. Here's an overview of these components:</p>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/#main-module","title":"Main Module","text":"<ul> <li><code>main.py</code>: The entry point of the service.</li> <li>It initializes various configurations, including the service name and context environment.</li> <li>Creates consumers for specific configurations and starts processing data.</li> <li>Each config has it owns queue consumption.</li> </ul>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/#consumer-module","title":"Consumer Module","text":"<ul> <li><code>speech_transcriber/consumer/consumer.py</code>: Contains the <code>EventConsumer</code> class responsible for consume an input message and trigger the callback.</li> <li>This class listens to a RabbitMQ queue, processes incoming data, and trigger the results to the controller.</li> </ul>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/#controller-module","title":"Controller Module","text":"<ul> <li> <p><code>speech_transcriber/controller/controller.py</code>: This module contains the <code>EventController</code> class, which is responsible for handling the business logic related to event processing.</p> </li> <li> <p>The <code>EventController</code> class receives the processed data from the <code>EventConsumer</code>.</p> </li> <li>It checks if the controller should be active based on the configuration.</li> <li>If active, it parses and processes the data using the job handler.</li> <li>It triggers the job dispatcher to execute the job and collect the results.</li> <li>It publishes the results, including the storage URI, to a message queue for further consumption.</li> </ul> <p>The <code>EventController</code> class plays a crucial role in orchestrating the event-driven processing of data within the service.</p> <p>This class ensures that the service processes incoming data efficiently, initiates the appropriate job handler for the task, and communicates the results to the relevant channels.</p>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/#job-handling-module","title":"Job Handling Module","text":"<ul> <li><code>speech_transcriber/jobs/job_handler.py</code>: Handles the execution of jobs related to downloading and storing the file in a bucket.</li> <li>It uses a specific job handler module based on the configuration.</li> </ul>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/#job-handler-module","title":"Job Handler Module","text":""},{"location":"reference/apps/services-bronze-layer/speech-transcriber/#audio-to-text-handler","title":"Audio To Text Handler","text":"<ul> <li><code>jobs/handlers/audio_to_text/job.py</code>: An example job handler module.</li> <li>It defines the logic for extracting the audio transcription with a generative IA approach.</li> <li>It uploads the transcription data to a Minio storage bucket.</li> <li>It returns the job result, including the storage URI and status.</li> </ul>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/#libraries-dependencies","title":"Libraries Dependencies:","text":""},{"location":"reference/apps/services-bronze-layer/speech-transcriber/#configuration-module","title":"Configuration Module","text":"<ul> <li><code>config_loader</code>: Loads configurations for the service, such as the source, job handler, service parameters and job parameters also.</li> </ul>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/#rabbitmq-module","title":"RabbitMQ Module","text":"<ul> <li><code>pyrabbitmq</code>: Handles the interaction with RabbitMQ, including creating channels, queues, and publishing messages.</li> </ul>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/#service-discovery-module","title":"Service Discovery Module","text":"<ul> <li><code>pysd</code>: Manages service discovery and RabbitMQ endpoints.</li> </ul>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/#architecture-diagram","title":"Architecture Diagram","text":""},{"location":"reference/apps/services-bronze-layer/speech-transcriber/#c4-diagram","title":"C4 Diagram","text":""},{"location":"reference/apps/services-bronze-layer/speech-transcriber/#service-diagram","title":"Service Diagram","text":""},{"location":"reference/apps/services-bronze-layer/speech-transcriber/#how-to-run-the-service","title":"How to Run the Service","text":"<p>To run your service, follow these steps:</p> <ol> <li> <p>Setup Configuration:</p> <ul> <li>Create a <code>.env.{ENVIRONMENT}</code> file based on the example provided in the <code>envs</code> folder.</li> </ul> </li> <li> <p>Build The Service:</p> </li> </ol> <pre><code>npx nx image services-bronze-layer-speech-transcriber --env=&lt;ENVIRONMENT&gt;\n</code></pre> <ol> <li>Run the Application:</li> </ol> <pre><code>docker-compose up -d\n</code></pre> <p>Please note that this README provides a high-level overview of your service's structure and components. To run the service effectively, make sure to provide the required configurations and customize the job handler logic according to your specific use case.</p> <p>If you have any questions or need further assistance, feel free to ask.</p>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/consumer/consumer/","title":"Consumer","text":""},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/consumer/consumer/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.consumer.consumer.Consumer","title":"<code>Consumer</code>","text":"<p>The base class for creating data consumers.</p> <p>Parameters:</p> Name Type Description Default <code>sd</code> <code>ServiceDiscovery</code> <p>An instance of the ServiceDiscovery class.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <code>transcription_pipeline</code> <code>pipeline</code> <p>The pipeline for automatic speech recognition.</p> required Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/consumer/consumer.py</code> <pre><code>class Consumer:\n    \"\"\"\n    The base class for creating data consumers.\n\n    Args:\n        sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        transcription_pipeline (pipeline): The pipeline for automatic speech recognition.\n\n    \"\"\"\n    def __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue, transcription_pipeline: pipeline):\n        \"\"\"\n        Initialize the Consumer instance.\n\n        Args:\n            sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n            rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n            config (ConfigDTO): The configuration data.\n            queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n            transcription_pipeline (pipeline): The pipeline for automatic speech recognition.\n\n        Returns:\n            None\n        \"\"\"\n        self._config = config\n        self._rabbitmq_service = rabbitmq_service\n        self._queue_active_jobs = queue_active_jobs\n        self._transcription_pipeline = transcription_pipeline\n        self._exchange_name = sd.services_rabbitmq_exchange()\n        self._queue_name = _get_queue_name(config)\n        self._routing_key = _get_routing_key(config)\n\n    async def _run(self, controller: callable) -&gt; None:\n        \"\"\"\n        Run the consumer with the specified controller.\n\n        Args:\n            controller (callable): The controller class responsible for processing data.\n\n        Returns:\n            None\n        \"\"\"\n        channel = await self._rabbitmq_service.create_channel()\n        queue = await self._rabbitmq_service.create_queue(\n            channel,\n            self._queue_name,\n            self._exchange_name,\n            self._routing_key\n        )\n        logger.info(f\"Listening to queue: {self._queue_name}\")\n        await self._rabbitmq_service.listen(queue, controller(self._config, self._rabbitmq_service, self._queue_active_jobs, self._transcription_pipeline).run)\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/consumer/consumer/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.consumer.consumer.Consumer.__init__","title":"<code>__init__(sd, rabbitmq_service, config, queue_active_jobs, transcription_pipeline)</code>","text":"<p>Initialize the Consumer instance.</p> <p>Parameters:</p> Name Type Description Default <code>sd</code> <code>ServiceDiscovery</code> <p>An instance of the ServiceDiscovery class.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <code>transcription_pipeline</code> <code>pipeline</code> <p>The pipeline for automatic speech recognition.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/consumer/consumer.py</code> <pre><code>def __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue, transcription_pipeline: pipeline):\n    \"\"\"\n    Initialize the Consumer instance.\n\n    Args:\n        sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        transcription_pipeline (pipeline): The pipeline for automatic speech recognition.\n\n    Returns:\n        None\n    \"\"\"\n    self._config = config\n    self._rabbitmq_service = rabbitmq_service\n    self._queue_active_jobs = queue_active_jobs\n    self._transcription_pipeline = transcription_pipeline\n    self._exchange_name = sd.services_rabbitmq_exchange()\n    self._queue_name = _get_queue_name(config)\n    self._routing_key = _get_routing_key(config)\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/consumer/consumer/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.consumer.consumer.EventConsumer","title":"<code>EventConsumer</code>","text":"<p>             Bases: <code>Consumer</code></p> <p>The EventConsumer class for processing event data.</p> <p>Parameters:</p> Name Type Description Default <code>sd</code> <code>ServiceDiscovery</code> <p>An instance of the ServiceDiscovery class.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <code>transcription_pipeline</code> <code>pipeline</code> <p>The pipeline for automatic speech recognition.</p> required Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/consumer/consumer.py</code> <pre><code>class EventConsumer(Consumer):\n    \"\"\"\n    The EventConsumer class for processing event data.\n\n    Args:\n        sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        transcription_pipeline (pipeline): The pipeline for automatic speech recognition.\n\n    \"\"\"\n    def __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue, transcription_pipeline: pipeline):\n        \"\"\"\n        Initialize the EventConsumer instance.\n\n        Args:\n            sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n            rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n            config (ConfigDTO): The configuration data.\n            queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n            transcription_pipeline (pipeline): The pipeline for automatic speech recognition.\n\n        Returns:\n            None\n        \"\"\"\n        super().__init__(sd, rabbitmq_service, config, queue_active_jobs, transcription_pipeline)\n\n    async def run(self) -&gt; None:\n        \"\"\"\n        Run the EventConsumer to process event data.\n\n        This method triggers the processing of incoming event data using the specified controller.\n\n        Returns:\n            None\n        \"\"\"\n        await self._run(EventController)\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/consumer/consumer/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.consumer.consumer.EventConsumer.__init__","title":"<code>__init__(sd, rabbitmq_service, config, queue_active_jobs, transcription_pipeline)</code>","text":"<p>Initialize the EventConsumer instance.</p> <p>Parameters:</p> Name Type Description Default <code>sd</code> <code>ServiceDiscovery</code> <p>An instance of the ServiceDiscovery class.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <code>transcription_pipeline</code> <code>pipeline</code> <p>The pipeline for automatic speech recognition.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/consumer/consumer.py</code> <pre><code>def __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue, transcription_pipeline: pipeline):\n    \"\"\"\n    Initialize the EventConsumer instance.\n\n    Args:\n        sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        transcription_pipeline (pipeline): The pipeline for automatic speech recognition.\n\n    Returns:\n        None\n    \"\"\"\n    super().__init__(sd, rabbitmq_service, config, queue_active_jobs, transcription_pipeline)\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/consumer/consumer/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.consumer.consumer.EventConsumer.run","title":"<code>run()</code>  <code>async</code>","text":"<p>Run the EventConsumer to process event data.</p> <p>This method triggers the processing of incoming event data using the specified controller.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/consumer/consumer.py</code> <pre><code>async def run(self) -&gt; None:\n    \"\"\"\n    Run the EventConsumer to process event data.\n\n    This method triggers the processing of incoming event data using the specified controller.\n\n    Returns:\n        None\n    \"\"\"\n    await self._run(EventController)\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/controller/controller/","title":"Controller","text":""},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/controller/controller/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.controller.controller.Controller","title":"<code>Controller</code>","text":"<p>Base class for handling event data processing.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <code>transcription_pipeline</code> <code>pipeline</code> <p>The pipeline for automatic speech recognition.</p> required <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>The configuration data.</p> <code>_config_id</code> <code>str</code> <p>The ID associated with the configuration.</p> <code>_service_name</code> <code>str</code> <p>The service name from the configuration.</p> <code>_source_name</code> <code>str</code> <p>The source name from the configuration.</p> <code>_context_env</code> <code>str</code> <p>The context environment from the configuration.</p> <code>_repository_schema_type</code> <code>str</code> <p>The repository schema type for service input.</p> <code>_queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> <code>_active</code> <code>bool</code> <p>The activation status based on the configuration.</p> <code>_transcription_pipeline</code> <code>pipeline</code> <p>The pipeline for automatic speech recognition.</p> <code>_schema_handler_client</code> <p>The schema handler client for retrieving JSON schemas.</p> <code>_input_body_dto</code> <p>The input data DTO.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>ConfigDTO, queue_active_jobs: asyncio.Queue, transcription_pipeline: pipeline) -&gt; None: Initializes a Controller instance with the provided configuration, active jobs queue, and transcription pipeline.</p> <code>_should_controller_active</code> <p>Check if the controller should be active based on the configuration.</p> <code>async _get_event_parser</code> <p>Get the event parser JSON schema for data processing.</p> <code>async _parse_event</code> <p>str) -&gt; type[warlock.model.Model]: Parse the incoming event message and transform it into the appropriate data format.</p> <code>_get_metadata</code> <p>Generate metadata information for the processed event data.</p> <code>async job_dispatcher</code> <p>Dispatch a job to process the event input data and collect the results.</p> Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/controller/controller.py</code> <pre><code>class Controller:\n    \"\"\"\n    Base class for handling event data processing.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        transcription_pipeline (pipeline): The pipeline for automatic speech recognition.\n\n    Attributes:\n        _config (ConfigDTO): The configuration data.\n        _config_id (str): The ID associated with the configuration.\n        _service_name (str): The service name from the configuration.\n        _source_name (str): The source name from the configuration.\n        _context_env (str): The context environment from the configuration.\n        _repository_schema_type (str): The repository schema type for service input.\n        _queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        _active (bool): The activation status based on the configuration.\n        _transcription_pipeline (pipeline): The pipeline for automatic speech recognition.\n        _schema_handler_client: The schema handler client for retrieving JSON schemas.\n        _input_body_dto: The input data DTO.\n\n    Methods:\n        __init__(self, config: ConfigDTO, queue_active_jobs: asyncio.Queue, transcription_pipeline: pipeline) -&gt; None:\n            Initializes a Controller instance with the provided configuration, active jobs queue, and transcription pipeline.\n\n        _should_controller_active(self) -&gt; bool:\n            Check if the controller should be active based on the configuration.\n\n        async _get_event_parser(self) -&gt; Dict[str, any]:\n            Get the event parser JSON schema for data processing.\n\n        async _parse_event(self, message: str) -&gt; type[warlock.model.Model]:\n            Parse the incoming event message and transform it into the appropriate data format.\n\n        _get_metadata(self) -&gt; MetadataDTO:\n            Generate metadata information for the processed event data.\n\n        async job_dispatcher(self, event_input) -&gt; ServiceFeedbackDTO:\n            Dispatch a job to process the event input data and collect the results.\n    \"\"\"\n    def __init__(self, config: ConfigDTO, queue_active_jobs: asyncio.Queue, transcription_pipeline: pipeline):\n        \"\"\"\n        Initializes a Controller instance with the provided configuration, active jobs queue, and transcription pipeline.\n\n        Args:\n            config (ConfigDTO): The configuration data.\n            queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n            transcription_pipeline (pipeline): The pipeline for automatic speech recognition.\n\n        Returns:\n            None\n        \"\"\"\n        self._config = config\n        self._config_id = config.id\n        self._service_name = config.service\n        self._source_name = config.source\n        self._context_env = config.context\n        self._repository_schema_type = _REPOSITORY_SCHEMA_TYPE\n        self._queue_active_jobs = queue_active_jobs\n        self._active = config.active\n        self._transcription_pipeline = transcription_pipeline\n        self._schema_handler_client = async_py_schema_handler_client()\n        self._input_body_dto = None\n\n    def _should_controller_active(self) -&gt; bool:\n        \"\"\"\n        Check if the controller should be active based on the configuration.\n\n        Returns:\n            bool: True if the controller is active, False otherwise.\n\n        \"\"\"\n        if self._active:\n            return True\n        return False\n\n    async def _get_event_parser(self) -&gt; Dict[str, any]:\n        \"\"\"\n        Get the event parser JSON schema for data processing.\n\n        Returns:\n            Dict[str, any]: The JSON schema for data processing.\n\n        \"\"\"\n        self.schema_input = await self._schema_handler_client.list_one_schema_by_service_n_source_n_context_n_schema_type(\n            context=self._context_env,\n            service_name=self._service_name,\n            source_name=self._source_name,\n            schema_type=self._repository_schema_type\n        )\n        json_schema = self.schema_input.json_schema\n        return json_schema\n\n    async def _parse_event(self, message: str) -&gt; type[warlock.model.Model]:\n        \"\"\"\n        Parse the incoming event message and transform it into the appropriate data format.\n\n        Args:\n            message (str): The incoming event message.\n\n        Returns:\n            object: The parsed event data in the required data format.\n\n        Raises:\n            ValueError: If the message body cannot be parsed.\n\n        \"\"\"\n        message_body = message.body.decode()\n        event_parser_class = await self._get_event_parser()\n        try:\n            input_body = json.loads(message_body)\n            self._input_body_dto = serialize_to_dataclass(input_body, InputDTO)\n\n            input_data = self._input_body_dto.data\n            Input_dataclass = warlock.model_factory(event_parser_class)\n            return Input_dataclass(**input_data)\n        except json.JSONDecodeError as e:\n            logger.error(f\"Failed to parse message body: {e}\")\n            raise ValueError(\"Invalid message body\")\n\n    def _get_metadata(self) -&gt; MetadataDTO:\n        \"\"\"\n        Generate metadata information for the processed event data.\n\n        Returns:\n            MetadataDTO: Metadata information for the event data.\n\n        \"\"\"\n        return MetadataDTO(\n            input=MetadataInputDTO(\n                id=self._input_body_dto.id,\n                data=self._input_body_dto.data,\n                processing_id=self._input_body_dto.metadata[\"processing_id\"],\n                processing_timestamp=self._input_body_dto.metadata[\"processing_timestamp\"],\n                input_schema_id=self.schema_input.schema_id\n            ),\n            context=self._config.context,\n            service=self._config.service,\n            source=self._config.source,\n            processing_timestamp=datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n            job_frequency=self._config.frequency,\n            job_config_id=self._config.config_id,\n        )\n\n    async def job_dispatcher(self, event_input) -&gt; ServiceFeedbackDTO:\n        \"\"\"\n        Dispatch a job to process the event input data and collect the results.\n\n        Args:\n            event_input: The input data for the job.\n\n        Returns:\n            ServiceFeedbackDTO: Feedback and result information from the job processing.\n\n        \"\"\"\n        await self._queue_active_jobs.put(1)\n        job_data, status_data = JobHandler(self._config, self._transcription_pipeline ).run(event_input)\n        return ServiceFeedbackDTO(\n            data=job_data,\n            metadata=self._get_metadata(),\n            status=status_data,\n        )\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/controller/controller/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.controller.controller.Controller.__init__","title":"<code>__init__(config, queue_active_jobs, transcription_pipeline)</code>","text":"<p>Initializes a Controller instance with the provided configuration, active jobs queue, and transcription pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <code>transcription_pipeline</code> <code>pipeline</code> <p>The pipeline for automatic speech recognition.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/controller/controller.py</code> <pre><code>def __init__(self, config: ConfigDTO, queue_active_jobs: asyncio.Queue, transcription_pipeline: pipeline):\n    \"\"\"\n    Initializes a Controller instance with the provided configuration, active jobs queue, and transcription pipeline.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        transcription_pipeline (pipeline): The pipeline for automatic speech recognition.\n\n    Returns:\n        None\n    \"\"\"\n    self._config = config\n    self._config_id = config.id\n    self._service_name = config.service\n    self._source_name = config.source\n    self._context_env = config.context\n    self._repository_schema_type = _REPOSITORY_SCHEMA_TYPE\n    self._queue_active_jobs = queue_active_jobs\n    self._active = config.active\n    self._transcription_pipeline = transcription_pipeline\n    self._schema_handler_client = async_py_schema_handler_client()\n    self._input_body_dto = None\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/controller/controller/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.controller.controller.Controller.job_dispatcher","title":"<code>job_dispatcher(event_input)</code>  <code>async</code>","text":"<p>Dispatch a job to process the event input data and collect the results.</p> <p>Parameters:</p> Name Type Description Default <code>event_input</code> <p>The input data for the job.</p> required <p>Returns:</p> Name Type Description <code>ServiceFeedbackDTO</code> <code>ServiceFeedbackDTO</code> <p>Feedback and result information from the job processing.</p> Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/controller/controller.py</code> <pre><code>async def job_dispatcher(self, event_input) -&gt; ServiceFeedbackDTO:\n    \"\"\"\n    Dispatch a job to process the event input data and collect the results.\n\n    Args:\n        event_input: The input data for the job.\n\n    Returns:\n        ServiceFeedbackDTO: Feedback and result information from the job processing.\n\n    \"\"\"\n    await self._queue_active_jobs.put(1)\n    job_data, status_data = JobHandler(self._config, self._transcription_pipeline ).run(event_input)\n    return ServiceFeedbackDTO(\n        data=job_data,\n        metadata=self._get_metadata(),\n        status=status_data,\n    )\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/controller/controller/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.controller.controller.EventController","title":"<code>EventController</code>","text":"<p>             Bases: <code>Controller</code></p> <p>EventController class for processing event data.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <code>transcription_pipeline</code> <code>pipeline</code> <p>The pipeline for automatic speech recognition.</p> required <p>Methods:</p> Name Description <code>__init__</code> <p>ConfigDTO, rabbitmq_service: RabbitMQConsumer, queue_active_jobs: asyncio.Queue, transcription_pipeline: pipeline) -&gt; None: Initializes an EventController instance with the provided configuration, RabbitMQ service, active jobs queue, and transcription pipeline.</p> <code>async run</code> <p>Run the EventController to process event data.</p> <p>This method initiates the processing of incoming event data using the specified controller logic.</p> <p>Args:     message: The incoming event message.</p> Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/controller/controller.py</code> <pre><code>class EventController(Controller):\n    \"\"\"\n    EventController class for processing event data.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        transcription_pipeline (pipeline): The pipeline for automatic speech recognition.\n\n    Methods:\n        __init__(self, config: ConfigDTO, rabbitmq_service: RabbitMQConsumer, queue_active_jobs: asyncio.Queue, transcription_pipeline: pipeline) -&gt; None:\n            Initializes an EventController instance with the provided configuration, RabbitMQ service, active jobs queue, and transcription pipeline.\n\n        async run(self, message) -&gt; None:\n            Run the EventController to process event data.\n\n            This method initiates the processing of incoming event data using the specified controller logic.\n\n            Args:\n                message: The incoming event message.\n    \"\"\"\n    def __init__(self, config: ConfigDTO, rabbitmq_service: RabbitMQConsumer, queue_active_jobs: asyncio.Queue, transcription_pipeline: pipeline) -&gt; None:\n        \"\"\"\n        Initialize the EventController instance.\n\n        Args:\n            config (ConfigDTO): The configuration data.\n            rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n            queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n            transcription_pipeline (pipeline): The pipeline for automatic speech recognition.\n\n        Returns:\n            None\n        \"\"\"\n        self._rabbitmq_service = rabbitmq_service\n        super().__init__(config, queue_active_jobs, transcription_pipeline)\n\n    async def run(self, message) -&gt; None:\n        \"\"\"\n        Run the EventController to process event data.\n\n        This method initiates the processing of incoming event data using the specified controller logic.\n\n        Args:\n            message: The incoming event message.\n\n        Returns:\n            None\n        \"\"\"\n        logger.info(f\"Processing message: {message}\")\n        if not self._should_controller_active():\n            logger.warning(f\"Controller for config_id {self._config_id} is not active\")\n            return\n\n        await self._rabbitmq_service.publish_message(\n            \"services\",\n            \"input-processing\",\n            json.dumps(json.loads(message.body.decode()))\n        )\n\n        event_input = await self._parse_event(message)\n        job_result = await self.job_dispatcher(event_input)\n        output = serialize_to_json(job_result)\n        logger.info(f\"sleeping for 5 seconds...\")\n        time.sleep(5)\n        logger.info(f\"Output: {output}\")\n        await self._rabbitmq_service.publish_message(\n                \"services\",\n                \"feedback\",\n                output\n            )\n        await message.ack()\n        await self._queue_active_jobs.get()\n        logger.info(\"Published message to service\")\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/controller/controller/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.controller.controller.EventController.__init__","title":"<code>__init__(config, rabbitmq_service, queue_active_jobs, transcription_pipeline)</code>","text":"<p>Initialize the EventController instance.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <code>transcription_pipeline</code> <code>pipeline</code> <p>The pipeline for automatic speech recognition.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/controller/controller.py</code> <pre><code>def __init__(self, config: ConfigDTO, rabbitmq_service: RabbitMQConsumer, queue_active_jobs: asyncio.Queue, transcription_pipeline: pipeline) -&gt; None:\n    \"\"\"\n    Initialize the EventController instance.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        transcription_pipeline (pipeline): The pipeline for automatic speech recognition.\n\n    Returns:\n        None\n    \"\"\"\n    self._rabbitmq_service = rabbitmq_service\n    super().__init__(config, queue_active_jobs, transcription_pipeline)\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/controller/controller/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.controller.controller.EventController.run","title":"<code>run(message)</code>  <code>async</code>","text":"<p>Run the EventController to process event data.</p> <p>This method initiates the processing of incoming event data using the specified controller logic.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <p>The incoming event message.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/controller/controller.py</code> <pre><code>async def run(self, message) -&gt; None:\n    \"\"\"\n    Run the EventController to process event data.\n\n    This method initiates the processing of incoming event data using the specified controller logic.\n\n    Args:\n        message: The incoming event message.\n\n    Returns:\n        None\n    \"\"\"\n    logger.info(f\"Processing message: {message}\")\n    if not self._should_controller_active():\n        logger.warning(f\"Controller for config_id {self._config_id} is not active\")\n        return\n\n    await self._rabbitmq_service.publish_message(\n        \"services\",\n        \"input-processing\",\n        json.dumps(json.loads(message.body.decode()))\n    )\n\n    event_input = await self._parse_event(message)\n    job_result = await self.job_dispatcher(event_input)\n    output = serialize_to_json(job_result)\n    logger.info(f\"sleeping for 5 seconds...\")\n    time.sleep(5)\n    logger.info(f\"Output: {output}\")\n    await self._rabbitmq_service.publish_message(\n            \"services\",\n            \"feedback\",\n            output\n        )\n    await message.ack()\n    await self._queue_active_jobs.get()\n    logger.info(\"Published message to service\")\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/jobs/job_handler/","title":"Job handler","text":""},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/jobs/job_handler/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.jobs.job_handler.JobHandler","title":"<code>JobHandler</code>","text":"<p>Represents a job handler that runs a specific job based on configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data for the job handler.</p> required <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>The configuration data for the job handler.</p> <code>_job_handler</code> <code>str</code> <p>The name of the job handler.</p> <code>_config_id</code> <code>int</code> <p>The unique identifier for the configuration.</p> <code>_module</code> <code>module</code> <p>The imported module for the specified job handler.</p> <p>Methods:</p> Name Description <code>_import_job_handler_as_module</code> <p>Imports the job handler module based on the provided configuration.</p> <code>run</code> <p>type[warlock.model.Model]) -&gt; Tuple[dict, StatusDTO, str]: Runs the job associated with the configuration.</p> <p>Args:     source_input (type[warlock.model.Model]): The input data for the job.</p> <p>Returns:     Tuple[dict, StatusDTO, str]: A tuple containing job_data, job_status, and target_endpoint.</p> Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/jobs/job_handler.py</code> <pre><code>class JobHandler:\n    \"\"\"\n    Represents a job handler that runs a specific job based on configuration.\n\n    Args:\n        config (ConfigDTO): The configuration data for the job handler.\n\n    Attributes:\n        _config (ConfigDTO): The configuration data for the job handler.\n        _job_handler (str): The name of the job handler.\n        _config_id (int): The unique identifier for the configuration.\n        _module (module): The imported module for the specified job handler.\n\n    Methods:\n        _import_job_handler_as_module(self) -&gt; module:\n            Imports the job handler module based on the provided configuration.\n\n        run(self, source_input: type[warlock.model.Model]) -&gt; Tuple[dict, StatusDTO, str]:\n            Runs the job associated with the configuration.\n\n            Args:\n                source_input (type[warlock.model.Model]): The input data for the job.\n\n            Returns:\n                Tuple[dict, StatusDTO, str]: A tuple containing job_data, job_status, and target_endpoint.\n    \"\"\"\n    def __init__(self, config: ConfigDTO, transcription_pipeline: pipeline) -&gt; None:\n        \"\"\"\n        Initialize the JobHandler instance.\n\n        Args:\n            config (ConfigDTO): The configuration data for the job handler.\n            transcription_pipeline (pipeline): The pipeline for automatic speech recognition.\n\n        Returns:\n            None\n        \"\"\"\n        self._config = config\n        self._job_handler = config.service_parameters[\"job_handler\"]\n        self._config_id = config.id\n        self._transcription_pipeline = transcription_pipeline\n        self._module = self._import_job_handler_as_module()\n\n    def _import_job_handler_as_module(self):\n        \"\"\"\n        Import the job handler module based on the specified job handler name.\n\n        Returns:\n            module: The imported module for the job handler.\n        \"\"\"\n        return importlib.import_module(f\"jobs.handlers.{self._job_handler}.job\")\n\n    def run(self, source_input: type[warlock.model.Model]) -&gt; Tuple[dict, StatusDTO]:\n        \"\"\"\n        Run the job associated with the configuration.\n\n        Args:\n            source_input (type[warlock.model.Model]): The input data for the job.\n\n        Returns:\n            Tuple[dict, StatusDTO]: A tuple containing job_data and job_status.\n        \"\"\"\n        logger.info(f\"[RUNNING JOB] - Config ID: {self._config_id} - handler: {self._job_handler}\")\n        job_data, job_status = self._module.Job(self._config, source_input, self._transcription_pipeline).run()\n        return job_data, job_status\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/jobs/job_handler/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.jobs.job_handler.JobHandler.__init__","title":"<code>__init__(config, transcription_pipeline)</code>","text":"<p>Initialize the JobHandler instance.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data for the job handler.</p> required <code>transcription_pipeline</code> <code>pipeline</code> <p>The pipeline for automatic speech recognition.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/jobs/job_handler.py</code> <pre><code>def __init__(self, config: ConfigDTO, transcription_pipeline: pipeline) -&gt; None:\n    \"\"\"\n    Initialize the JobHandler instance.\n\n    Args:\n        config (ConfigDTO): The configuration data for the job handler.\n        transcription_pipeline (pipeline): The pipeline for automatic speech recognition.\n\n    Returns:\n        None\n    \"\"\"\n    self._config = config\n    self._job_handler = config.service_parameters[\"job_handler\"]\n    self._config_id = config.id\n    self._transcription_pipeline = transcription_pipeline\n    self._module = self._import_job_handler_as_module()\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/jobs/job_handler/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.jobs.job_handler.JobHandler.run","title":"<code>run(source_input)</code>","text":"<p>Run the job associated with the configuration.</p> <p>Parameters:</p> Name Type Description Default <code>source_input</code> <code>type[Model]</code> <p>The input data for the job.</p> required <p>Returns:</p> Type Description <code>Tuple[dict, StatusDTO]</code> <p>Tuple[dict, StatusDTO]: A tuple containing job_data and job_status.</p> Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/jobs/job_handler.py</code> <pre><code>def run(self, source_input: type[warlock.model.Model]) -&gt; Tuple[dict, StatusDTO]:\n    \"\"\"\n    Run the job associated with the configuration.\n\n    Args:\n        source_input (type[warlock.model.Model]): The input data for the job.\n\n    Returns:\n        Tuple[dict, StatusDTO]: A tuple containing job_data and job_status.\n    \"\"\"\n    logger.info(f\"[RUNNING JOB] - Config ID: {self._config_id} - handler: {self._job_handler}\")\n    job_data, job_status = self._module.Job(self._config, source_input, self._transcription_pipeline).run()\n    return job_data, job_status\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/jobs/handlers/audio_to_text/job/","title":"Job","text":""},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/jobs/handlers/audio_to_text/job/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.jobs.handlers.audio_to_text.job.Job","title":"<code>Job</code>","text":"<p>Represents a job that makes HTTP requests and handles the response.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data for the job.</p> required <code>input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> required <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>The configuration data for the job.</p> <code>_source</code> <code> (str</code> <p>The source information from the configuration.</p> <code>_context</code> <code>str</code> <p>The context information from the configuration.</p> <code>_input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> <code>_transcription_pipeline</code> <code>pipeline</code> <p>The pipeline for transcription.</p> <code>_partition</code> <code>str</code> <p>The partition based on video id.</p> <code>_target_endpoint</code> <code>str</code> <p>The final endpoint URL.</p> <p>Methods:</p> Name Description <code>_get_bucket_name</code> <p>str) -&gt; str: Generates the bucket name for Minio storage.</p> <code>_get_status</code> <p>Extracts the status information from an HTTP response.</p> <code>make_request</code> <p>MinioClient, audio_path: str) -&gt; bytes: Makes a request to Minio for audio data.</p> <code>run</code> <p>Runs the job, making the HTTP request and handling the response.</p> Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/jobs/handlers/audio_to_text/job.py</code> <pre><code>class Job:\n    \"\"\"\n    Represents a job that makes HTTP requests and handles the response.\n\n    Args:\n        config (ConfigDTO): The configuration data for the job.\n        input_data: The input data for the job.\n\n    Attributes:\n        _config (ConfigDTO): The configuration data for the job.\n        _source  (str): The source information from the configuration.\n        _context (str): The context information from the configuration.\n        _input_data (type[warlock.model.Model]): The input data for the job.\n        _transcription_pipeline (pipeline): The pipeline for transcription.\n        _partition (str): The partition based on video id.\n        _target_endpoint (str): The final endpoint URL.\n\n    Methods:\n        _get_bucket_name(self, layer: str) -&gt; str:\n            Generates the bucket name for Minio storage.\n\n        _get_status(self) -&gt; StatusDTO:\n            Extracts the status information from an HTTP response.\n\n        make_request(self, minio: MinioClient, audio_path: str) -&gt; bytes:\n            Makes a request to Minio for audio data.\n\n        run(self) -&gt; Tuple[dict, StatusDTO, str]:\n            Runs the job, making the HTTP request and handling the response.\n\n    \"\"\"\n    def __init__(self, config: ConfigDTO, input_data: type[warlock.model.Model], transcription_pipeline: pipeline) -&gt; None:\n        \"\"\"\n        Initialize the Job instance.\n\n        Args:\n            config (ConfigDTO): The configuration data for the job.\n            input_data (type[warlock.model.Model]): The input data for the job.\n            transcription_pipeline (pipeline): The pipeline for transcription.\n\n        Returns:\n            None\n        \"\"\"\n        self._config = config\n        self._source = config.source\n        self._context = config.context\n        self._input_data = input_data\n        self._transcription_pipeline = transcription_pipeline\n        self._partition = input_data.partition\n        self._target_endpoint = input_data.documentUri\n\n    def _get_bucket_name(self, layer: str) -&gt; str:\n        \"\"\"\n        Generates the bucket name for Minio storage.\n\n        Args:\n            layer (str): The layer of the bucket.\n\n        Returns:\n            str: The bucket name.\n        \"\"\"\n        return \"{layer}-{context}-source-{source}\".format(\n            layer=layer,\n            context=self._context,\n            source=self._source,\n        )\n\n    def _get_status(self) -&gt; StatusDTO:\n        \"\"\"\n        Extracts the status information from an HTTP response.\n\n        Returns:\n            StatusDTO: The status information.\n        \"\"\"\n        return StatusDTO(\n            code=200,\n            detail=\"Success\",\n        )\n\n    def make_request(self, minio: MinioClient) -&gt; None:\n        \"\"\"\n        Makes a request to Minio for audio data.\n\n        Args:\n            minio (MinioClient): An instance of the MinioClient for interacting with Minio.\n\n        Returns:\n            bytes: The audio data in bytes.\n        \"\"\"\n        logger.info(f\"endpoint: {self._target_endpoint}\")\n        file_bytes = minio.download_file_as_bytes(self._get_bucket_name(layer=\"raw\"), f\"{self._partition}/audio.mp3\")\n        return file_bytes\n\n\n    def run(self) -&gt; Tuple[dict, StatusDTO]:\n        \"\"\"\n        Runs the job, making the HTTP request and handling the response.\n\n        Returns:\n            Tuple[dict, StatusDTO]: A tuple containing job_data and job_status.\n        \"\"\"\n        logger.info(f\"Job triggered with input: {self._input_data}\")\n        minio = minio_client()\n        audio = self.make_request(minio)\n        transcription = self._transcription_pipeline(audio)\n        transcription_text = transcription[\"text\"]\n\n        uri = minio.upload_bytes(self._get_bucket_name(layer=\"bronze\"), f\"{self._partition}/transcription.txt\", transcription_text.encode(\"utf-8\"))\n        logger.info(f\"File storage uri: {uri}\")\n        result = {\"documentUri\": uri, \"partition\": self._partition}\n        logger.info(f\"Job result: {result}\")\n        return result, self._get_status()\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/jobs/handlers/audio_to_text/job/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.jobs.handlers.audio_to_text.job.Job.__init__","title":"<code>__init__(config, input_data, transcription_pipeline)</code>","text":"<p>Initialize the Job instance.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data for the job.</p> required <code>input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> required <code>transcription_pipeline</code> <code>pipeline</code> <p>The pipeline for transcription.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/jobs/handlers/audio_to_text/job.py</code> <pre><code>def __init__(self, config: ConfigDTO, input_data: type[warlock.model.Model], transcription_pipeline: pipeline) -&gt; None:\n    \"\"\"\n    Initialize the Job instance.\n\n    Args:\n        config (ConfigDTO): The configuration data for the job.\n        input_data (type[warlock.model.Model]): The input data for the job.\n        transcription_pipeline (pipeline): The pipeline for transcription.\n\n    Returns:\n        None\n    \"\"\"\n    self._config = config\n    self._source = config.source\n    self._context = config.context\n    self._input_data = input_data\n    self._transcription_pipeline = transcription_pipeline\n    self._partition = input_data.partition\n    self._target_endpoint = input_data.documentUri\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/jobs/handlers/audio_to_text/job/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.jobs.handlers.audio_to_text.job.Job.make_request","title":"<code>make_request(minio)</code>","text":"<p>Makes a request to Minio for audio data.</p> <p>Parameters:</p> Name Type Description Default <code>minio</code> <code>MinioClient</code> <p>An instance of the MinioClient for interacting with Minio.</p> required <p>Returns:</p> Name Type Description <code>bytes</code> <code>None</code> <p>The audio data in bytes.</p> Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/jobs/handlers/audio_to_text/job.py</code> <pre><code>def make_request(self, minio: MinioClient) -&gt; None:\n    \"\"\"\n    Makes a request to Minio for audio data.\n\n    Args:\n        minio (MinioClient): An instance of the MinioClient for interacting with Minio.\n\n    Returns:\n        bytes: The audio data in bytes.\n    \"\"\"\n    logger.info(f\"endpoint: {self._target_endpoint}\")\n    file_bytes = minio.download_file_as_bytes(self._get_bucket_name(layer=\"raw\"), f\"{self._partition}/audio.mp3\")\n    return file_bytes\n</code></pre>"},{"location":"reference/apps/services-bronze-layer/speech-transcriber/code_reference/speech_transcriber/jobs/handlers/audio_to_text/job/#apps.services-bronze-layer.speech-transcriber.speech_transcriber.jobs.handlers.audio_to_text.job.Job.run","title":"<code>run()</code>","text":"<p>Runs the job, making the HTTP request and handling the response.</p> <p>Returns:</p> Type Description <code>Tuple[dict, StatusDTO]</code> <p>Tuple[dict, StatusDTO]: A tuple containing job_data and job_status.</p> Source code in <code>apps/services-bronze-layer/speech-transcriber/speech_transcriber/jobs/handlers/audio_to_text/job.py</code> <pre><code>def run(self) -&gt; Tuple[dict, StatusDTO]:\n    \"\"\"\n    Runs the job, making the HTTP request and handling the response.\n\n    Returns:\n        Tuple[dict, StatusDTO]: A tuple containing job_data and job_status.\n    \"\"\"\n    logger.info(f\"Job triggered with input: {self._input_data}\")\n    minio = minio_client()\n    audio = self.make_request(minio)\n    transcription = self._transcription_pipeline(audio)\n    transcription_text = transcription[\"text\"]\n\n    uri = minio.upload_bytes(self._get_bucket_name(layer=\"bronze\"), f\"{self._partition}/transcription.txt\", transcription_text.encode(\"utf-8\"))\n    logger.info(f\"File storage uri: {uri}\")\n    result = {\"documentUri\": uri, \"partition\": self._partition}\n    logger.info(f\"Job result: {result}\")\n    return result, self._get_status()\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/","title":"Document Vectorizer","text":"<p><code>document-vectorizer</code> is a Python-based service that performs the following tasks:</p> <ul> <li>process document data, extracting relevant information</li> <li>creating vector embeddings for further analysis.</li> </ul>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/#overview","title":"Overview","text":"<p>The Document Vectorizer is built to handle document data processing within a distributed architecture. It utilizes asyncio, RabbitMQ, Minio, and Neo4j to efficiently process and store vector embeddings.</p>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/#service-components","title":"Service Components","text":"<p>The service consists of multiple Python modules and classes, each serving a specific purpose. Here's an overview of these components:</p>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/#main-module","title":"Main Module","text":"<ul> <li><code>main.py</code>: The entry point of the service.</li> <li>It initializes various configurations, including the service name and context environment.</li> <li>Load LLM Model.</li> <li>Creates consumers for specific configurations and starts processing data.</li> <li>Each config has it owns queue consumption.</li> </ul>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/#consumer-module","title":"Consumer Module","text":"<p>The Event Consumer is responsible for creating consumers for processing data from various configurations. It connects to RabbitMQ and triggers the Event Controller.</p> <ul> <li><code>file_downloader/consumer/consumer.py</code>: Contains the <code>EventConsumer</code> class responsible for consume an input message and trigger the callback.</li> <li>This class listens to a RabbitMQ queue, processes incoming data, and trigger the results to the controller.</li> </ul>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/#controller-module","title":"Controller Module","text":"<p>The Event Controller processes incoming event data, converts it into the appropriate format, and dispatches jobs for further processing. It interacts with the Job Handler to process the document data.</p> <ul> <li> <p><code>file_downloader/controller/controller.py</code>: This module contains the <code>EventController</code> class, which is responsible for handling the business logic related to event processing.</p> </li> <li> <p>The <code>EventController</code> class receives the processed data from the <code>EventConsumer</code>.</p> </li> <li>It checks if the controller should be active based on the configuration.</li> <li>If active, it parses and processes the data using the job handler.</li> <li>It triggers the job dispatcher to execute the job and collect the results.</li> <li>It publishes the results, including the storage URI, to a message queue for further consumption.</li> </ul> <p>The <code>EventController</code> class plays a crucial role in orchestrating the event-driven processing of data within the service.</p> <p>This class ensures that the service processes incoming data efficiently, initiates the appropriate job handler for the task, and communicates the results to the relevant channels.</p>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/#job-handling-module","title":"Job Handling Module","text":"<p>The Job Handler executes jobs associated with a configuration. It imports the appropriate job handler module based on the specified name, processes the document data, and stores vector embeddings.</p> <ul> <li><code>file_downloader/jobs/job_handler.py</code>: Handles the execution of jobs related to downloading and storing the file in a bucket.</li> <li>It uses a specific job handler module based on the configuration.</li> </ul>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/#job-handler-module","title":"Job Handler Module","text":""},{"location":"reference/apps/services-gold-layer/document-vectorizer/#default-handler","title":"Default Handler","text":"<ul> <li><code>jobs/handlers/pdf_embeddings/job.py</code>: An example job handler module.</li> <li>It defines the logic for creating vector embeddings for PDF files.</li> <li>It stores the embeddings vectors in Neo4J.</li> <li>It returns the job result, including the storage URI and status.</li> </ul>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/#libraries-dependencies","title":"Libraries Dependencies:","text":""},{"location":"reference/apps/services-gold-layer/document-vectorizer/#configuration-module","title":"Configuration Module","text":"<ul> <li><code>config_loader</code>: Loads configurations for the service, such as the source, job handler, service parameters and job parameters also.</li> </ul>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/#rabbitmq-module","title":"RabbitMQ Module","text":"<ul> <li><code>pyrabbitmq</code>: Handles the interaction with RabbitMQ, including creating channels, queues, and publishing messages.</li> </ul>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/#service-discovery-module","title":"Service Discovery Module","text":"<ul> <li><code>pysd</code>: Manages service discovery and RabbitMQ endpoints.</li> </ul>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/#architecture-diagram","title":"Architecture Diagram","text":""},{"location":"reference/apps/services-gold-layer/document-vectorizer/#c4-diagram","title":"C4 Diagram","text":""},{"location":"reference/apps/services-gold-layer/document-vectorizer/#service-diagram","title":"Service Diagram","text":""},{"location":"reference/apps/services-gold-layer/document-vectorizer/#how-to-run-the-service","title":"How to Run the Service","text":"<p>To run your service, follow these steps:</p> <ol> <li> <p>Setup Configuration:</p> <ul> <li>Create a <code>.env.{ENVIRONMENT}</code> file based on the example provided in the <code>envs</code> folder.</li> </ul> </li> <li> <p>Build The Service:</p> </li> </ol> <pre><code>npx nx image services-gold-layer-document-vectorizer --env=&lt;ENVIRONMENT&gt;\n</code></pre> <ol> <li>Run the Application:</li> </ol> <pre><code>docker-compose up -d\n</code></pre> <p>Please note that this README provides a high-level overview of your service's structure and components. To run the service effectively, make sure to provide the required configurations and customize the job handler logic according to your specific use case.</p> <p>If you have any questions or need further assistance, feel free to ask.</p>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/consumer/consumer/","title":"Consumer","text":""},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/consumer/consumer/#apps.services-gold-layer.document-vectorizer.document_vectorizer.consumer.consumer.Consumer","title":"<code>Consumer</code>","text":"<p>Consumer class for processing data.</p> <p>Parameters:</p> Name Type Description Default <code>sd</code> <code>ServiceDiscovery</code> <p>An instance of the ServiceDiscovery class.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <code>embeddings</code> <p>Embeddings for data processing.</p> required <code>dimension</code> <p>Dimension for embeddings.</p> required Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/consumer/consumer.py</code> <pre><code>class Consumer:\n    \"\"\"\n    Consumer class for processing data.\n\n    Args:\n        sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        embeddings: Embeddings for data processing.\n        dimension: Dimension for embeddings.\n\n    \"\"\"\n    def __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue, embeddings, dimension):\n        \"\"\"\n        Initialize the Consumer instance.\n\n        Args:\n            sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n            rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n            config (ConfigDTO): The configuration data.\n            queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n            embeddings: Embeddings for data processing.\n            dimension: Dimension for embeddings.\n\n        Returns:\n            None\n        \"\"\"\n        self._config = config\n        self._rabbitmq_service = rabbitmq_service\n        self._queue_active_jobs = queue_active_jobs\n        self._embeddings = embeddings\n        self._dimension = dimension\n        self._exchange_name = sd.services_rabbitmq_exchange()\n        self._queue_name = _get_queue_name(config)\n        self._routing_key = _get_routing_key(config)\n\n    async def _run(self, controller: callable) -&gt; None:\n        \"\"\"\n        Run the consumer with the specified controller.\n\n        Args:\n            controller (callable): The controller class responsible for processing data.\n\n        Returns:\n            None\n        \"\"\"\n        channel = await self._rabbitmq_service.create_channel()\n        queue = await self._rabbitmq_service.create_queue(\n            channel,\n            self._queue_name,\n            self._exchange_name,\n            self._routing_key\n        )\n        logger.info(f\"Listening to queue: {self._queue_name}\")\n        await self._rabbitmq_service.listen(queue, controller(self._config, self._rabbitmq_service, self._queue_active_jobs, self._embeddings, self._dimension).run)\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/consumer/consumer/#apps.services-gold-layer.document-vectorizer.document_vectorizer.consumer.consumer.Consumer.__init__","title":"<code>__init__(sd, rabbitmq_service, config, queue_active_jobs, embeddings, dimension)</code>","text":"<p>Initialize the Consumer instance.</p> <p>Parameters:</p> Name Type Description Default <code>sd</code> <code>ServiceDiscovery</code> <p>An instance of the ServiceDiscovery class.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <code>embeddings</code> <p>Embeddings for data processing.</p> required <code>dimension</code> <p>Dimension for embeddings.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/consumer/consumer.py</code> <pre><code>def __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue, embeddings, dimension):\n    \"\"\"\n    Initialize the Consumer instance.\n\n    Args:\n        sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        embeddings: Embeddings for data processing.\n        dimension: Dimension for embeddings.\n\n    Returns:\n        None\n    \"\"\"\n    self._config = config\n    self._rabbitmq_service = rabbitmq_service\n    self._queue_active_jobs = queue_active_jobs\n    self._embeddings = embeddings\n    self._dimension = dimension\n    self._exchange_name = sd.services_rabbitmq_exchange()\n    self._queue_name = _get_queue_name(config)\n    self._routing_key = _get_routing_key(config)\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/consumer/consumer/#apps.services-gold-layer.document-vectorizer.document_vectorizer.consumer.consumer.EventConsumer","title":"<code>EventConsumer</code>","text":"<p>             Bases: <code>Consumer</code></p> <p>EventConsumer class for processing event data.</p> <p>Parameters:</p> Name Type Description Default <code>sd</code> <code>ServiceDiscovery</code> <p>An instance of the ServiceDiscovery class.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <code>embeddings</code> <p>Embeddings for data processing.</p> required <code>dimension</code> <p>Dimension for embeddings.</p> required Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/consumer/consumer.py</code> <pre><code>class EventConsumer(Consumer):\n    \"\"\"\n    EventConsumer class for processing event data.\n\n    Args:\n        sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        embeddings: Embeddings for data processing.\n        dimension: Dimension for embeddings.\n\n    \"\"\"\n    def __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue, embeddings, dimension):\n        \"\"\"\n        Initialize the EventConsumer instance.\n\n        Args:\n            sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n            rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n            config (ConfigDTO): The configuration data.\n            queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n            embeddings: Embeddings for data processing.\n            dimension: Dimension for embeddings.\n\n        Returns:\n            None\n        \"\"\"\n        super().__init__(sd, rabbitmq_service, config, queue_active_jobs, embeddings, dimension)\n\n    async def run(self) -&gt; None:\n        \"\"\"\n        Run the EventConsumer to process event data.\n\n        This method triggers the processing of incoming event data using the specified controller.\n\n        Returns:\n            None\n        \"\"\"\n        await self._run(EventController)\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/consumer/consumer/#apps.services-gold-layer.document-vectorizer.document_vectorizer.consumer.consumer.EventConsumer.__init__","title":"<code>__init__(sd, rabbitmq_service, config, queue_active_jobs, embeddings, dimension)</code>","text":"<p>Initialize the EventConsumer instance.</p> <p>Parameters:</p> Name Type Description Default <code>sd</code> <code>ServiceDiscovery</code> <p>An instance of the ServiceDiscovery class.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <code>embeddings</code> <p>Embeddings for data processing.</p> required <code>dimension</code> <p>Dimension for embeddings.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/consumer/consumer.py</code> <pre><code>def __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue, embeddings, dimension):\n    \"\"\"\n    Initialize the EventConsumer instance.\n\n    Args:\n        sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        embeddings: Embeddings for data processing.\n        dimension: Dimension for embeddings.\n\n    Returns:\n        None\n    \"\"\"\n    super().__init__(sd, rabbitmq_service, config, queue_active_jobs, embeddings, dimension)\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/consumer/consumer/#apps.services-gold-layer.document-vectorizer.document_vectorizer.consumer.consumer.EventConsumer.run","title":"<code>run()</code>  <code>async</code>","text":"<p>Run the EventConsumer to process event data.</p> <p>This method triggers the processing of incoming event data using the specified controller.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/consumer/consumer.py</code> <pre><code>async def run(self) -&gt; None:\n    \"\"\"\n    Run the EventConsumer to process event data.\n\n    This method triggers the processing of incoming event data using the specified controller.\n\n    Returns:\n        None\n    \"\"\"\n    await self._run(EventController)\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/controller/controller/","title":"Controller","text":""},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/controller/controller/#apps.services-gold-layer.document-vectorizer.document_vectorizer.controller.controller.Controller","title":"<code>Controller</code>","text":"<p>Base class for handling event data processing.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <code>embeddings</code> <p>Embeddings for data processing.</p> required <code>dimension</code> <p>Dimension for embeddings.</p> required Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/controller/controller.py</code> <pre><code>class Controller:\n    \"\"\"\n    Base class for handling event data processing.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        embeddings: Embeddings for data processing.\n        dimension: Dimension for embeddings.\n    \"\"\"\n    def __init__(self, config: ConfigDTO, queue_active_jobs: asyncio.Queue, embeddings, dimension):\n        \"\"\"\n        Initialize the Controller instance.\n\n        Args:\n            config (ConfigDTO): The configuration data.\n            queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n            embeddings: Embeddings for data processing.\n            dimension: Dimension for embeddings.\n\n        Returns:\n            None\n        \"\"\"\n        self._config = config\n        self._config_id = config.id\n        self._service_name = config.service\n        self._source_name = config.source\n        self._context_env = config.context\n        self._repository_schema_type = _REPOSITORY_SCHEMA_TYPE\n        self._queue_active_jobs = queue_active_jobs\n        self._active = config.active\n        self._embeddings = embeddings\n        self._dimension = dimension\n        self._schema_handler_client = async_py_schema_handler_client()\n        self._input_body_dto = None\n\n    def _should_controller_active(self) -&gt; bool:\n        \"\"\"\n        Check if the controller should be active based on the configuration.\n\n        Returns:\n            bool: True if the controller is active, False otherwise.\n        \"\"\"\n        if self._active:\n            return True\n        return False\n\n    async def _get_event_parser(self) -&gt; Dict[str, any]:\n        \"\"\"\n        Get the event parser JSON schema for data processing.\n\n        Returns:\n            Dict[str, any]: The JSON schema for data processing.\n        \"\"\"\n        self.schema_input = await self._schema_handler_client.list_one_schema_by_service_n_source_n_context_n_schema_type(\n            context=self._context_env,\n            service_name=self._service_name,\n            source_name=self._source_name,\n            schema_type=self._repository_schema_type\n        )\n        json_schema = self.schema_input.json_schema\n        return json_schema\n\n    async def _parse_event(self, message: str) -&gt; Type[warlock.model.Model]:\n        \"\"\"\n        Parse the incoming event message and transform it into the appropriate data format.\n\n        Args:\n            message (str): The incoming event message.\n\n        Returns:\n            object: The parsed event data in the required data format.\n\n        Raises:\n            ValueError: If the message body cannot be parsed.\n        \"\"\"\n        message_body = message.body.decode()\n        event_parser_class = await self._get_event_parser()\n        try:\n            input_body = json.loads(message_body)\n            self._input_body_dto = serialize_to_dataclass(input_body, InputDTO)\n\n            input_data = self._input_body_dto.data\n            Input_dataclass = warlock.model_factory(event_parser_class)\n            return Input_dataclass(**input_data)\n        except json.JSONDecodeError as e:\n            logger.error(f\"Failed to parse message body: {e}\")\n            raise ValueError(\"Invalid message body\")\n\n    def _get_metadata(self) -&gt; MetadataDTO:\n        \"\"\"\n        Generate metadata information for the processed event data.\n\n        Returns:\n            MetadataDTO: Metadata information for the event data.\n        \"\"\"\n        return MetadataDTO(\n            input=MetadataInputDTO(\n                id=self._input_body_dto.id,\n                data=self._input_body_dto.data,\n                processing_id=self._input_body_dto.metadata[\"processing_id\"],\n                processing_timestamp=self._input_body_dto.metadata[\"processing_timestamp\"],\n                input_schema_id=self.schema_input.schema_id\n            ),\n            context=self._config.context,\n            service=self._config.service,\n            source=self._config.source,\n            processing_timestamp=datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n            job_frequency=self._config.frequency,\n            job_config_id=self._config.config_id,\n        )\n\n    async def job_dispatcher(self, event_input) -&gt; ServiceFeedbackDTO:\n        \"\"\"\n        Dispatch a job to process the event input data and collect the results.\n\n        Args:\n            event_input: The input data for the job.\n\n        Returns:\n            ServiceFeedbackDTO: Feedback and result information from the job processing.\n        \"\"\"\n        await self._queue_active_jobs.put(1)\n        job_data, status_data = JobHandler(self._config, self._embeddings, self._dimension).run(event_input)\n        return ServiceFeedbackDTO(\n            data=job_data,\n            metadata=self._get_metadata(),\n            status=status_data,\n        )\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/controller/controller/#apps.services-gold-layer.document-vectorizer.document_vectorizer.controller.controller.Controller.__init__","title":"<code>__init__(config, queue_active_jobs, embeddings, dimension)</code>","text":"<p>Initialize the Controller instance.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <code>embeddings</code> <p>Embeddings for data processing.</p> required <code>dimension</code> <p>Dimension for embeddings.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/controller/controller.py</code> <pre><code>def __init__(self, config: ConfigDTO, queue_active_jobs: asyncio.Queue, embeddings, dimension):\n    \"\"\"\n    Initialize the Controller instance.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        embeddings: Embeddings for data processing.\n        dimension: Dimension for embeddings.\n\n    Returns:\n        None\n    \"\"\"\n    self._config = config\n    self._config_id = config.id\n    self._service_name = config.service\n    self._source_name = config.source\n    self._context_env = config.context\n    self._repository_schema_type = _REPOSITORY_SCHEMA_TYPE\n    self._queue_active_jobs = queue_active_jobs\n    self._active = config.active\n    self._embeddings = embeddings\n    self._dimension = dimension\n    self._schema_handler_client = async_py_schema_handler_client()\n    self._input_body_dto = None\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/controller/controller/#apps.services-gold-layer.document-vectorizer.document_vectorizer.controller.controller.Controller.job_dispatcher","title":"<code>job_dispatcher(event_input)</code>  <code>async</code>","text":"<p>Dispatch a job to process the event input data and collect the results.</p> <p>Parameters:</p> Name Type Description Default <code>event_input</code> <p>The input data for the job.</p> required <p>Returns:</p> Name Type Description <code>ServiceFeedbackDTO</code> <code>ServiceFeedbackDTO</code> <p>Feedback and result information from the job processing.</p> Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/controller/controller.py</code> <pre><code>async def job_dispatcher(self, event_input) -&gt; ServiceFeedbackDTO:\n    \"\"\"\n    Dispatch a job to process the event input data and collect the results.\n\n    Args:\n        event_input: The input data for the job.\n\n    Returns:\n        ServiceFeedbackDTO: Feedback and result information from the job processing.\n    \"\"\"\n    await self._queue_active_jobs.put(1)\n    job_data, status_data = JobHandler(self._config, self._embeddings, self._dimension).run(event_input)\n    return ServiceFeedbackDTO(\n        data=job_data,\n        metadata=self._get_metadata(),\n        status=status_data,\n    )\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/controller/controller/#apps.services-gold-layer.document-vectorizer.document_vectorizer.controller.controller.EventController","title":"<code>EventController</code>","text":"<p>             Bases: <code>Controller</code></p> <p>Controller class for processing event data.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <code>embeddings</code> <p>Embeddings for data processing.</p> required <code>dimension</code> <p>Dimension for embeddings.</p> required Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/controller/controller.py</code> <pre><code>class EventController(Controller):\n    \"\"\"\n    Controller class for processing event data.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        embeddings: Embeddings for data processing.\n        dimension: Dimension for embeddings.\n    \"\"\"\n    def __init__(self, config: ConfigDTO, rabbitmq_service: RabbitMQConsumer, queue_active_jobs: asyncio.Queue, embeddings, dimension) -&gt; None:\n        \"\"\"\n        Initialize the EventController instance.\n\n        Args:\n            config (ConfigDTO): The configuration data.\n            rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n            queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n            embeddings: Embeddings for data processing.\n            dimension: Dimension for embeddings.\n\n        Returns:\n            None\n        \"\"\"\n        self._rabbitmq_service = rabbitmq_service\n        super().__init__(config, queue_active_jobs, embeddings, dimension)\n\n    async def run(self, message) -&gt; None:\n        \"\"\"\n        Run the EventController to process event data.\n\n        This method initiates the processing of incoming event data using the specified controller logic.\n\n        Args:\n            message: The incoming event message.\n\n        Returns:\n            None\n        \"\"\"\n        logger.info(f\"Processing message: {message}\")\n        if not self._should_controller_active():\n            logger.warning(f\"Controller for config_id {self._config_id} is not active\")\n            return\n\n        await self._rabbitmq_service.publish_message(\n            \"services\",\n            \"input-processing\",\n            json.dumps(json.loads(message.body.decode()))\n        )\n\n        event_input = await self._parse_event(message)\n        job_result = await self.job_dispatcher(event_input)\n        output = serialize_to_json(job_result)\n        logger.info(f\"sleeping for 5 seconds...\")\n        time.sleep(5)\n        logger.info(f\"Output: {output}\")\n        await self._rabbitmq_service.publish_message(\n                \"services\",\n                \"feedback\",\n                output\n            )\n        await message.ack()\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/controller/controller/#apps.services-gold-layer.document-vectorizer.document_vectorizer.controller.controller.EventController.__init__","title":"<code>__init__(config, rabbitmq_service, queue_active_jobs, embeddings, dimension)</code>","text":"<p>Initialize the EventController instance.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required <code>embeddings</code> <p>Embeddings for data processing.</p> required <code>dimension</code> <p>Dimension for embeddings.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/controller/controller.py</code> <pre><code>def __init__(self, config: ConfigDTO, rabbitmq_service: RabbitMQConsumer, queue_active_jobs: asyncio.Queue, embeddings, dimension) -&gt; None:\n    \"\"\"\n    Initialize the EventController instance.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n        embeddings: Embeddings for data processing.\n        dimension: Dimension for embeddings.\n\n    Returns:\n        None\n    \"\"\"\n    self._rabbitmq_service = rabbitmq_service\n    super().__init__(config, queue_active_jobs, embeddings, dimension)\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/controller/controller/#apps.services-gold-layer.document-vectorizer.document_vectorizer.controller.controller.EventController.run","title":"<code>run(message)</code>  <code>async</code>","text":"<p>Run the EventController to process event data.</p> <p>This method initiates the processing of incoming event data using the specified controller logic.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <p>The incoming event message.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/controller/controller.py</code> <pre><code>async def run(self, message) -&gt; None:\n    \"\"\"\n    Run the EventController to process event data.\n\n    This method initiates the processing of incoming event data using the specified controller logic.\n\n    Args:\n        message: The incoming event message.\n\n    Returns:\n        None\n    \"\"\"\n    logger.info(f\"Processing message: {message}\")\n    if not self._should_controller_active():\n        logger.warning(f\"Controller for config_id {self._config_id} is not active\")\n        return\n\n    await self._rabbitmq_service.publish_message(\n        \"services\",\n        \"input-processing\",\n        json.dumps(json.loads(message.body.decode()))\n    )\n\n    event_input = await self._parse_event(message)\n    job_result = await self.job_dispatcher(event_input)\n    output = serialize_to_json(job_result)\n    logger.info(f\"sleeping for 5 seconds...\")\n    time.sleep(5)\n    logger.info(f\"Output: {output}\")\n    await self._rabbitmq_service.publish_message(\n            \"services\",\n            \"feedback\",\n            output\n        )\n    await message.ack()\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/jobs/job_handler/","title":"Job handler","text":""},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/jobs/job_handler/#apps.services-gold-layer.document-vectorizer.document_vectorizer.jobs.job_handler.JobHandler","title":"<code>JobHandler</code>","text":"<p>Handles the execution of jobs associated with a configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>embeddings</code> <p>Embeddings for job processing.</p> required <code>dimension</code> <p>Dimension for embeddings.</p> required <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>The configuration data.</p> <code>_job_handler</code> <code>str</code> <p>The name of the job handler.</p> <code>_config_id</code> <code>str</code> <p>The unique identifier for the configuration.</p> <code>_embeddings</code> <p>Embeddings for job processing.</p> <code>_dimension</code> <p>Dimension for embeddings.</p> <code>_module</code> <p>The imported module for the job handler.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>ConfigDTO, embeddings, dimension) -&gt; None: Initializes the JobHandler instance.</p> <code>_import_job_handler_as_module</code> <p>Imports the job handler module based on the specified name.</p> <code>run</code> <p>type[warlock.model.Model]) -&gt; Tuple[dict, StatusDTO]: Runs the job associated with the configuration.</p> Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/jobs/job_handler.py</code> <pre><code>class JobHandler:\n    \"\"\"\n    Handles the execution of jobs associated with a configuration.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        embeddings: Embeddings for job processing.\n        dimension: Dimension for embeddings.\n\n    Attributes:\n        _config (ConfigDTO): The configuration data.\n        _job_handler (str): The name of the job handler.\n        _config_id (str): The unique identifier for the configuration.\n        _embeddings: Embeddings for job processing.\n        _dimension: Dimension for embeddings.\n        _module: The imported module for the job handler.\n\n    Methods:\n        __init__(self, config: ConfigDTO, embeddings, dimension) -&gt; None:\n            Initializes the JobHandler instance.\n\n        _import_job_handler_as_module(self) -&gt; module:\n            Imports the job handler module based on the specified name.\n\n        run(self, source_input: type[warlock.model.Model]) -&gt; Tuple[dict, StatusDTO]:\n            Runs the job associated with the configuration.\n\n    \"\"\"\n    def __init__(self, config: ConfigDTO, embeddings, dimension) -&gt; None:\n        \"\"\"\n        Initializes the JobHandler instance.\n\n        Args:\n            config (ConfigDTO): The configuration data.\n            embeddings: Embeddings for job processing.\n            dimension: Dimension for embeddings.\n\n        Returns:\n            None\n        \"\"\"\n        self._config = config\n        self._job_handler = config.service_parameters[\"job_handler\"]\n        self._config_id = config.id\n        self._embeddings = embeddings\n        self._dimension = dimension\n        self._module = self._import_job_handler_as_module()\n\n    def _import_job_handler_as_module(self):\n        \"\"\"\n        Imports the job handler module based on the specified job handler name.\n\n        Returns:\n            module: The imported module for the job handler.\n        \"\"\"\n        return importlib.import_module(f\"jobs.handlers.{self._job_handler}.job\")\n\n    def run(self, source_input: type[warlock.model.Model]) -&gt; Tuple[dict, StatusDTO]:\n        \"\"\"\n        Runs the job associated with the configuration.\n\n        Args:\n            source_input (type[warlock.model.Model]): The input data for the job.\n\n        Returns:\n            Tuple[dict, StatusDTO]: A tuple containing job_data and job_status.\n        \"\"\"\n        logger.info(f\"[RUNNING JOB] - Config ID: {self._config_id} - handler: {self._job_handler}\")\n        job_data, job_status = self._module.Job(self._config, source_input, self._embeddings, self._dimension).run()\n        return job_data, job_status\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/jobs/job_handler/#apps.services-gold-layer.document-vectorizer.document_vectorizer.jobs.job_handler.JobHandler.__init__","title":"<code>__init__(config, embeddings, dimension)</code>","text":"<p>Initializes the JobHandler instance.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>embeddings</code> <p>Embeddings for job processing.</p> required <code>dimension</code> <p>Dimension for embeddings.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/jobs/job_handler.py</code> <pre><code>def __init__(self, config: ConfigDTO, embeddings, dimension) -&gt; None:\n    \"\"\"\n    Initializes the JobHandler instance.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        embeddings: Embeddings for job processing.\n        dimension: Dimension for embeddings.\n\n    Returns:\n        None\n    \"\"\"\n    self._config = config\n    self._job_handler = config.service_parameters[\"job_handler\"]\n    self._config_id = config.id\n    self._embeddings = embeddings\n    self._dimension = dimension\n    self._module = self._import_job_handler_as_module()\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/jobs/job_handler/#apps.services-gold-layer.document-vectorizer.document_vectorizer.jobs.job_handler.JobHandler.run","title":"<code>run(source_input)</code>","text":"<p>Runs the job associated with the configuration.</p> <p>Parameters:</p> Name Type Description Default <code>source_input</code> <code>type[Model]</code> <p>The input data for the job.</p> required <p>Returns:</p> Type Description <code>Tuple[dict, StatusDTO]</code> <p>Tuple[dict, StatusDTO]: A tuple containing job_data and job_status.</p> Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/jobs/job_handler.py</code> <pre><code>def run(self, source_input: type[warlock.model.Model]) -&gt; Tuple[dict, StatusDTO]:\n    \"\"\"\n    Runs the job associated with the configuration.\n\n    Args:\n        source_input (type[warlock.model.Model]): The input data for the job.\n\n    Returns:\n        Tuple[dict, StatusDTO]: A tuple containing job_data and job_status.\n    \"\"\"\n    logger.info(f\"[RUNNING JOB] - Config ID: {self._config_id} - handler: {self._job_handler}\")\n    job_data, job_status = self._module.Job(self._config, source_input, self._embeddings, self._dimension).run()\n    return job_data, job_status\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/jobs/handlers/pdf_embeddings/job/","title":"Job","text":""},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/jobs/handlers/pdf_embeddings/job/#apps.services-gold-layer.document-vectorizer.document_vectorizer.jobs.handlers.pdf_embeddings.job.Job","title":"<code>Job</code>","text":"<p>Handles the processing of document data.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> required <code>embeddings</code> <p>Embeddings for document processing.</p> required <code>dimension</code> <p>Dimension for embeddings.</p> required <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>The configuration data.</p> <code>_source</code> <code>str</code> <p>The source identifier.</p> <code>_context</code> <code>str</code> <p>The context environment.</p> <code>_input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> <code>_embeddings</code> <p>Embeddings for document processing.</p> <code>_dimension</code> <p>Dimension for embeddings.</p> <code>_partition</code> <code>str</code> <p>The partition identifier.</p> <code>_target_endpoint</code> <code>str</code> <p>The document's target endpoint.</p> <code>_neo4j_url</code> <code>str</code> <p>The URL for Neo4j database.</p> <code>_neo4j_username</code> <code>str</code> <p>The username for Neo4j database.</p> <code>_neo4j_password</code> <code>str</code> <p>The password for Neo4j database.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>ConfigDTO, input_data: type[warlock.model.Model], embeddings, dimension) -&gt; None: Initializes the Job instance.</p> <code>_get_bucket_name</code> <p>str) -&gt; str: Generates the bucket name for Minio storage.</p> <code>_get_status</code> <p>Gets the success status.</p> <code>_get_file_path</code> <p>Extracts the file path from the target endpoint.</p> <code>get_pdf_from_bucket</code> <p>MinioClient) -&gt; PdfReader: Downloads and returns the PDF file from Minio.</p> <code>_convert_document_to_text</code> <p>PdfReader) -&gt; str: Converts the PDF document to text.</p> <code>split_document</code> <p>PdfReader): Splits the document into chunks using langchain_textsplitter.</p> <code>get_neo4j_credentials</code> <p>Retrieves the Neo4j database credentials.</p> <code>store_embeddings</code> <p>Stores the document chunks in the Neo4j database.</p> <code>run</code> <p>Runs the document processing job.</p> Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/jobs/handlers/pdf_embeddings/job.py</code> <pre><code>class Job:\n    \"\"\"\n    Handles the processing of document data.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        input_data (type[warlock.model.Model]): The input data for the job.\n        embeddings: Embeddings for document processing.\n        dimension: Dimension for embeddings.\n\n    Attributes:\n        _config (ConfigDTO): The configuration data.\n        _source (str): The source identifier.\n        _context (str): The context environment.\n        _input_data (type[warlock.model.Model]): The input data for the job.\n        _embeddings: Embeddings for document processing.\n        _dimension: Dimension for embeddings.\n        _partition (str): The partition identifier.\n        _target_endpoint (str): The document's target endpoint.\n        _neo4j_url (str): The URL for Neo4j database.\n        _neo4j_username (str): The username for Neo4j database.\n        _neo4j_password (str): The password for Neo4j database.\n\n    Methods:\n        __init__(self, config: ConfigDTO, input_data: type[warlock.model.Model], embeddings, dimension) -&gt; None:\n            Initializes the Job instance.\n\n        _get_bucket_name(self, layer: str) -&gt; str:\n            Generates the bucket name for Minio storage.\n\n        _get_status(self) -&gt; StatusDTO:\n            Gets the success status.\n\n        _get_file_path(self):\n            Extracts the file path from the target endpoint.\n\n        get_pdf_from_bucket(self, minio: MinioClient) -&gt; PdfReader:\n            Downloads and returns the PDF file from Minio.\n\n        _convert_document_to_text(self, pdf_reader: PdfReader) -&gt; str:\n            Converts the PDF document to text.\n\n        split_document(self, pdf_reader: PdfReader):\n            Splits the document into chunks using langchain_textsplitter.\n\n        get_neo4j_credentials(self):\n            Retrieves the Neo4j database credentials.\n\n        store_embeddings(self, chunks):\n            Stores the document chunks in the Neo4j database.\n\n        run(self) -&gt; Tuple[dict, StatusDTO]:\n            Runs the document processing job.\n\n    \"\"\"\n    def __init__(self, config: ConfigDTO, input_data: type[warlock.model.Model], embeddings, dimension) -&gt; None:\n        \"\"\"\n        Initializes the Job instance.\n\n        Args:\n            config (ConfigDTO): The configuration data.\n            input_data (type[warlock.model.Model]): The input data for the job.\n            embeddings: Embeddings for document processing.\n            dimension: Dimension for embeddings.\n\n        Returns:\n            None\n        \"\"\"\n        self._config = config\n        self._source = config.source\n        self._context = config.context\n        self._input_data = input_data\n        self._embeddings = embeddings\n        self._dimension = dimension\n        self._partition = input_data.partition\n        self._target_endpoint = input_data.documentUri\n        self._neo4j_url, self._neo4j_username, self._neo4j_password = self.get_neo4j_credentials()\n\n    def _get_bucket_name(self, layer: str) -&gt; str:\n        \"\"\"\n        Generates the bucket name for Minio storage.\n\n        Args:\n            layer (str): The layer of the bucket.\n\n        Returns:\n            str: The bucket name.\n        \"\"\"\n        return \"{layer}-{context}-source-{source}\".format(\n            layer=layer,\n            context=self._context,\n            source=self._source,\n        )\n\n    def _get_status(self) -&gt; StatusDTO:\n        \"\"\"\n        Gets the success status.\n\n        Returns:\n            StatusDTO: The success status.\n        \"\"\"\n        return StatusDTO(\n            code=200,\n            detail=\"Success\",\n        )\n\n    def _get_file_path(self):\n        \"\"\"\n        Extracts the file path from the target endpoint.\n\n        Returns:\n            None\n        \"\"\"\n        match = re.search(f\"{self._partition}.*\", self._target_endpoint)\n        if match:\n            return match.group()\n        else:\n            logger.warning(\"Year not found in onclick attribute\")\n\n    def get_pdf_from_bucket(self, minio: MinioClient) -&gt; PdfReader:\n        \"\"\"\n        Downloads and returns the PDF file from Minio.\n\n        Args:\n            minio (MinioClient): The Minio client.\n\n        Returns:\n            PdfReader: The PDF file reader.\n        \"\"\"\n        logger.info(f\"endpoint: {self._target_endpoint}\")\n        file_bytes = minio.download_file_as_bytes(self._get_bucket_name(layer=\"landing\"), self._get_file_path())\n        # TODO: AttributeError: 'bytes' object has no attribute 'seek'\n        return PdfReader(io.BytesIO(file_bytes))\n\n    def _convert_document_to_text(self, pdf_reader: PdfReader) -&gt; str:\n        \"\"\"\n        Converts the PDF document to text.\n\n        Args:\n            pdf_reader (PdfReader): The PDF file reader.\n\n        Returns:\n            str: The text extracted from the document.\n        \"\"\"\n        text = \"\"\n        for page in pdf_reader.pages:\n            text += page.extract_text()\n        return text\n\n    def split_document(self, pdf_reader: PdfReader):\n        \"\"\"\n        Splits the document into chunks using langchain_textsplitter.\n\n        Args:\n            pdf_reader (PdfReader): The PDF file reader.\n\n        Returns:\n            None\n        \"\"\"\n        text = self._convert_document_to_text(pdf_reader)\n        text_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=1000, chunk_overlap=200, length_function=len\n        )\n\n        chunks = text_splitter.split_text(text=text)\n        return chunks\n\n    def get_neo4j_credentials(self):\n        \"\"\"\n        Retrieves the Neo4j database credentials.\n\n        Returns:\n            Tuple[str, str, str]: The Neo4j database URL, username, and password.\n        \"\"\"\n        url = os.getenv(\"NEO4J_URL\")\n        username = os.getenv(\"NEO4J_USERNAME\")\n        password = os.getenv(\"NEO4J_PASSWORD\")\n        return url, username, password\n\n    def store_embeddings(self, chunks):\n        \"\"\"\n        Stores the document chunks in the Neo4j database.\n\n        Args:\n            chunks: The document chunks.\n\n        Returns:\n            None\n        \"\"\"\n        vectorstore = Neo4jVector.from_texts(\n            chunks,\n            url=self._neo4j_url,\n            username=self._neo4j_username,\n            password=self._neo4j_password,\n            embedding=self._embeddings,\n            index_name=\"pdf_enbeddings\",\n            node_label=\"PdfEnbeddingsChunk\",\n            pre_delete_collection=False,\n        )\n\n    def run(self) -&gt; Tuple[dict, StatusDTO]:\n        \"\"\"\n        Runs the document processing job.\n\n        Returns:\n            Tuple[dict, StatusDTO]: A tuple containing job result and status.\n        \"\"\"\n        logger.info(f\"Job triggered with input: {self._input_data}\")\n        minio = minio_client()\n        pdf_reader = self.get_pdf_from_bucket(minio)\n        document_chunks = self.split_document(pdf_reader)\n        self.store_embeddings(document_chunks)\n        result = {\"documentUri\": \"\", \"partition\": self._partition}\n        logger.info(f\"Job result: {result}\")\n        return result, self._get_status()\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/jobs/handlers/pdf_embeddings/job/#apps.services-gold-layer.document-vectorizer.document_vectorizer.jobs.handlers.pdf_embeddings.job.Job.__init__","title":"<code>__init__(config, input_data, embeddings, dimension)</code>","text":"<p>Initializes the Job instance.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> required <code>embeddings</code> <p>Embeddings for document processing.</p> required <code>dimension</code> <p>Dimension for embeddings.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/jobs/handlers/pdf_embeddings/job.py</code> <pre><code>def __init__(self, config: ConfigDTO, input_data: type[warlock.model.Model], embeddings, dimension) -&gt; None:\n    \"\"\"\n    Initializes the Job instance.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        input_data (type[warlock.model.Model]): The input data for the job.\n        embeddings: Embeddings for document processing.\n        dimension: Dimension for embeddings.\n\n    Returns:\n        None\n    \"\"\"\n    self._config = config\n    self._source = config.source\n    self._context = config.context\n    self._input_data = input_data\n    self._embeddings = embeddings\n    self._dimension = dimension\n    self._partition = input_data.partition\n    self._target_endpoint = input_data.documentUri\n    self._neo4j_url, self._neo4j_username, self._neo4j_password = self.get_neo4j_credentials()\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/jobs/handlers/pdf_embeddings/job/#apps.services-gold-layer.document-vectorizer.document_vectorizer.jobs.handlers.pdf_embeddings.job.Job.get_pdf_from_bucket","title":"<code>get_pdf_from_bucket(minio)</code>","text":"<p>Downloads and returns the PDF file from Minio.</p> <p>Parameters:</p> Name Type Description Default <code>minio</code> <code>MinioClient</code> <p>The Minio client.</p> required <p>Returns:</p> Name Type Description <code>PdfReader</code> <code>PdfReader</code> <p>The PDF file reader.</p> Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/jobs/handlers/pdf_embeddings/job.py</code> <pre><code>def get_pdf_from_bucket(self, minio: MinioClient) -&gt; PdfReader:\n    \"\"\"\n    Downloads and returns the PDF file from Minio.\n\n    Args:\n        minio (MinioClient): The Minio client.\n\n    Returns:\n        PdfReader: The PDF file reader.\n    \"\"\"\n    logger.info(f\"endpoint: {self._target_endpoint}\")\n    file_bytes = minio.download_file_as_bytes(self._get_bucket_name(layer=\"landing\"), self._get_file_path())\n    # TODO: AttributeError: 'bytes' object has no attribute 'seek'\n    return PdfReader(io.BytesIO(file_bytes))\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/jobs/handlers/pdf_embeddings/job/#apps.services-gold-layer.document-vectorizer.document_vectorizer.jobs.handlers.pdf_embeddings.job.Job.split_document","title":"<code>split_document(pdf_reader)</code>","text":"<p>Splits the document into chunks using langchain_textsplitter.</p> <p>Parameters:</p> Name Type Description Default <code>pdf_reader</code> <code>PdfReader</code> <p>The PDF file reader.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/jobs/handlers/pdf_embeddings/job.py</code> <pre><code>def split_document(self, pdf_reader: PdfReader):\n    \"\"\"\n    Splits the document into chunks using langchain_textsplitter.\n\n    Args:\n        pdf_reader (PdfReader): The PDF file reader.\n\n    Returns:\n        None\n    \"\"\"\n    text = self._convert_document_to_text(pdf_reader)\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1000, chunk_overlap=200, length_function=len\n    )\n\n    chunks = text_splitter.split_text(text=text)\n    return chunks\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/jobs/handlers/pdf_embeddings/job/#apps.services-gold-layer.document-vectorizer.document_vectorizer.jobs.handlers.pdf_embeddings.job.Job.get_neo4j_credentials","title":"<code>get_neo4j_credentials()</code>","text":"<p>Retrieves the Neo4j database credentials.</p> <p>Returns:</p> Type Description <p>Tuple[str, str, str]: The Neo4j database URL, username, and password.</p> Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/jobs/handlers/pdf_embeddings/job.py</code> <pre><code>def get_neo4j_credentials(self):\n    \"\"\"\n    Retrieves the Neo4j database credentials.\n\n    Returns:\n        Tuple[str, str, str]: The Neo4j database URL, username, and password.\n    \"\"\"\n    url = os.getenv(\"NEO4J_URL\")\n    username = os.getenv(\"NEO4J_USERNAME\")\n    password = os.getenv(\"NEO4J_PASSWORD\")\n    return url, username, password\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/jobs/handlers/pdf_embeddings/job/#apps.services-gold-layer.document-vectorizer.document_vectorizer.jobs.handlers.pdf_embeddings.job.Job.store_embeddings","title":"<code>store_embeddings(chunks)</code>","text":"<p>Stores the document chunks in the Neo4j database.</p> <p>Parameters:</p> Name Type Description Default <code>chunks</code> <p>The document chunks.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/jobs/handlers/pdf_embeddings/job.py</code> <pre><code>def store_embeddings(self, chunks):\n    \"\"\"\n    Stores the document chunks in the Neo4j database.\n\n    Args:\n        chunks: The document chunks.\n\n    Returns:\n        None\n    \"\"\"\n    vectorstore = Neo4jVector.from_texts(\n        chunks,\n        url=self._neo4j_url,\n        username=self._neo4j_username,\n        password=self._neo4j_password,\n        embedding=self._embeddings,\n        index_name=\"pdf_enbeddings\",\n        node_label=\"PdfEnbeddingsChunk\",\n        pre_delete_collection=False,\n    )\n</code></pre>"},{"location":"reference/apps/services-gold-layer/document-vectorizer/code_reference/document_vectorizer/jobs/handlers/pdf_embeddings/job/#apps.services-gold-layer.document-vectorizer.document_vectorizer.jobs.handlers.pdf_embeddings.job.Job.run","title":"<code>run()</code>","text":"<p>Runs the document processing job.</p> <p>Returns:</p> Type Description <code>Tuple[dict, StatusDTO]</code> <p>Tuple[dict, StatusDTO]: A tuple containing job result and status.</p> Source code in <code>apps/services-gold-layer/document-vectorizer/document_vectorizer/jobs/handlers/pdf_embeddings/job.py</code> <pre><code>def run(self) -&gt; Tuple[dict, StatusDTO]:\n    \"\"\"\n    Runs the document processing job.\n\n    Returns:\n        Tuple[dict, StatusDTO]: A tuple containing job result and status.\n    \"\"\"\n    logger.info(f\"Job triggered with input: {self._input_data}\")\n    minio = minio_client()\n    pdf_reader = self.get_pdf_from_bucket(minio)\n    document_chunks = self.split_document(pdf_reader)\n    self.store_embeddings(document_chunks)\n    result = {\"documentUri\": \"\", \"partition\": self._partition}\n    logger.info(f\"Job result: {result}\")\n    return result, self._get_status()\n</code></pre>"},{"location":"reference/apps/services-orchestration/services-config-handler/","title":"services-config-handler","text":"<p>This is a Go API project structured following the clean architecture pattern with RabbitMQ integration for asynchronous messaging.</p>"},{"location":"reference/apps/services-orchestration/services-config-handler/#overview","title":"Overview","text":"<p>This project is designed to provide a scalable and maintainable architecture for building APIs. It separates concerns into distinct layers and integrates RabbitMQ for message queuing, ensuring the decoupling of components.</p>"},{"location":"reference/apps/services-orchestration/services-config-handler/#project-structure","title":"Project Structure","text":"<ul> <li><code>main.go</code>: Entry point of the application, where all components are initialized and the API server is started.</li> <li><code>envs</code>: Configuration files for different environments.</li> <li><code>configs</code>: Configuration Loading.</li> <li><code>internal</code>: The core application code.</li> <li><code>entity</code>: Defines the application's entities.</li> <li><code>event</code>: Handles application events.</li> <li><code>infra</code>: Infrastructure code, such as database and web.<ul> <li><code>web</code>: Handles HTTP server, routing, and API endpoints.</li> </ul> </li> <li><code>usecase</code>: Contains business logic and use cases.</li> </ul>"},{"location":"reference/apps/services-orchestration/services-config-handler/#getting-started","title":"Getting Started","text":"<ol> <li> <p>Setup Configuration:</p> </li> <li> <p>Create a <code>.env.{ENVIRONMENT}</code> file based on the example provided in the <code>envs</code> folder.</p> </li> <li> <p>Build The Application:</p> </li> </ol> <pre><code>npx nx image services-orchestration-services-config-handler --env=&lt;ENVIRONMENT&gt;\n</code></pre> <ol> <li>Run the Application:</li> </ol> <pre><code>docker-compose up -d\n</code></pre> <p>The API server will start on the specified port, and RabbitMQ will be used for asynchronous messaging.</p>"},{"location":"reference/apps/services-orchestration/services-config-handler/#configuration","title":"Configuration","text":"<p>The project uses a configuration system that loads environment-specific settings from the <code>envs</code> folder. Ensure that you provide the necessary environment variables or configuration files for your specific deployment.</p>"},{"location":"reference/apps/services-orchestration/services-config-handler/#dependency-management","title":"Dependency Management","text":"<p>This project uses Go modules for dependency management. You can use the <code>nx</code> commands to add or update dependencies as needed.</p> <pre><code>npx nx go-tidy services-orchestration-services-config-handler\n</code></pre>"},{"location":"reference/apps/services-orchestration/services-config-handler/#testing","title":"Testing","text":"<p>Unit tests and integration tests can be added to the respective packages in the <code>internal</code> directory. You can use Go's built-in testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test services-orchestration-services-config-handler\n</code></pre>"},{"location":"reference/apps/services-orchestration/services-config-handler/#contributing","title":"Contributing","text":"<p>Contributions to this project are welcome. If you find issues or have suggestions for improvements, feel free to create an issue or submit a pull request.</p>"},{"location":"reference/apps/services-orchestration/services-config-handler/#acknowledgments","title":"Acknowledgments","text":"<ul> <li>This project follows the clean architecture pattern as described by Robert C. Martin.</li> <li>RabbitMQ is used for asynchronous messaging.</li> </ul> <p>Feel free to adapt this README file to your specific project's needs and add more details as necessary.</p>"},{"location":"reference/apps/services-orchestration/services-config-handler/openapi/","title":"OpenAPI Specification","text":""},{"location":"reference/apps/services-orchestration/services-events-handler/","title":"services-events-handler","text":""},{"location":"reference/apps/services-orchestration/services-file-catalog-handler/","title":"services-file-catalog-handler","text":"<p>This is a Go API project structured following the clean architecture pattern.</p>"},{"location":"reference/apps/services-orchestration/services-file-catalog-handler/#overview","title":"Overview","text":"<p>This project is designed to provide a scalable and maintainable architecture for building APIs. It separates concerns into distinct layers ensuring the decoupling of components.</p>"},{"location":"reference/apps/services-orchestration/services-file-catalog-handler/#project-structure","title":"Project Structure","text":"<ul> <li><code>main.go</code>: Entry point of the application, where all components are initialized and the API server is started.</li> <li><code>envs</code>: Configuration files for different environments.</li> <li><code>configs</code>: Configuration Loading.</li> <li><code>internal</code>: The core application code.</li> <li><code>entity</code>: Defines the application's entities.</li> <li><code>infra</code>: Infrastructure code, such as database and web.<ul> <li><code>web</code>: Handles HTTP server, routing, and API endpoints.</li> </ul> </li> <li><code>usecase</code>: Contains business logic and use cases.</li> </ul>"},{"location":"reference/apps/services-orchestration/services-file-catalog-handler/#getting-started","title":"Getting Started","text":"<ol> <li> <p>Setup Configuration:</p> </li> <li> <p>Create a <code>.env.{ENVIRONMENT}</code> file based on the example provided in the <code>envs</code> folder.</p> </li> <li> <p>Build The Application:</p> </li> </ol> <pre><code>npx nx image services-orchestration-services-file-catalog-handler --env=&lt;ENVIRONMENT&gt;\n</code></pre> <ol> <li>Run the Application:</li> </ol> <pre><code>docker-compose up -d\n</code></pre> <p>The API server will start on the specified port, and RabbitMQ will be used for asynchronous messaging.</p>"},{"location":"reference/apps/services-orchestration/services-file-catalog-handler/#configuration","title":"Configuration","text":"<p>The project uses a configuration system that loads environment-specific settings from the <code>envs</code> folder. Ensure that you provide the necessary environment variables or configuration files for your specific deployment.</p>"},{"location":"reference/apps/services-orchestration/services-file-catalog-handler/#dependency-management","title":"Dependency Management","text":"<p>This project uses Go modules for dependency management. You can use the <code>nx</code> commands to add or update dependencies as needed.</p> <pre><code>npx nx go-tidy services-orchestration-services-file-catalog-handler\n</code></pre>"},{"location":"reference/apps/services-orchestration/services-file-catalog-handler/#testing","title":"Testing","text":"<p>Unit tests and integration tests can be added to the respective packages in the <code>internal</code> directory. You can use Go's built-in testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test services-orchestration-services-file-catalog-handler\n</code></pre>"},{"location":"reference/apps/services-orchestration/services-file-catalog-handler/#contributing","title":"Contributing","text":"<p>Contributions to this project are welcome. If you find issues or have suggestions for improvements, feel free to create an issue or submit a pull request.</p>"},{"location":"reference/apps/services-orchestration/services-file-catalog-handler/#acknowledgments","title":"Acknowledgments","text":"<ul> <li>This project follows the clean architecture pattern as described by Robert C. Martin.</li> </ul> <p>Feel free to adapt this README file to your specific project's needs and add more details as necessary.</p>"},{"location":"reference/apps/services-orchestration/services-file-catalog-handler/openapi/","title":"OpenAPI Specification","text":""},{"location":"reference/apps/services-orchestration/services-input-handler/","title":"services-input-handler","text":"<p>This is a Go API project structured following the clean architecture pattern with RabbitMQ integration for asynchronous messaging.</p>"},{"location":"reference/apps/services-orchestration/services-input-handler/#overview","title":"Overview","text":"<p>This project is designed to provide a scalable and maintainable architecture for building APIs. It separates concerns into distinct layers and integrates RabbitMQ for message queuing, ensuring the decoupling of components.</p>"},{"location":"reference/apps/services-orchestration/services-input-handler/#project-structure","title":"Project Structure","text":"<ul> <li><code>main.go</code>: Entry point of the application, where all components are initialized and the API server is started.</li> <li><code>envs</code>: Configuration files for different environments.</li> <li><code>configs</code>: Configuration Loading.</li> <li><code>internal</code>: The core application code.</li> <li><code>entity</code>: Defines the application's entities.</li> <li><code>event</code>: Handles application events.</li> <li><code>infra</code>: Infrastructure code, such as database and web.<ul> <li><code>web</code>: Handles HTTP server, routing, and API endpoints.</li> </ul> </li> <li><code>usecase</code>: Contains business logic and use cases.</li> </ul>"},{"location":"reference/apps/services-orchestration/services-input-handler/#getting-started","title":"Getting Started","text":"<ol> <li> <p>Setup Configuration:</p> </li> <li> <p>Create a <code>.env.{ENVIRONMENT}</code> file based on the example provided in the <code>envs</code> folder.</p> </li> <li> <p>Build The Application:</p> </li> </ol> <pre><code>npx nx image services-orchestration-services-input-handler --env=&lt;ENVIRONMENT&gt;\n</code></pre> <ol> <li>Run the Application:</li> </ol> <pre><code>docker-compose up -d\n</code></pre> <p>The API server will start on the specified port, and RabbitMQ will be used for asynchronous messaging.</p>"},{"location":"reference/apps/services-orchestration/services-input-handler/#configuration","title":"Configuration","text":"<p>The project uses a configuration system that loads environment-specific settings from the <code>envs</code> folder. Ensure that you provide the necessary environment variables or configuration files for your specific deployment.</p>"},{"location":"reference/apps/services-orchestration/services-input-handler/#dependency-management","title":"Dependency Management","text":"<p>This project uses Go modules for dependency management. You can use the <code>nx</code> commands to add or update dependencies as needed.</p> <pre><code>npx nx go-tidy services-orchestration-services-input-handler\n</code></pre>"},{"location":"reference/apps/services-orchestration/services-input-handler/#testing","title":"Testing","text":"<p>Unit tests and integration tests can be added to the respective packages in the <code>internal</code> directory. You can use Go's built-in testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test services-orchestration-services-input-handler\n</code></pre>"},{"location":"reference/apps/services-orchestration/services-input-handler/#contributing","title":"Contributing","text":"<p>Contributions to this project are welcome. If you find issues or have suggestions for improvements, feel free to create an issue or submit a pull request.</p>"},{"location":"reference/apps/services-orchestration/services-input-handler/#acknowledgments","title":"Acknowledgments","text":"<ul> <li>This project follows the clean architecture pattern as described by Robert C. Martin.</li> <li>RabbitMQ is used for asynchronous messaging.</li> </ul> <p>Feel free to adapt this README file to your specific project's needs and add more details as necessary.</p>"},{"location":"reference/apps/services-orchestration/services-input-handler/openapi/","title":"OpenAPI Specification","text":""},{"location":"reference/apps/services-orchestration/services-output-handler/","title":"services-output-handler","text":"<p>This is a Go API project structured following the clean architecture pattern.</p>"},{"location":"reference/apps/services-orchestration/services-output-handler/#overview","title":"Overview","text":"<p>This project is designed to provide a scalable and maintainable architecture for building APIs. It separates concerns into distinct layers ensuring the decoupling of components.</p>"},{"location":"reference/apps/services-orchestration/services-output-handler/#project-structure","title":"Project Structure","text":"<ul> <li><code>main.go</code>: Entry point of the application, where all components are initialized and the API server is started.</li> <li><code>envs</code>: Configuration files for different environments.</li> <li><code>configs</code>: Configuration Loading.</li> <li><code>internal</code>: The core application code.</li> <li><code>entity</code>: Defines the application's entities.</li> <li><code>infra</code>: Infrastructure code, such as database and web.<ul> <li><code>web</code>: Handles HTTP server, routing, and API endpoints.</li> </ul> </li> <li><code>usecase</code>: Contains business logic and use cases.</li> </ul>"},{"location":"reference/apps/services-orchestration/services-output-handler/#getting-started","title":"Getting Started","text":"<ol> <li> <p>Setup Configuration:</p> </li> <li> <p>Create a <code>.env.{ENVIRONMENT}</code> file based on the example provided in the <code>envs</code> folder.</p> </li> <li> <p>Build The Application:</p> </li> </ol> <pre><code>npx nx image services-orchestration-services-output-handler --env=&lt;ENVIRONMENT&gt;\n</code></pre> <ol> <li>Run the Application:</li> </ol> <pre><code>docker-compose up -d\n</code></pre> <p>The API server will start on the specified port, and RabbitMQ will be used for asynchronous messaging.</p>"},{"location":"reference/apps/services-orchestration/services-output-handler/#configuration","title":"Configuration","text":"<p>The project uses a configuration system that loads environment-specific settings from the <code>envs</code> folder. Ensure that you provide the necessary environment variables or configuration files for your specific deployment.</p>"},{"location":"reference/apps/services-orchestration/services-output-handler/#dependency-management","title":"Dependency Management","text":"<p>This project uses Go modules for dependency management. You can use the <code>nx</code> commands to add or update dependencies as needed.</p> <pre><code>npx nx go-tidy services-orchestration-services-output-handler\n</code></pre>"},{"location":"reference/apps/services-orchestration/services-output-handler/#testing","title":"Testing","text":"<p>Unit tests and integration tests can be added to the respective packages in the <code>internal</code> directory. You can use Go's built-in testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test services-orchestration-services-output-handler\n</code></pre>"},{"location":"reference/apps/services-orchestration/services-output-handler/#contributing","title":"Contributing","text":"<p>Contributions to this project are welcome. If you find issues or have suggestions for improvements, feel free to create an issue or submit a pull request.</p>"},{"location":"reference/apps/services-orchestration/services-output-handler/#acknowledgments","title":"Acknowledgments","text":"<ul> <li>This project follows the clean architecture pattern as described by Robert C. Martin.</li> </ul> <p>Feel free to adapt this README file to your specific project's needs and add more details as necessary.</p>"},{"location":"reference/apps/services-orchestration/services-output-handler/openapi/","title":"OpenAPI Specification","text":""},{"location":"reference/apps/services-orchestration/services-schema-handler/","title":"services-schema-handler","text":"<p>This is a Go API project structured following the clean architecture pattern with RabbitMQ integration for asynchronous messaging.</p>"},{"location":"reference/apps/services-orchestration/services-schema-handler/#overview","title":"Overview","text":"<p>This project is designed to provide a scalable and maintainable architecture for building APIs. It separates concerns into distinct layers and integrates RabbitMQ for message queuing, ensuring the decoupling of components.</p>"},{"location":"reference/apps/services-orchestration/services-schema-handler/#project-structure","title":"Project Structure","text":"<ul> <li><code>main.go</code>: Entry point of the application, where all components are initialized and the API server is started.</li> <li><code>envs</code>: Configuration files for different environments.</li> <li><code>configs</code>: Configuration Loading.</li> <li><code>internal</code>: The core application code.</li> <li><code>entity</code>: Defines the application's entities.</li> <li><code>event</code>: Handles application events.</li> <li><code>infra</code>: Infrastructure code, such as database and web.<ul> <li><code>web</code>: Handles HTTP server, routing, and API endpoints.</li> </ul> </li> <li><code>usecase</code>: Contains business logic and use cases.</li> </ul>"},{"location":"reference/apps/services-orchestration/services-schema-handler/#getting-started","title":"Getting Started","text":"<ol> <li> <p>Setup Configuration:</p> </li> <li> <p>Create a <code>.env.{ENVIRONMENT}</code> file based on the example provided in the <code>envs</code> folder.</p> </li> <li> <p>Build The Application:</p> </li> </ol> <pre><code>npx nx image services-orchestration-services-schema-handler --env=&lt;ENVIRONMENT&gt;\n</code></pre> <ol> <li>Run the Application:</li> </ol> <pre><code>docker-compose up -d\n</code></pre> <p>The API server will start on the specified port, and RabbitMQ will be used for asynchronous messaging.</p>"},{"location":"reference/apps/services-orchestration/services-schema-handler/#configuration","title":"Configuration","text":"<p>The project uses a configuration system that loads environment-specific settings from the <code>envs</code> folder. Ensure that you provide the necessary environment variables or configuration files for your specific deployment.</p>"},{"location":"reference/apps/services-orchestration/services-schema-handler/#dependency-management","title":"Dependency Management","text":"<p>This project uses Go modules for dependency management. You can use the <code>nx</code> commands to add or update dependencies as needed.</p> <pre><code>npx nx go-tidy services-orchestration-services-schema-handler\n</code></pre>"},{"location":"reference/apps/services-orchestration/services-schema-handler/#testing","title":"Testing","text":"<p>Unit tests and integration tests can be added to the respective packages in the <code>internal</code> directory. You can use Go's built-in testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test services-orchestration-services-schema-handler\n</code></pre>"},{"location":"reference/apps/services-orchestration/services-schema-handler/#contributing","title":"Contributing","text":"<p>Contributions to this project are welcome. If you find issues or have suggestions for improvements, feel free to create an issue or submit a pull request.</p>"},{"location":"reference/apps/services-orchestration/services-schema-handler/#acknowledgments","title":"Acknowledgments","text":"<ul> <li>This project follows the clean architecture pattern as described by Robert C. Martin.</li> <li>RabbitMQ is used for asynchronous messaging.</li> </ul> <p>Feel free to adapt this README file to your specific project's needs and add more details as necessary.</p>"},{"location":"reference/apps/services-orchestration/services-schema-handler/openapi/","title":"OpenAPI Specification","text":""},{"location":"reference/apps/services-orchestration/services-staging-handler/","title":"services-staging-handler","text":"<p>This is a Go API project structured following the clean architecture pattern with RabbitMQ integration for asynchronous messaging.</p>"},{"location":"reference/apps/services-orchestration/services-staging-handler/#overview","title":"Overview","text":"<p>This project is designed to provide a scalable and maintainable architecture for building APIs. It separates concerns into distinct layers and integrates RabbitMQ for message queuing, ensuring the decoupling of components.</p>"},{"location":"reference/apps/services-orchestration/services-staging-handler/#project-structure","title":"Project Structure","text":"<ul> <li><code>main.go</code>: Entry point of the application, where all components are initialized and the API server is started.</li> <li><code>envs</code>: Configuration files for different environments.</li> <li><code>configs</code>: Configuration Loading.</li> <li><code>internal</code>: The core application code.</li> <li><code>entity</code>: Defines the application's entities.</li> <li><code>event</code>: Handles application events.</li> <li><code>infra</code>: Infrastructure code, such as database and web.<ul> <li><code>web</code>: Handles HTTP server, routing, and API endpoints.</li> </ul> </li> <li><code>usecase</code>: Contains business logic and use cases.</li> </ul>"},{"location":"reference/apps/services-orchestration/services-staging-handler/#getting-started","title":"Getting Started","text":"<ol> <li> <p>Setup Configuration:</p> </li> <li> <p>Create a <code>.env.{ENVIRONMENT}</code> file based on the example provided in the <code>envs</code> folder.</p> </li> <li> <p>Build The Application:</p> </li> </ol> <pre><code>npx nx image services-orchestration-services-staging-handler --env=&lt;ENVIRONMENT&gt;\n</code></pre> <ol> <li>Run the Application:</li> </ol> <pre><code>docker-compose up -d\n</code></pre> <p>The API server will start on the specified port, and RabbitMQ will be used for asynchronous messaging.</p>"},{"location":"reference/apps/services-orchestration/services-staging-handler/#configuration","title":"Configuration","text":"<p>The project uses a configuration system that loads environment-specific settings from the <code>envs</code> folder. Ensure that you provide the necessary environment variables or configuration files for your specific deployment.</p>"},{"location":"reference/apps/services-orchestration/services-staging-handler/#dependency-management","title":"Dependency Management","text":"<p>This project uses Go modules for dependency management. You can use the <code>nx</code> commands to add or update dependencies as needed.</p> <pre><code>npx nx go-tidy services-orchestration-services-staging-handler\n</code></pre>"},{"location":"reference/apps/services-orchestration/services-staging-handler/#testing","title":"Testing","text":"<p>Unit tests and integration tests can be added to the respective packages in the <code>internal</code> directory. You can use Go's built-in testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test services-orchestration-services-staging-handler\n</code></pre>"},{"location":"reference/apps/services-orchestration/services-staging-handler/#contributing","title":"Contributing","text":"<p>Contributions to this project are welcome. If you find issues or have suggestions for improvements, feel free to create an issue or submit a pull request.</p>"},{"location":"reference/apps/services-orchestration/services-staging-handler/#acknowledgments","title":"Acknowledgments","text":"<ul> <li>This project follows the clean architecture pattern as described by Robert C. Martin.</li> <li>RabbitMQ is used for asynchronous messaging.</li> </ul> <p>Feel free to adapt this README file to your specific project's needs and add more details as necessary.</p>"},{"location":"reference/apps/services-orchestration/services-staging-handler/openapi%20copy/","title":"OpenAPI Specification","text":""},{"location":"reference/apps/services-orchestration/services-staging-handler/openapi/","title":"OpenAPI Specification","text":""},{"location":"reference/apps/services-raw-layer/file-downloader/","title":"file-downloader","text":"<p><code>file-downloader</code> is a Python-based service that performs the following tasks:</p> <ul> <li>Downloads data from a specific source in a event approach</li> <li>Store the file downloaded in a bucket (raw layer).</li> <li>Publishes the bucket location to a message queue for further consumption.</li> </ul>"},{"location":"reference/apps/services-raw-layer/file-downloader/#service-components","title":"Service Components","text":"<p>The service consists of multiple Python modules and classes, each serving a specific purpose. Here's an overview of these components:</p>"},{"location":"reference/apps/services-raw-layer/file-downloader/#main-module","title":"Main Module","text":"<ul> <li><code>main.py</code>: The entry point of the service.</li> <li>It initializes various configurations, including the service name and context environment.</li> <li>Creates consumers for specific configurations and starts processing data.</li> <li>Each config has it owns queue consumption.</li> </ul>"},{"location":"reference/apps/services-raw-layer/file-downloader/#consumer-module","title":"Consumer Module","text":"<ul> <li><code>file_downloader/consumer/consumer.py</code>: Contains the <code>EventConsumer</code> class responsible for consume an input message and trigger the callback.</li> <li>This class listens to a RabbitMQ queue, processes incoming data, and trigger the results to the controller.</li> </ul>"},{"location":"reference/apps/services-raw-layer/file-downloader/#controller-module","title":"Controller Module","text":"<ul> <li> <p><code>file_downloader/controller/controller.py</code>: This module contains the <code>EventController</code> class, which is responsible for handling the business logic related to event processing.</p> </li> <li> <p>The <code>EventController</code> class receives the processed data from the <code>EventConsumer</code>.</p> </li> <li>It checks if the controller should be active based on the configuration.</li> <li>If active, it parses and processes the data using the job handler.</li> <li>It triggers the job dispatcher to execute the job and collect the results.</li> <li>It publishes the results, including the storage URI, to a message queue for further consumption.</li> </ul> <p>The <code>EventController</code> class plays a crucial role in orchestrating the event-driven processing of data within the service.</p> <p>This class ensures that the service processes incoming data efficiently, initiates the appropriate job handler for the task, and communicates the results to the relevant channels.</p>"},{"location":"reference/apps/services-raw-layer/file-downloader/#job-handling-module","title":"Job Handling Module","text":"<ul> <li><code>file_downloader/jobs/job_handler.py</code>: Handles the execution of jobs related to downloading and storing the file in a bucket.</li> <li>It uses a specific job handler module based on the configuration.</li> </ul>"},{"location":"reference/apps/services-raw-layer/file-downloader/#job-handler-module","title":"Job Handler Module","text":""},{"location":"reference/apps/services-raw-layer/file-downloader/#default-handler","title":"Default Handler","text":"<ul> <li><code>jobs/handlers/default/job.py</code>: An example job handler module.</li> <li>It defines the logic for making HTTP requests to download data from a specific URL.</li> <li>It uploads the downloaded data to a Minio storage bucket.</li> <li>It returns the job result, including the storage URI and status.</li> </ul>"},{"location":"reference/apps/services-raw-layer/file-downloader/#youtube-handler","title":"Youtube Handler","text":"<ul> <li><code>jobs/handlers/youtube/job.py</code>: An example job handler module.</li> <li>It defines the logic for making HTTP requests to download videos from Youtube.</li> <li>It uploads the downloaded video to a Minio storage bucket.</li> <li>It returns the job result, including the storage URI and status.</li> </ul>"},{"location":"reference/apps/services-raw-layer/file-downloader/#libraries-dependencies","title":"Libraries Dependencies:","text":""},{"location":"reference/apps/services-raw-layer/file-downloader/#configuration-module","title":"Configuration Module","text":"<ul> <li><code>config_loader</code>: Loads configurations for the service, such as the source, job handler, service parameters and job parameters also.</li> </ul>"},{"location":"reference/apps/services-raw-layer/file-downloader/#rabbitmq-module","title":"RabbitMQ Module","text":"<ul> <li><code>pyrabbitmq</code>: Handles the interaction with RabbitMQ, including creating channels, queues, and publishing messages.</li> </ul>"},{"location":"reference/apps/services-raw-layer/file-downloader/#service-discovery-module","title":"Service Discovery Module","text":"<ul> <li><code>pysd</code>: Manages service discovery and RabbitMQ endpoints.</li> </ul>"},{"location":"reference/apps/services-raw-layer/file-downloader/#architecture-diagram","title":"Architecture Diagram","text":""},{"location":"reference/apps/services-raw-layer/file-downloader/#c4-diagram","title":"C4 Diagram","text":""},{"location":"reference/apps/services-raw-layer/file-downloader/#service-diagram","title":"Service Diagram","text":""},{"location":"reference/apps/services-raw-layer/file-downloader/#how-to-run-the-service","title":"How to Run the Service","text":"<p>To run your service, follow these steps:</p> <ol> <li> <p>Setup Configuration:</p> <ul> <li>Create a <code>.env.{ENVIRONMENT}</code> file based on the example provided in the <code>envs</code> folder.</li> </ul> </li> <li> <p>Build The Service:</p> </li> </ol> <pre><code>npx nx image services-raw-layer-file-downloader --env=&lt;ENVIRONMENT&gt;\n</code></pre> <ol> <li>Run the Application:</li> </ol> <pre><code>docker-compose up -d\n</code></pre> <p>Please note that this README provides a high-level overview of your service's structure and components. To run the service effectively, make sure to provide the required configurations and customize the job handler logic according to your specific use case.</p> <p>If you have any questions or need further assistance, feel free to ask.</p>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/consumer/consumer/","title":"Consumer","text":""},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/consumer/consumer/#apps.services-raw-layer.file-downloader.file_downloader.consumer.consumer.Consumer","title":"<code>Consumer</code>","text":"<p>The base class for creating data consumers.</p> <p>Parameters:</p> Name Type Description Default <code>sd</code> <code>ServiceDiscovery</code> <p>An instance of the ServiceDiscovery class.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/consumer/consumer.py</code> <pre><code>class Consumer:\n    \"\"\"\n    The base class for creating data consumers.\n\n    Args:\n        sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    \"\"\"\n    def __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue):\n        self._config = config\n        self._rabbitmq_service = rabbitmq_service\n        self._queue_active_jobs = queue_active_jobs\n        self._exchange_name = sd.services_rabbitmq_exchange()\n        self._queue_name = _get_queue_name(config)\n        self._routing_key = _get_routing_key(config)\n\n    async def _run(self, controller: callable) -&gt; None:\n        \"\"\"\n        Run the consumer with the specified controller.\n\n        Args:\n            controller (callable): The controller class responsible for processing data.\n\n        \"\"\"\n        channel = await self._rabbitmq_service.create_channel()\n        queue = await self._rabbitmq_service.create_queue(\n            channel,\n            self._queue_name,\n            self._exchange_name,\n            self._routing_key\n        )\n        logger.info(f\"Listening to queue: {self._queue_name}\")\n        await self._rabbitmq_service.listen(queue, controller(self._config, self._rabbitmq_service, self._queue_active_jobs).run)\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/consumer/consumer/#apps.services-raw-layer.file-downloader.file_downloader.consumer.consumer.EventConsumer","title":"<code>EventConsumer</code>","text":"<p>             Bases: <code>Consumer</code></p> <p>The EventConsumer class for processing event data.</p> <p>Parameters:</p> Name Type Description Default <code>sd</code> <code>ServiceDiscovery</code> <p>An instance of the ServiceDiscovery class.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/consumer/consumer.py</code> <pre><code>class EventConsumer(Consumer):\n    \"\"\"\n    The EventConsumer class for processing event data.\n\n    Args:\n        sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    \"\"\"\n    def __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue):\n        super().__init__(sd, rabbitmq_service, config, queue_active_jobs)\n\n    async def run(self) -&gt; None:\n        \"\"\"\n        Run the EventConsumer to process event data.\n\n        This method triggers the processing of incoming event data using the specified controller.\n\n        \"\"\"\n        await self._run(EventController)\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/consumer/consumer/#apps.services-raw-layer.file-downloader.file_downloader.consumer.consumer.EventConsumer.run","title":"<code>run()</code>  <code>async</code>","text":"<p>Run the EventConsumer to process event data.</p> <p>This method triggers the processing of incoming event data using the specified controller.</p> Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/consumer/consumer.py</code> <pre><code>async def run(self) -&gt; None:\n    \"\"\"\n    Run the EventConsumer to process event data.\n\n    This method triggers the processing of incoming event data using the specified controller.\n\n    \"\"\"\n    await self._run(EventController)\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/controller/controller/","title":"Controller","text":""},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/controller/controller/#apps.services-raw-layer.file-downloader.file_downloader.controller.controller.Controller","title":"<code>Controller</code>","text":"<p>Base class for handling event data processing.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/controller/controller.py</code> <pre><code>class Controller:\n    \"\"\"\n    Base class for handling event data processing.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    \"\"\"\n    def __init__(self, config: ConfigDTO, queue_active_jobs: asyncio.Queue):\n        self._config = config\n        self._config_id = config.id\n        self._service_name = config.service\n        self._source_name = config.source\n        self._context_env = config.context\n        self._repository_schema_type = _REPOSITORY_SCHEMA_TYPE\n        self._queue_active_jobs = queue_active_jobs\n        self._active = config.active\n        self._schema_handler_client = async_py_schema_handler_client()\n        self._input_body_dto = None\n\n    def _should_cotroller_active(self) -&gt; bool:\n        \"\"\"\n        Check if the controller should be active based on the configuration.\n\n        Returns:\n            bool: True if the controller is active, False otherwise.\n\n        \"\"\"\n        if self._active:\n            return True\n        return False\n\n    async def _get_event_parser(self) -&gt; Dict[str, any]:\n        \"\"\"\n        Get the event parser JSON schema for data processing.\n\n        Returns:\n            Dict[str, any]: The JSON schema for data processing.\n\n        \"\"\"\n        self.schema_input = await self._schema_handler_client.list_one_schema_by_service_n_source_n_context_n_schema_type(\n            context=self._context_env,\n            service_name=self._service_name,\n            source_name=self._source_name,\n            schema_type=self._repository_schema_type\n        )\n        json_schema = self.schema_input.json_schema\n        return json_schema\n\n    async def _parse_event(self, message: str) -&gt; type[warlock.model.Model]:\n        \"\"\"\n        Parse the incoming event message and transform it into the appropriate data format.\n\n        Args:\n            message (str): The incoming event message.\n\n        Returns:\n            object: The parsed event data in the required data format.\n\n        Raises:\n            ValueError: If the message body cannot be parsed.\n\n        \"\"\"\n        message_body = message.body.decode()\n        event_parser_class = await self._get_event_parser()\n        try:\n            input_body = json.loads(message_body)\n            self._input_body_dto = serialize_to_dataclass(input_body, InputDTO)\n\n            input_data = self._input_body_dto.data\n            Input_dataclass = warlock.model_factory(event_parser_class)\n            return Input_dataclass(**input_data)\n        except json.JSONDecodeError as e:\n            logger.error(f\"Failed to parse message body: {e}\")\n            raise ValueError(\"Invalid message body\")\n\n    def _get_metadata(self) -&gt; MetadataDTO:\n        \"\"\"\n        Generate metadata information for the processed event data.\n\n        Returns:\n            MetadataDTO: Metadata information for the event data.\n\n        \"\"\"\n        return MetadataDTO(\n            input=MetadataInputDTO(\n                id=self._input_body_dto.id,\n                data=self._input_body_dto.data,\n                processing_id=self._input_body_dto.metadata[\"processing_id\"],\n                processing_timestamp=self._input_body_dto.metadata[\"processing_timestamp\"],\n                input_schema_id=self.schema_input.schema_id\n            ),\n            context=self._config.context,\n            service=self._config.service,\n            source=self._config.source,\n            processing_timestamp=datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n            job_frequency=self._config.frequency,\n            job_config_id=self._config.config_id,\n        )\n\n    async def job_dispatcher(self, event_input) -&gt; ServiceFeedbackDTO:\n        \"\"\"\n        Dispatch a job to process the event input data and collect the results.\n\n        Args:\n            event_input: The input data for the job.\n\n        Returns:\n            ServiceFeedbackDTO: Feedback and result information from the job processing.\n\n        \"\"\"\n        await self._queue_active_jobs.put(1)\n        job_data, status_data = JobHandler(self._config).run(event_input)\n        return ServiceFeedbackDTO(\n            data=job_data,\n            metadata=self._get_metadata(),\n            status=status_data,\n        )\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/controller/controller/#apps.services-raw-layer.file-downloader.file_downloader.controller.controller.Controller.job_dispatcher","title":"<code>job_dispatcher(event_input)</code>  <code>async</code>","text":"<p>Dispatch a job to process the event input data and collect the results.</p> <p>Parameters:</p> Name Type Description Default <code>event_input</code> <p>The input data for the job.</p> required <p>Returns:</p> Name Type Description <code>ServiceFeedbackDTO</code> <code>ServiceFeedbackDTO</code> <p>Feedback and result information from the job processing.</p> Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/controller/controller.py</code> <pre><code>async def job_dispatcher(self, event_input) -&gt; ServiceFeedbackDTO:\n    \"\"\"\n    Dispatch a job to process the event input data and collect the results.\n\n    Args:\n        event_input: The input data for the job.\n\n    Returns:\n        ServiceFeedbackDTO: Feedback and result information from the job processing.\n\n    \"\"\"\n    await self._queue_active_jobs.put(1)\n    job_data, status_data = JobHandler(self._config).run(event_input)\n    return ServiceFeedbackDTO(\n        data=job_data,\n        metadata=self._get_metadata(),\n        status=status_data,\n    )\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/controller/controller/#apps.services-raw-layer.file-downloader.file_downloader.controller.controller.EventController","title":"<code>EventController</code>","text":"<p>             Bases: <code>Controller</code></p> <p>EventController class for processing event data.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/controller/controller.py</code> <pre><code>class EventController(Controller):\n    \"\"\"\n    EventController class for processing event data.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    \"\"\"\n    def __init__(self, config: ConfigDTO, rabbitmq_service: RabbitMQConsumer, queue_active_jobs: asyncio.Queue) -&gt; None:\n        self._rabbitmq_service = rabbitmq_service\n        super().__init__(config, queue_active_jobs)\n\n    async def run(self, message) -&gt; None:\n        \"\"\"\n        Run the EventController to process event data.\n\n        This method initiates the processing of incoming event data using the specified controller logic.\n\n        Args:\n            message: The incoming event message.\n\n        \"\"\"\n        logger.info(f\"Processing message: {message}\")\n        if not self._should_cotroller_active():\n            logger.warning(f\"Controller for config_id {self._config_id} is not active\")\n            return\n\n        await self._rabbitmq_service.publish_message(\n            \"services\",\n            \"input-processing\",\n            json.dumps(json.loads(message.body.decode()))\n        )\n\n        event_input = await self._parse_event(message)\n        job_result = await self.job_dispatcher(event_input)\n        output = serialize_to_json(job_result)\n        logger.info(f\"sleeping for 5 seconds...\")\n        time.sleep(5)\n        logger.info(f\"Output: {output}\")\n        await self._rabbitmq_service.publish_message(\n                \"services\",\n                \"feedback\",\n                output\n            )\n        await message.ack()\n        await self._queue_active_jobs.get()\n        logger.info(\"Published message to service\")\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/controller/controller/#apps.services-raw-layer.file-downloader.file_downloader.controller.controller.EventController.run","title":"<code>run(message)</code>  <code>async</code>","text":"<p>Run the EventController to process event data.</p> <p>This method initiates the processing of incoming event data using the specified controller logic.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <p>The incoming event message.</p> required Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/controller/controller.py</code> <pre><code>async def run(self, message) -&gt; None:\n    \"\"\"\n    Run the EventController to process event data.\n\n    This method initiates the processing of incoming event data using the specified controller logic.\n\n    Args:\n        message: The incoming event message.\n\n    \"\"\"\n    logger.info(f\"Processing message: {message}\")\n    if not self._should_cotroller_active():\n        logger.warning(f\"Controller for config_id {self._config_id} is not active\")\n        return\n\n    await self._rabbitmq_service.publish_message(\n        \"services\",\n        \"input-processing\",\n        json.dumps(json.loads(message.body.decode()))\n    )\n\n    event_input = await self._parse_event(message)\n    job_result = await self.job_dispatcher(event_input)\n    output = serialize_to_json(job_result)\n    logger.info(f\"sleeping for 5 seconds...\")\n    time.sleep(5)\n    logger.info(f\"Output: {output}\")\n    await self._rabbitmq_service.publish_message(\n            \"services\",\n            \"feedback\",\n            output\n        )\n    await message.ack()\n    await self._queue_active_jobs.get()\n    logger.info(\"Published message to service\")\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/jobs/job_handler/","title":"Job handler","text":""},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/jobs/job_handler/#apps.services-raw-layer.file-downloader.file_downloader.jobs.job_handler.JobHandler","title":"<code>JobHandler</code>","text":"<p>Represents a job handler that runs a specific job based on configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data for the job handler.</p> required <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>The configuration data for the job handler.</p> <code>_job_handler</code> <code>str</code> <p>The name of the job handler.</p> <code>_config_id</code> <code>int</code> <p>The unique identifier for the configuration.</p> <code>_module</code> <code>module</code> <p>The imported module for the specified job handler.</p> <p>Methods:</p> Name Description <code>_import_job_handler_as_module</code> <p>Imports the job handler module based on the provided configuration.</p> <code>run</code> <p>Runs the job associated with the configuration.</p> <p>Args:     source_input: The input data for the job.</p> <p>Returns:     tuple: A tuple containing job_data, job_status, and target_endpoint.</p> Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/jobs/job_handler.py</code> <pre><code>class JobHandler:\n    \"\"\"\n    Represents a job handler that runs a specific job based on configuration.\n\n    Args:\n        config (ConfigDTO): The configuration data for the job handler.\n\n    Attributes:\n        _config (ConfigDTO): The configuration data for the job handler.\n        _job_handler (str): The name of the job handler.\n        _config_id (int): The unique identifier for the configuration.\n        _module (module): The imported module for the specified job handler.\n\n    Methods:\n        _import_job_handler_as_module(self):\n            Imports the job handler module based on the provided configuration.\n\n        run(self, source_input):\n            Runs the job associated with the configuration.\n\n            Args:\n                source_input: The input data for the job.\n\n            Returns:\n                tuple: A tuple containing job_data, job_status, and target_endpoint.\n\n    \"\"\"\n\n    def __init__(self, config: ConfigDTO) -&gt; None:\n        self._config = config\n        self._job_handler = config.service_parameters[\"job_handler\"]\n        self._config_id = config.id\n        self._module = self._import_job_handler_as_module()\n\n    def _import_job_handler_as_module(self):\n        \"\"\"\n        Import the job handler module based on the specified job handler name.\n\n        Returns:\n            module: The imported module for the job handler.\n        \"\"\"\n        return importlib.import_module(f\"jobs.handlers.{self._job_handler}.job\")\n\n    def run(self, source_input: type[warlock.model.Model]) -&gt; Tuple[dict, StatusDTO]:\n        \"\"\"\n        Run the job associated with the configuration.\n\n        Args:\n            source_input: The input data for the job.\n\n        Returns:\n            tuple: A tuple containing job_data and job_status.\n        \"\"\"\n        logger.info(f\"[RUNNING JOB] - Config ID: {self._config_id} - handler: {self._job_handler}\")\n        job_data, job_status, target_endpoint = self._module.Job(self._config, source_input).run()\n        return job_data, job_status, target_endpoint\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/jobs/job_handler/#apps.services-raw-layer.file-downloader.file_downloader.jobs.job_handler.JobHandler.run","title":"<code>run(source_input)</code>","text":"<p>Run the job associated with the configuration.</p> <p>Parameters:</p> Name Type Description Default <code>source_input</code> <code>type[Model]</code> <p>The input data for the job.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>Tuple[dict, StatusDTO]</code> <p>A tuple containing job_data and job_status.</p> Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/jobs/job_handler.py</code> <pre><code>def run(self, source_input: type[warlock.model.Model]) -&gt; Tuple[dict, StatusDTO]:\n    \"\"\"\n    Run the job associated with the configuration.\n\n    Args:\n        source_input: The input data for the job.\n\n    Returns:\n        tuple: A tuple containing job_data and job_status.\n    \"\"\"\n    logger.info(f\"[RUNNING JOB] - Config ID: {self._config_id} - handler: {self._job_handler}\")\n    job_data, job_status, target_endpoint = self._module.Job(self._config, source_input).run()\n    return job_data, job_status, target_endpoint\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/jobs/handlers/annual_reports/job/","title":"Job","text":""},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/jobs/handlers/annual_reports/job/#apps.services-raw-layer.file-downloader.file_downloader.jobs.handlers.annual_reports.job.Job","title":"<code>Job</code>","text":"<p>Represents a job that makes HTTP requests and handles the response.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data for the job.</p> required <code>input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> required <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>The configuration data for the job.</p> <code>_source</code> <code> (str</code> <p>The source information from the configuration.</p> <code>_context</code> <code>str</code> <p>The context information from the configuration.</p> <code>_input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> <code>_job_url</code> <code>str</code> <p>The URL for the job.</p> <code>_partition</code> <code>str</code> <p>The partition based on input data reference.</p> <code>_target_endpoint</code> <code>str</code> <p>The final endpoint URL.</p> <p>Methods:</p> <pre><code>_get_endpoint(self):\n    Generates the target endpoint URL.\n\n_get_bucket_name(self):\n    Generates the bucket name for Minio storage.\n\n_get_status(self, response) -&gt; StatusDTO:\n    Extracts the status information from an HTTP response.\n\nmake_request(self):\n    Makes an HTTP GET request to the target endpoint.\n\nrun(self):\n    Runs the job, making the HTTP request and handling the response.\n</code></pre> Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/jobs/handlers/annual_reports/job.py</code> <pre><code>class Job:\n    \"\"\"\n    Represents a job that makes HTTP requests and handles the response.\n\n    Args:\n        config (ConfigDTO): The configuration data for the job.\n        input_data: The input data for the job.\n\n    Attributes:\n        _config (ConfigDTO): The configuration data for the job.\n        _source  (str): The source information from the configuration.\n        _context (str): The context information from the configuration.\n        _input_data (type[warlock.model.Model]): The input data for the job.\n        _job_url (str): The URL for the job.\n        _partition (str): The partition based on input data reference.\n        _target_endpoint (str): The final endpoint URL.\n\n    Methods:\n\n        _get_endpoint(self):\n            Generates the target endpoint URL.\n\n        _get_bucket_name(self):\n            Generates the bucket name for Minio storage.\n\n        _get_status(self, response) -&gt; StatusDTO:\n            Extracts the status information from an HTTP response.\n\n        make_request(self):\n            Makes an HTTP GET request to the target endpoint.\n\n        run(self):\n            Runs the job, making the HTTP request and handling the response.\n\n    \"\"\"\n    def __init__(self, config: ConfigDTO, input_data: type[warlock.model.Model]) -&gt; None:\n        self._config = config\n        self._source = config.source\n        self._context = config.context\n        self._input_data = input_data\n        self._job_url = config.job_parameters[\"url\"]\n        self._partition = input_data.partition\n        self._target_document = input_data.targetDocument\n        self._target_endpoint = self._get_endpoint()\n\n    def _get_endpoint(self) -&gt; str:\n        \"\"\"\n        Generates the target endpoint URL.\n\n        Returns:\n            str: The target endpoint URL.\n        \"\"\"\n        return self._job_url.format(self._target_document)\n\n    def _get_bucket_name(self) -&gt; str:\n        \"\"\"\n        Generates the bucket name for Minio storage.\n\n        Returns:\n            str: The bucket name.\n        \"\"\"\n        return \"landing-{context}-source-{source}\".format(\n            context=self._context,\n            source=self._source,\n        )\n\n    def _get_status(self, response) -&gt; StatusDTO:\n        \"\"\"\n        Extracts the status information from an HTTP response.\n\n        Args:\n            response: The HTTP response.\n\n        Returns:\n            StatusDTO: The status information.\n        \"\"\"\n        return StatusDTO(\n            code=response.status_code,\n            detail=response.reason,\n        )\n\n    def make_request(self) -&gt; requests.Response:\n        \"\"\"\n        Makes an HTTP GET request to the target endpoint.\n\n        Returns:\n            requests.Response: The HTTP response.\n        \"\"\"\n        logger.info(f\"endpoint: {self._target_endpoint}\")\n        headers = {\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n            \"Accept-Encoding\": \"gzip, deflate, br\",\n            \"Accept-Language\": \"pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7\",\n            \"Referer\": f\"https://www.annualreports.com/Company/{self._partition}\",\n            \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:92.0) Gecko/20100101 Firefox/92.0\",\n        }\n        return requests.get(\n            self._target_endpoint,\n            verify=False,\n            headers=headers,\n            timeout=10*60,\n        )\n\n    def run(self) -&gt; Tuple[dict, StatusDTO]:\n        \"\"\"\n        Runs the job, making the HTTP request and handling the response.\n\n        Returns:\n            tuple: A tuple containing result data and status information.\n        \"\"\"\n        logger.info(f\"Job triggered with input: {self._input_data}\")\n        response = self.make_request()\n        minio = minio_client()\n        uri = minio.upload_bytes(self._get_bucket_name(), f\"{self._partition}/{self._target_document}\", response.content)\n        logger.info(f\"File storage uri: {uri}\")\n        result = {\"documentUri\": uri, \"partition\": self._partition}\n        logger.info(f\"Job result: {result}\")\n        return result, self._get_status(response)\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/jobs/handlers/annual_reports/job/#apps.services-raw-layer.file-downloader.file_downloader.jobs.handlers.annual_reports.job.Job.make_request","title":"<code>make_request()</code>","text":"<p>Makes an HTTP GET request to the target endpoint.</p> <p>Returns:</p> Type Description <code>Response</code> <p>requests.Response: The HTTP response.</p> Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/jobs/handlers/annual_reports/job.py</code> <pre><code>def make_request(self) -&gt; requests.Response:\n    \"\"\"\n    Makes an HTTP GET request to the target endpoint.\n\n    Returns:\n        requests.Response: The HTTP response.\n    \"\"\"\n    logger.info(f\"endpoint: {self._target_endpoint}\")\n    headers = {\n        \"Sec-Fetch-Site\": \"same-origin\",\n        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n        \"Accept-Encoding\": \"gzip, deflate, br\",\n        \"Accept-Language\": \"pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7\",\n        \"Referer\": f\"https://www.annualreports.com/Company/{self._partition}\",\n        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:92.0) Gecko/20100101 Firefox/92.0\",\n    }\n    return requests.get(\n        self._target_endpoint,\n        verify=False,\n        headers=headers,\n        timeout=10*60,\n    )\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/jobs/handlers/annual_reports/job/#apps.services-raw-layer.file-downloader.file_downloader.jobs.handlers.annual_reports.job.Job.run","title":"<code>run()</code>","text":"<p>Runs the job, making the HTTP request and handling the response.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>Tuple[dict, StatusDTO]</code> <p>A tuple containing result data and status information.</p> Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/jobs/handlers/annual_reports/job.py</code> <pre><code>def run(self) -&gt; Tuple[dict, StatusDTO]:\n    \"\"\"\n    Runs the job, making the HTTP request and handling the response.\n\n    Returns:\n        tuple: A tuple containing result data and status information.\n    \"\"\"\n    logger.info(f\"Job triggered with input: {self._input_data}\")\n    response = self.make_request()\n    minio = minio_client()\n    uri = minio.upload_bytes(self._get_bucket_name(), f\"{self._partition}/{self._target_document}\", response.content)\n    logger.info(f\"File storage uri: {uri}\")\n    result = {\"documentUri\": uri, \"partition\": self._partition}\n    logger.info(f\"Job result: {result}\")\n    return result, self._get_status(response)\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/jobs/handlers/default/job/","title":"Job","text":""},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/jobs/handlers/default/job/#apps.services-raw-layer.file-downloader.file_downloader.jobs.handlers.default.job.Job","title":"<code>Job</code>","text":"<p>Represents a job that makes HTTP requests and handles the response.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data for the job.</p> required <code>input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> required <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>The configuration data for the job.</p> <code>_source</code> <code> (str</code> <p>The source information from the configuration.</p> <code>_context</code> <code>str</code> <p>The context information from the configuration.</p> <code>_input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> <code>_job_url</code> <code>str</code> <p>The URL for the job.</p> <code>_partition</code> <code>str</code> <p>The partition based on input data reference.</p> <code>_target_endpoint</code> <code>str</code> <p>The final endpoint URL.</p> <p>Methods:</p> <pre><code>_get_endpoint(self):\n    Generates the target endpoint URL.\n\n_get_bucket_name(self):\n    Generates the bucket name for Minio storage.\n\n_get_status(self, response) -&gt; StatusDTO:\n    Extracts the status information from an HTTP response.\n\nmake_request(self):\n    Makes an HTTP GET request to the target endpoint.\n\nrun(self):\n    Runs the job, making the HTTP request and handling the response.\n</code></pre> Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/jobs/handlers/default/job.py</code> <pre><code>class Job:\n    \"\"\"\n    Represents a job that makes HTTP requests and handles the response.\n\n    Args:\n        config (ConfigDTO): The configuration data for the job.\n        input_data: The input data for the job.\n\n    Attributes:\n        _config (ConfigDTO): The configuration data for the job.\n        _source  (str): The source information from the configuration.\n        _context (str): The context information from the configuration.\n        _input_data (type[warlock.model.Model]): The input data for the job.\n        _job_url (str): The URL for the job.\n        _partition (str): The partition based on input data reference.\n        _target_endpoint (str): The final endpoint URL.\n\n    Methods:\n\n        _get_endpoint(self):\n            Generates the target endpoint URL.\n\n        _get_bucket_name(self):\n            Generates the bucket name for Minio storage.\n\n        _get_status(self, response) -&gt; StatusDTO:\n            Extracts the status information from an HTTP response.\n\n        make_request(self):\n            Makes an HTTP GET request to the target endpoint.\n\n        run(self):\n            Runs the job, making the HTTP request and handling the response.\n\n    \"\"\"\n\n    def __init__(self, config: ConfigDTO, input_data: type[warlock.model.Model]) -&gt; None:\n        self._config = config\n        self._source = config.source\n        self._context = config.context\n        self._input_data = input_data\n        self._job_url = config.job_parameters[\"url\"]\n        self._partition = input_data.partition\n        self._target_endpoint = self._get_endpoint()\n\n    def _get_endpoint(self) -&gt; str:\n        \"\"\"\n        Generates the target endpoint URL.\n\n        Returns:\n            str: The target endpoint URL.\n        \"\"\"\n        return self._job_url.format(self._partition)\n\n    def _get_bucket_name(self) -&gt; str:\n        \"\"\"\n        Generates the bucket name for Minio storage.\n\n        Returns:\n            str: The bucket name.\n        \"\"\"\n        return \"landing-{context}-source-{source}\".format(\n            context=self._context,\n            source=self._source,\n        )\n\n    def _get_status(self, response) -&gt; StatusDTO:\n        \"\"\"\n        Extracts the status information from an HTTP response.\n\n        Args:\n            response: The HTTP response.\n\n        Returns:\n            StatusDTO: The status information.\n        \"\"\"\n        return StatusDTO(\n            code=response.status_code,\n            detail=response.reason,\n        )\n\n    def make_request(self) -&gt; requests.Response:\n        \"\"\"\n        Makes an HTTP GET request to the target endpoint.\n\n        Returns:\n            requests.Response: The HTTP response.\n        \"\"\"\n        logger.info(f\"endpoint: {self._target_endpoint}\")\n        headers = {\n            # Add your headers here\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n            \"Accept-Encoding\": \"gzip, deflate, br\",\n            \"Accept-Language\": \"pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7\",\n            \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:92.0) Gecko/20100101 Firefox/92.0\",\n        }\n        return requests.get(\n            self._target_endpoint,\n            verify=False,\n            headers=headers,\n            timeout=10*60,\n        )\n\n    def run(self) -&gt; Tuple[dict, StatusDTO]:\n        \"\"\"\n        Runs the job, making the HTTP request and handling the response.\n\n        Returns:\n            tuple: A tuple containing result data and status information.\n        \"\"\"\n        logger.info(f\"Job triggered with input: {self._input_data}\")\n        response = self.make_request()\n        minio = minio_client()\n        uri = minio.upload_bytes(self._get_bucket_name(), f\"{self._partition}/{self._source}.zip\", response.content)\n        logger.info(f\"File storage uri: {uri}\")\n        result = {\"documentUri\": uri, \"partition\": self._partition}\n        logger.info(f\"Job result: {result}\")\n        return result, self._get_status(response)\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/jobs/handlers/default/job/#apps.services-raw-layer.file-downloader.file_downloader.jobs.handlers.default.job.Job.make_request","title":"<code>make_request()</code>","text":"<p>Makes an HTTP GET request to the target endpoint.</p> <p>Returns:</p> Type Description <code>Response</code> <p>requests.Response: The HTTP response.</p> Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/jobs/handlers/default/job.py</code> <pre><code>def make_request(self) -&gt; requests.Response:\n    \"\"\"\n    Makes an HTTP GET request to the target endpoint.\n\n    Returns:\n        requests.Response: The HTTP response.\n    \"\"\"\n    logger.info(f\"endpoint: {self._target_endpoint}\")\n    headers = {\n        # Add your headers here\n        \"Sec-Fetch-Site\": \"same-origin\",\n        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n        \"Accept-Encoding\": \"gzip, deflate, br\",\n        \"Accept-Language\": \"pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7\",\n        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:92.0) Gecko/20100101 Firefox/92.0\",\n    }\n    return requests.get(\n        self._target_endpoint,\n        verify=False,\n        headers=headers,\n        timeout=10*60,\n    )\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/jobs/handlers/default/job/#apps.services-raw-layer.file-downloader.file_downloader.jobs.handlers.default.job.Job.run","title":"<code>run()</code>","text":"<p>Runs the job, making the HTTP request and handling the response.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>Tuple[dict, StatusDTO]</code> <p>A tuple containing result data and status information.</p> Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/jobs/handlers/default/job.py</code> <pre><code>def run(self) -&gt; Tuple[dict, StatusDTO]:\n    \"\"\"\n    Runs the job, making the HTTP request and handling the response.\n\n    Returns:\n        tuple: A tuple containing result data and status information.\n    \"\"\"\n    logger.info(f\"Job triggered with input: {self._input_data}\")\n    response = self.make_request()\n    minio = minio_client()\n    uri = minio.upload_bytes(self._get_bucket_name(), f\"{self._partition}/{self._source}.zip\", response.content)\n    logger.info(f\"File storage uri: {uri}\")\n    result = {\"documentUri\": uri, \"partition\": self._partition}\n    logger.info(f\"Job result: {result}\")\n    return result, self._get_status(response)\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/jobs/handlers/youtube/job/","title":"Job","text":""},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/jobs/handlers/youtube/job/#apps.services-raw-layer.file-downloader.file_downloader.jobs.handlers.youtube.job.Job","title":"<code>Job</code>","text":"<p>Represents a job that makes HTTP requests and handles the response.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data for the job.</p> required <code>input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> required <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>The configuration data for the job.</p> <code>_source</code> <code> (str</code> <p>The source information from the configuration.</p> <code>_context</code> <code>str</code> <p>The context information from the configuration.</p> <code>_input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> <code>_job_url</code> <code>str</code> <p>The URL for the job.</p> <code>_partition</code> <code>str</code> <p>The partition based on video id.</p> <code>_target_endpoint</code> <code>str</code> <p>The final endpoint URL.</p> <p>Methods:</p> <pre><code>_get_endpoint(self):\n    Generates the target endpoint URL.\n\n_get_bucket_name(self):\n    Generates the bucket name for Minio storage.\n\n_get_status(self, response) -&gt; StatusDTO:\n    Extracts the status information from an HTTP response.\n\nmake_request(self):\n    Makes an HTTP GET request to the target endpoint.\n\nrun(self):\n    Runs the job, making the HTTP request and handling the response.\n</code></pre> Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/jobs/handlers/youtube/job.py</code> <pre><code>class Job:\n    \"\"\"\n    Represents a job that makes HTTP requests and handles the response.\n\n    Args:\n        config (ConfigDTO): The configuration data for the job.\n        input_data: The input data for the job.\n\n    Attributes:\n        _config (ConfigDTO): The configuration data for the job.\n        _source  (str): The source information from the configuration.\n        _context (str): The context information from the configuration.\n        _input_data (type[warlock.model.Model]): The input data for the job.\n        _job_url (str): The URL for the job.\n        _partition (str): The partition based on video id.\n        _target_endpoint (str): The final endpoint URL.\n\n    Methods:\n\n        _get_endpoint(self):\n            Generates the target endpoint URL.\n\n        _get_bucket_name(self):\n            Generates the bucket name for Minio storage.\n\n        _get_status(self, response) -&gt; StatusDTO:\n            Extracts the status information from an HTTP response.\n\n        make_request(self):\n            Makes an HTTP GET request to the target endpoint.\n\n        run(self):\n            Runs the job, making the HTTP request and handling the response.\n\n    \"\"\"\n\n    def __init__(self, config: ConfigDTO, input_data: type[warlock.model.Model]) -&gt; None:\n        self._config = config\n        self._source = config.source\n        self._context = config.context\n        self._input_data = input_data\n        self._job_url = config.job_parameters[\"url\"]\n        self._partition = input_data.videoId\n        self._target_endpoint = self._get_endpoint()\n\n    def _get_endpoint(self) -&gt; str:\n        \"\"\"\n        Generates the target endpoint URL.\n\n        Returns:\n            str: The target endpoint URL.\n        \"\"\"\n        return self._job_url.format(self._partition)\n\n    def _get_bucket_name(self) -&gt; str:\n        \"\"\"\n        Generates the bucket name for Minio storage.\n\n        Returns:\n            str: The bucket name.\n        \"\"\"\n        return \"landing-{context}-source-{source}\".format(\n            context=self._context,\n            source=self._source,\n        )\n\n    def _get_status(self) -&gt; StatusDTO:\n        \"\"\"\n        Extracts the status information from an HTTP response.\n\n        Args:\n            response: The HTTP response.\n\n        Returns:\n            StatusDTO: The status information.\n        \"\"\"\n        return StatusDTO(\n            code=200,\n            detail=\"Success\",\n        )\n\n    def make_request(self) -&gt; io.BytesIO:\n        \"\"\"\n        Makes a video download from youtube by the id provided.\n\n        Returns:\n            io.BytesIO: The video bytes.\n        \"\"\"\n        logger.info(f\"endpoint: {self._target_endpoint}\")\n        return download_to_buffer(self._target_endpoint)\n\n\n    def run(self) -&gt; Tuple[dict, StatusDTO]:\n        \"\"\"\n        Runs the job, making the HTTP request and handling the response.\n\n        Returns:\n            tuple: A tuple containing result data and status information.\n        \"\"\"\n        logger.info(f\"Job triggered with input: {self._input_data}\")\n        video = self.make_request()\n        minio = minio_client()\n\n        uri = minio.upload_bytes(self._get_bucket_name(), f\"{self._partition}/video.mp4\", video)\n\n\n        logger.info(f\"File storage uri: {uri}\")\n        result = {\"documentUri\": uri, \"partition\": self._partition}\n        logger.info(f\"Job result: {result}\")\n        return result, self._get_status()\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/jobs/handlers/youtube/job/#apps.services-raw-layer.file-downloader.file_downloader.jobs.handlers.youtube.job.Job.make_request","title":"<code>make_request()</code>","text":"<p>Makes a video download from youtube by the id provided.</p> <p>Returns:</p> Type Description <code>BytesIO</code> <p>io.BytesIO: The video bytes.</p> Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/jobs/handlers/youtube/job.py</code> <pre><code>def make_request(self) -&gt; io.BytesIO:\n    \"\"\"\n    Makes a video download from youtube by the id provided.\n\n    Returns:\n        io.BytesIO: The video bytes.\n    \"\"\"\n    logger.info(f\"endpoint: {self._target_endpoint}\")\n    return download_to_buffer(self._target_endpoint)\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-downloader/code_reference/file_downloader/jobs/handlers/youtube/job/#apps.services-raw-layer.file-downloader.file_downloader.jobs.handlers.youtube.job.Job.run","title":"<code>run()</code>","text":"<p>Runs the job, making the HTTP request and handling the response.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>Tuple[dict, StatusDTO]</code> <p>A tuple containing result data and status information.</p> Source code in <code>apps/services-raw-layer/file-downloader/file_downloader/jobs/handlers/youtube/job.py</code> <pre><code>def run(self) -&gt; Tuple[dict, StatusDTO]:\n    \"\"\"\n    Runs the job, making the HTTP request and handling the response.\n\n    Returns:\n        tuple: A tuple containing result data and status information.\n    \"\"\"\n    logger.info(f\"Job triggered with input: {self._input_data}\")\n    video = self.make_request()\n    minio = minio_client()\n\n    uri = minio.upload_bytes(self._get_bucket_name(), f\"{self._partition}/video.mp4\", video)\n\n\n    logger.info(f\"File storage uri: {uri}\")\n    result = {\"documentUri\": uri, \"partition\": self._partition}\n    logger.info(f\"Job result: {result}\")\n    return result, self._get_status()\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-unzip/","title":"file-unzip","text":"<p><code>file-unzip</code> is a Golang-based service that performs the following tasks:</p> <ul> <li>Unzip files stored in a bucket (raw layer).</li> <li>Apply a slicer in each file inside the zip file (chunk size: 128MB)</li> <li>Store the zip file content in a bucket (raw layer).</li> <li>Publishes the bucket location to a message queue for further consumption.</li> </ul>"},{"location":"reference/apps/services-raw-layer/file-unzip/#service-components","title":"Service Components","text":"<p>The service consists in a simple consumer for a queue, each serving a specific purpose. Here's an overview of these components:</p>"},{"location":"reference/apps/services-raw-layer/file-unzip/#main-module","title":"Main Module","text":"<ul> <li><code>main.go</code>: The entry point of the service.</li> <li>Creates consumer for specific queue that its bind with a regex routing key to receives all messages with the service destiny.</li> <li>Creates Listeners that can handle with use cases approach.</li> <li>Register all the listeners in the consumer than run the consumer.</li> </ul>"},{"location":"reference/apps/services-raw-layer/file-unzip/#consumer-module","title":"Consumer Module","text":"<ul> <li><code>file_unzip/internal/infra/consumer/consumer.go</code>: Contains the <code>RunConsumers</code> method responsible for starts consuming events for all Listeners registered.</li> <li>This method listens to a RabbitMQ exchange in a goroutine, processes incoming data, and trigger the results to the listener.</li> </ul>"},{"location":"reference/apps/services-raw-layer/file-unzip/#listener-module","title":"listener Module","text":"<ul> <li> <p><code>file_unzip/internal/infra/consumer/listener/listener.go</code>: This package contains the <code>MessageHandlerInterface</code> interface, which is responsible for handling the listener dependency injection.</p> </li> <li> <p><code>file_unzip/internal/infra/consumer/listener/service_input_listener.go</code>: This package is responsible to get the message in the channel unmarshal in the structure to execute an use case then dispatch the result to a rabbitMQ exchange.</p> </li> </ul>"},{"location":"reference/apps/services-raw-layer/file-unzip/#job-handling-module","title":"Job Handling Module","text":"<ul> <li><code>file_unzip/internal/usecase/unzip_file.go</code>: Handles the execution of jobs related to unzip and storing the file in a bucket.</li> <li>It uses a slicer in each file to resize the file to 128MB.</li> </ul>"},{"location":"reference/apps/services-raw-layer/file-unzip/#how-to-run-the-service","title":"How to Run the Service","text":"<p>To run your service, follow these steps:</p> <ol> <li> <p>Setup Configuration:</p> <ul> <li>Create a <code>.env.{ENVIRONMENT}</code> file based on the example provided in the <code>envs</code> folder.</li> </ul> </li> <li> <p>Build The Service:</p> </li> </ol> <pre><code>npx nx image services-raw-layer-file-unzip --env=&lt;ENVIRONMENT&gt;\n</code></pre> <ol> <li>Run the Application:</li> </ol> <pre><code>docker-compose up -d\n</code></pre>"},{"location":"reference/apps/services-raw-layer/file-unzip/#architecture-diagram","title":"Architecture Diagram","text":""},{"location":"reference/apps/services-raw-layer/file-unzip/#c4-diagram","title":"C4 Diagram","text":"<p>Please note that this README provides a high-level overview of your service's structure and components. To run the service effectively, make sure to provide the required configurations and customize the job handler logic according to your specific use case.</p> <p>If you have any questions or need further assistance, feel free to ask.</p>"},{"location":"reference/apps/services-raw-layer/media-transcoder/","title":"media-transcoder","text":"<p><code>media-transcoder</code> is a Python-based service that performs the following tasks:</p> <ul> <li>Extract Audio from a video of a specific source in a event approach.</li> <li>Store the Audio in a bucket (raw layer).</li> <li>Publishes the bucket location to a message queue for further consumption.</li> </ul>"},{"location":"reference/apps/services-raw-layer/media-transcoder/#service-components","title":"Service Components","text":"<p>The service consists of multiple Python modules and classes, each serving a specific purpose. Here's an overview of these components:</p>"},{"location":"reference/apps/services-raw-layer/media-transcoder/#main-module","title":"Main Module","text":"<ul> <li><code>main.py</code>: The entry point of the service.</li> <li>It initializes various configurations, including the service name and context environment.</li> <li>Creates consumers for specific configurations and starts processing data.</li> <li>Each config has it owns queue consumption.</li> </ul>"},{"location":"reference/apps/services-raw-layer/media-transcoder/#consumer-module","title":"Consumer Module","text":"<ul> <li><code>media_transcoder/consumer/consumer.py</code>: Contains the <code>EventConsumer</code> class responsible for consume an input message and trigger the callback.</li> <li>This class listens to a RabbitMQ queue, processes incoming data, and trigger the results to the controller.</li> </ul>"},{"location":"reference/apps/services-raw-layer/media-transcoder/#controller-module","title":"Controller Module","text":"<ul> <li> <p><code>media_transcoder/controller/controller.py</code>: This module contains the <code>EventController</code> class, which is responsible for handling the business logic related to event processing.</p> </li> <li> <p>The <code>EventController</code> class receives the processed data from the <code>EventConsumer</code>.</p> </li> <li>It checks if the controller should be active based on the configuration.</li> <li>If active, it parses and processes the data using the job handler.</li> <li>It triggers the job dispatcher to execute the job and collect the results.</li> <li>It publishes the results, including the storage URI, to a message queue for further consumption.</li> </ul> <p>The <code>EventController</code> class plays a crucial role in orchestrating the event-driven processing of data within the service.</p> <p>This class ensures that the service processes incoming data efficiently, initiates the appropriate job handler for the task, and communicates the results to the relevant channels.</p>"},{"location":"reference/apps/services-raw-layer/media-transcoder/#job-handling-module","title":"Job Handling Module","text":"<ul> <li><code>media_transcoder/jobs/job_handler.py</code>: Handles the execution of jobs related to downloading and storing the file in a bucket.</li> <li>It uses a specific job handler module based on the configuration.</li> </ul>"},{"location":"reference/apps/services-raw-layer/media-transcoder/#job-handler-module","title":"Job Handler Module","text":""},{"location":"reference/apps/services-raw-layer/media-transcoder/#audio-clip-handler","title":"Audio Clip Handler","text":"<ul> <li><code>jobs/handlers/audio_clip/job.py</code>: An example job handler module.</li> <li>It defines the logic for extracting the audio from a video.</li> <li>It uploads the downloaded data to a Minio storage bucket.</li> <li>It returns the job result, including the storage URI and status.</li> </ul>"},{"location":"reference/apps/services-raw-layer/media-transcoder/#libraries-dependencies","title":"Libraries Dependencies:","text":""},{"location":"reference/apps/services-raw-layer/media-transcoder/#configuration-module","title":"Configuration Module","text":"<ul> <li><code>config_loader</code>: Loads configurations for the service, such as the source, job handler, service parameters and job parameters also.</li> </ul>"},{"location":"reference/apps/services-raw-layer/media-transcoder/#rabbitmq-module","title":"RabbitMQ Module","text":"<ul> <li><code>pyrabbitmq</code>: Handles the interaction with RabbitMQ, including creating channels, queues, and publishing messages.</li> </ul>"},{"location":"reference/apps/services-raw-layer/media-transcoder/#service-discovery-module","title":"Service Discovery Module","text":"<ul> <li><code>pysd</code>: Manages service discovery and RabbitMQ endpoints.</li> </ul>"},{"location":"reference/apps/services-raw-layer/media-transcoder/#architecture-diagram","title":"Architecture Diagram","text":""},{"location":"reference/apps/services-raw-layer/media-transcoder/#c4-diagram","title":"C4 Diagram","text":""},{"location":"reference/apps/services-raw-layer/media-transcoder/#service-diagram","title":"Service Diagram","text":""},{"location":"reference/apps/services-raw-layer/media-transcoder/#how-to-run-the-service","title":"How to Run the Service","text":"<p>To run your service, follow these steps:</p> <ol> <li> <p>Setup Configuration:</p> <ul> <li>Create a <code>.env.{ENVIRONMENT}</code> file based on the example provided in the <code>envs</code> folder.</li> </ul> </li> <li> <p>Build The Service:</p> </li> </ol> <pre><code>npx nx image services-raw-layer-media-transcoder --env=&lt;ENVIRONMENT&gt;\n</code></pre> <ol> <li>Run the Application:</li> </ol> <pre><code>docker-compose up -d\n</code></pre> <p>Please note that this README provides a high-level overview of your service's structure and components. To run the service effectively, make sure to provide the required configurations and customize the job handler logic according to your specific use case.</p> <p>If you have any questions or need further assistance, feel free to ask.</p>"},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/consumer/consumer/","title":"Consumer","text":""},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/consumer/consumer/#apps.services-raw-layer.media-transcoder.media_transcoder.consumer.consumer.Consumer","title":"<code>Consumer</code>","text":"<p>The base class for creating data consumers.</p> <p>Parameters:</p> Name Type Description Default <code>sd</code> <code>ServiceDiscovery</code> <p>An instance of the ServiceDiscovery class.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required Source code in <code>apps/services-raw-layer/media-transcoder/media_transcoder/consumer/consumer.py</code> <pre><code>class Consumer:\n    \"\"\"\n    The base class for creating data consumers.\n\n    Args:\n        sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    \"\"\"\n    def __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue):\n        self._config = config\n        self._rabbitmq_service = rabbitmq_service\n        self._queue_active_jobs = queue_active_jobs\n        self._exchange_name = sd.services_rabbitmq_exchange()\n        self._queue_name = _get_queue_name(config)\n        self._routing_key = _get_routing_key(config)\n\n    async def _run(self, controller: callable) -&gt; None:\n        \"\"\"\n        Run the consumer with the specified controller.\n\n        Args:\n            controller (callable): The controller class responsible for processing data.\n\n        \"\"\"\n        channel = await self._rabbitmq_service.create_channel()\n        queue = await self._rabbitmq_service.create_queue(\n            channel,\n            self._queue_name,\n            self._exchange_name,\n            self._routing_key\n        )\n        logger.info(f\"Listening to queue: {self._queue_name}\")\n        await self._rabbitmq_service.listen(queue, controller(self._config, self._rabbitmq_service, self._queue_active_jobs).run)\n</code></pre>"},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/consumer/consumer/#apps.services-raw-layer.media-transcoder.media_transcoder.consumer.consumer.EventConsumer","title":"<code>EventConsumer</code>","text":"<p>             Bases: <code>Consumer</code></p> <p>The EventConsumer class for processing event data.</p> <p>Parameters:</p> Name Type Description Default <code>sd</code> <code>ServiceDiscovery</code> <p>An instance of the ServiceDiscovery class.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required Source code in <code>apps/services-raw-layer/media-transcoder/media_transcoder/consumer/consumer.py</code> <pre><code>class EventConsumer(Consumer):\n    \"\"\"\n    The EventConsumer class for processing event data.\n\n    Args:\n        sd (ServiceDiscovery): An instance of the ServiceDiscovery class.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    \"\"\"\n    def __init__(self, sd: ServiceDiscovery, rabbitmq_service: RabbitMQConsumer, config: ConfigDTO, queue_active_jobs: asyncio.Queue):\n        super().__init__(sd, rabbitmq_service, config, queue_active_jobs)\n\n    async def run(self) -&gt; None:\n        \"\"\"\n        Run the EventConsumer to process event data.\n\n        This method triggers the processing of incoming event data using the specified controller.\n\n        \"\"\"\n        await self._run(EventController)\n</code></pre>"},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/consumer/consumer/#apps.services-raw-layer.media-transcoder.media_transcoder.consumer.consumer.EventConsumer.run","title":"<code>run()</code>  <code>async</code>","text":"<p>Run the EventConsumer to process event data.</p> <p>This method triggers the processing of incoming event data using the specified controller.</p> Source code in <code>apps/services-raw-layer/media-transcoder/media_transcoder/consumer/consumer.py</code> <pre><code>async def run(self) -&gt; None:\n    \"\"\"\n    Run the EventConsumer to process event data.\n\n    This method triggers the processing of incoming event data using the specified controller.\n\n    \"\"\"\n    await self._run(EventController)\n</code></pre>"},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/controller/controller/","title":"Controller","text":""},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/controller/controller/#apps.services-raw-layer.media-transcoder.media_transcoder.controller.controller.Controller","title":"<code>Controller</code>","text":"<p>Base class for handling event data processing.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required Source code in <code>apps/services-raw-layer/media-transcoder/media_transcoder/controller/controller.py</code> <pre><code>class Controller:\n    \"\"\"\n    Base class for handling event data processing.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    \"\"\"\n    def __init__(self, config: ConfigDTO, queue_active_jobs: asyncio.Queue):\n        self._config = config\n        self._config_id = config.id\n        self._service_name = config.service\n        self._source_name = config.source\n        self._context_env = config.context\n        self._repository_schema_type = _REPOSITORY_SCHEMA_TYPE\n        self._queue_active_jobs = queue_active_jobs\n        self._active = config.active\n        self._schema_handler_client = async_py_schema_handler_client()\n        self._input_body_dto = None\n\n    def _should_cotroller_active(self) -&gt; bool:\n        \"\"\"\n        Check if the controller should be active based on the configuration.\n\n        Returns:\n            bool: True if the controller is active, False otherwise.\n\n        \"\"\"\n        if self._active:\n            return True\n        return False\n\n    async def _get_event_parser(self) -&gt; Dict[str, any]:\n        \"\"\"\n        Get the event parser JSON schema for data processing.\n\n        Returns:\n            Dict[str, any]: The JSON schema for data processing.\n\n        \"\"\"\n        self.schema_input = await self._schema_handler_client.list_one_schema_by_service_n_source_n_context_n_schema_type(\n            context=self._context_env,\n            service_name=self._service_name,\n            source_name=self._source_name,\n            schema_type=self._repository_schema_type\n        )\n        json_schema = self.schema_input.json_schema\n        return json_schema\n\n    async def _parse_event(self, message: str) -&gt; type[warlock.model.Model]:\n        \"\"\"\n        Parse the incoming event message and transform it into the appropriate data format.\n\n        Args:\n            message (str): The incoming event message.\n\n        Returns:\n            object: The parsed event data in the required data format.\n\n        Raises:\n            ValueError: If the message body cannot be parsed.\n\n        \"\"\"\n        message_body = message.body.decode()\n        event_parser_class = await self._get_event_parser()\n        try:\n            input_body = json.loads(message_body)\n            self._input_body_dto = serialize_to_dataclass(input_body, InputDTO)\n\n            input_data = self._input_body_dto.data\n            Input_dataclass = warlock.model_factory(event_parser_class)\n            return Input_dataclass(**input_data)\n        except json.JSONDecodeError as e:\n            logger.error(f\"Failed to parse message body: {e}\")\n            raise ValueError(\"Invalid message body\")\n\n    def _get_metadata(self) -&gt; MetadataDTO:\n        \"\"\"\n        Generate metadata information for the processed event data.\n\n        Returns:\n            MetadataDTO: Metadata information for the event data.\n\n        \"\"\"\n        return MetadataDTO(\n            input=MetadataInputDTO(\n                id=self._input_body_dto.id,\n                data=self._input_body_dto.data,\n                processing_id=self._input_body_dto.metadata[\"processing_id\"],\n                processing_timestamp=self._input_body_dto.metadata[\"processing_timestamp\"],\n                input_schema_id=self.schema_input.schema_id\n            ),\n            context=self._config.context,\n            service=self._config.service,\n            source=self._config.source,\n            processing_timestamp=datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n            job_frequency=self._config.frequency,\n            job_config_id=self._config.config_id,\n        )\n\n    async def job_dispatcher(self, event_input) -&gt; ServiceFeedbackDTO:\n        \"\"\"\n        Dispatch a job to process the event input data and collect the results.\n\n        Args:\n            event_input: The input data for the job.\n\n        Returns:\n            ServiceFeedbackDTO: Feedback and result information from the job processing.\n\n        \"\"\"\n        await self._queue_active_jobs.put(1)\n        job_data, status_data = JobHandler(self._config).run(event_input)\n        return ServiceFeedbackDTO(\n            data=job_data,\n            metadata=self._get_metadata(),\n            status=status_data,\n        )\n</code></pre>"},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/controller/controller/#apps.services-raw-layer.media-transcoder.media_transcoder.controller.controller.Controller.job_dispatcher","title":"<code>job_dispatcher(event_input)</code>  <code>async</code>","text":"<p>Dispatch a job to process the event input data and collect the results.</p> <p>Parameters:</p> Name Type Description Default <code>event_input</code> <p>The input data for the job.</p> required <p>Returns:</p> Name Type Description <code>ServiceFeedbackDTO</code> <code>ServiceFeedbackDTO</code> <p>Feedback and result information from the job processing.</p> Source code in <code>apps/services-raw-layer/media-transcoder/media_transcoder/controller/controller.py</code> <pre><code>async def job_dispatcher(self, event_input) -&gt; ServiceFeedbackDTO:\n    \"\"\"\n    Dispatch a job to process the event input data and collect the results.\n\n    Args:\n        event_input: The input data for the job.\n\n    Returns:\n        ServiceFeedbackDTO: Feedback and result information from the job processing.\n\n    \"\"\"\n    await self._queue_active_jobs.put(1)\n    job_data, status_data = JobHandler(self._config).run(event_input)\n    return ServiceFeedbackDTO(\n        data=job_data,\n        metadata=self._get_metadata(),\n        status=status_data,\n    )\n</code></pre>"},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/controller/controller/#apps.services-raw-layer.media-transcoder.media_transcoder.controller.controller.EventController","title":"<code>EventController</code>","text":"<p>             Bases: <code>Controller</code></p> <p>EventController class for processing event data.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data.</p> required <code>rabbitmq_service</code> <code>RabbitMQConsumer</code> <p>An instance of the RabbitMQConsumer class.</p> required <code>queue_active_jobs</code> <code>Queue</code> <p>An asyncio queue for active jobs.</p> required Source code in <code>apps/services-raw-layer/media-transcoder/media_transcoder/controller/controller.py</code> <pre><code>class EventController(Controller):\n    \"\"\"\n    EventController class for processing event data.\n\n    Args:\n        config (ConfigDTO): The configuration data.\n        rabbitmq_service (RabbitMQConsumer): An instance of the RabbitMQConsumer class.\n        queue_active_jobs (asyncio.Queue): An asyncio queue for active jobs.\n\n    \"\"\"\n    def __init__(self, config: ConfigDTO, rabbitmq_service: RabbitMQConsumer, queue_active_jobs: asyncio.Queue) -&gt; None:\n        self._rabbitmq_service = rabbitmq_service\n        super().__init__(config, queue_active_jobs)\n\n    async def run(self, message) -&gt; None:\n        \"\"\"\n        Run the EventController to process event data.\n\n        This method initiates the processing of incoming event data using the specified controller logic.\n\n        Args:\n            message: The incoming event message.\n\n        \"\"\"\n        logger.info(f\"Processing message: {message}\")\n        if not self._should_cotroller_active():\n            logger.warning(f\"Controller for config_id {self._config_id} is not active\")\n            return\n\n        await self._rabbitmq_service.publish_message(\n            \"services\",\n            \"input-processing\",\n            json.dumps(json.loads(message.body.decode()))\n        )\n\n        event_input = await self._parse_event(message)\n        job_result = await self.job_dispatcher(event_input)\n        output = serialize_to_json(job_result)\n        logger.info(f\"sleeping for 5 seconds...\")\n        time.sleep(5)\n        logger.info(f\"Output: {output}\")\n        await self._rabbitmq_service.publish_message(\n                \"services\",\n                \"feedback\",\n                output\n            )\n        await message.ack()\n        await self._queue_active_jobs.get()\n        logger.info(\"Published message to service\")\n</code></pre>"},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/controller/controller/#apps.services-raw-layer.media-transcoder.media_transcoder.controller.controller.EventController.run","title":"<code>run(message)</code>  <code>async</code>","text":"<p>Run the EventController to process event data.</p> <p>This method initiates the processing of incoming event data using the specified controller logic.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <p>The incoming event message.</p> required Source code in <code>apps/services-raw-layer/media-transcoder/media_transcoder/controller/controller.py</code> <pre><code>async def run(self, message) -&gt; None:\n    \"\"\"\n    Run the EventController to process event data.\n\n    This method initiates the processing of incoming event data using the specified controller logic.\n\n    Args:\n        message: The incoming event message.\n\n    \"\"\"\n    logger.info(f\"Processing message: {message}\")\n    if not self._should_cotroller_active():\n        logger.warning(f\"Controller for config_id {self._config_id} is not active\")\n        return\n\n    await self._rabbitmq_service.publish_message(\n        \"services\",\n        \"input-processing\",\n        json.dumps(json.loads(message.body.decode()))\n    )\n\n    event_input = await self._parse_event(message)\n    job_result = await self.job_dispatcher(event_input)\n    output = serialize_to_json(job_result)\n    logger.info(f\"sleeping for 5 seconds...\")\n    time.sleep(5)\n    logger.info(f\"Output: {output}\")\n    await self._rabbitmq_service.publish_message(\n            \"services\",\n            \"feedback\",\n            output\n        )\n    await message.ack()\n    await self._queue_active_jobs.get()\n    logger.info(\"Published message to service\")\n</code></pre>"},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/jobs/job_handler/","title":"Job handler","text":""},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/jobs/job_handler/#apps.services-raw-layer.media-transcoder.media_transcoder.jobs.job_handler.JobHandler","title":"<code>JobHandler</code>","text":"<p>Represents a job handler that runs a specific job based on configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data for the job handler.</p> required <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>The configuration data for the job handler.</p> <code>_job_handler</code> <code>str</code> <p>The name of the job handler.</p> <code>_config_id</code> <code>int</code> <p>The unique identifier for the configuration.</p> <code>_module</code> <code>module</code> <p>The imported module for the specified job handler.</p> <p>Methods:</p> Name Description <code>_import_job_handler_as_module</code> <p>Imports the job handler module based on the provided configuration.</p> <code>run</code> <p>Runs the job associated with the configuration.</p> <p>Args:     source_input: The input data for the job.</p> <p>Returns:     tuple: A tuple containing job_data, job_status, and target_endpoint.</p> Source code in <code>apps/services-raw-layer/media-transcoder/media_transcoder/jobs/job_handler.py</code> <pre><code>class JobHandler:\n    \"\"\"\n    Represents a job handler that runs a specific job based on configuration.\n\n    Args:\n        config (ConfigDTO): The configuration data for the job handler.\n\n    Attributes:\n        _config (ConfigDTO): The configuration data for the job handler.\n        _job_handler (str): The name of the job handler.\n        _config_id (int): The unique identifier for the configuration.\n        _module (module): The imported module for the specified job handler.\n\n    Methods:\n        _import_job_handler_as_module(self):\n            Imports the job handler module based on the provided configuration.\n\n        run(self, source_input):\n            Runs the job associated with the configuration.\n\n            Args:\n                source_input: The input data for the job.\n\n            Returns:\n                tuple: A tuple containing job_data, job_status, and target_endpoint.\n\n    \"\"\"\n\n    def __init__(self, config: ConfigDTO) -&gt; None:\n        self._config = config\n        self._job_handler = config.service_parameters[\"job_handler\"]\n        self._config_id = config.id\n        self._module = self._import_job_handler_as_module()\n\n    def _import_job_handler_as_module(self):\n        \"\"\"\n        Import the job handler module based on the specified job handler name.\n\n        Returns:\n            module: The imported module for the job handler.\n        \"\"\"\n        return importlib.import_module(f\"jobs.handlers.{self._job_handler}.job\")\n\n    def run(self, source_input: type[warlock.model.Model]) -&gt; Tuple[dict, StatusDTO]:\n        \"\"\"\n        Run the job associated with the configuration.\n\n        Args:\n            source_input: The input data for the job.\n\n        Returns:\n            tuple: A tuple containing job_data and job_status.\n        \"\"\"\n        logger.info(f\"[RUNNING JOB] - Config ID: {self._config_id} - handler: {self._job_handler}\")\n        job_data, job_status = self._module.Job(self._config, source_input).run()\n        return job_data, job_status\n</code></pre>"},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/jobs/job_handler/#apps.services-raw-layer.media-transcoder.media_transcoder.jobs.job_handler.JobHandler.run","title":"<code>run(source_input)</code>","text":"<p>Run the job associated with the configuration.</p> <p>Parameters:</p> Name Type Description Default <code>source_input</code> <code>type[Model]</code> <p>The input data for the job.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>Tuple[dict, StatusDTO]</code> <p>A tuple containing job_data and job_status.</p> Source code in <code>apps/services-raw-layer/media-transcoder/media_transcoder/jobs/job_handler.py</code> <pre><code>def run(self, source_input: type[warlock.model.Model]) -&gt; Tuple[dict, StatusDTO]:\n    \"\"\"\n    Run the job associated with the configuration.\n\n    Args:\n        source_input: The input data for the job.\n\n    Returns:\n        tuple: A tuple containing job_data and job_status.\n    \"\"\"\n    logger.info(f\"[RUNNING JOB] - Config ID: {self._config_id} - handler: {self._job_handler}\")\n    job_data, job_status = self._module.Job(self._config, source_input).run()\n    return job_data, job_status\n</code></pre>"},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/jobs/handlers/audio_clip/job/","title":"Job","text":""},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/jobs/handlers/audio_clip/job/#apps.services-raw-layer.media-transcoder.media_transcoder.jobs.handlers.audio_clip.job.Job","title":"<code>Job</code>","text":"<p>Represents a job that makes HTTP requests and handles the response.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data for the job.</p> required <code>input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> required <p>Attributes:</p> Name Type Description <code>_config</code> <code>ConfigDTO</code> <p>The configuration data for the job.</p> <code>_source</code> <code>str</code> <p>The source information from the configuration.</p> <code>_context</code> <code>str</code> <p>The context information from the configuration.</p> <code>_input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> <code>_partition</code> <code>str</code> <p>The partition based on video id.</p> <code>_target_endpoint</code> <code>str</code> <p>The final endpoint URL.</p> <p>Methods:</p> Name Description <code>_get_bucket_name</code> <p>str) -&gt; str: Generates the bucket name for Minio storage.</p> <code>_get_status</code> <p>Extracts the status information from an HTTP response.</p> <code>make_request</code> <p>MinioClient, audio_path: str) -&gt; None: Download a video from Minio, convert it to audio, and save the audio file.</p> <code>convert_video_bytes_to_audio</code> <p>bytes, audio_path: str) -&gt; None: Convert a video in bytes format to audio and save it as a separate file.</p> <code>run</code> <p>Runs the job, making the HTTP request and handling the response.</p> Source code in <code>apps/services-raw-layer/media-transcoder/media_transcoder/jobs/handlers/audio_clip/job.py</code> <pre><code>class Job:\n    \"\"\"\n    Represents a job that makes HTTP requests and handles the response.\n\n    Args:\n        config (ConfigDTO): The configuration data for the job.\n        input_data (type[warlock.model.Model]): The input data for the job.\n\n    Attributes:\n        _config (ConfigDTO): The configuration data for the job.\n        _source (str): The source information from the configuration.\n        _context (str): The context information from the configuration.\n        _input_data (type[warlock.model.Model]): The input data for the job.\n        _partition (str): The partition based on video id.\n        _target_endpoint (str): The final endpoint URL.\n\n    Methods:\n        _get_bucket_name(self, layer: str) -&gt; str:\n            Generates the bucket name for Minio storage.\n\n        _get_status(self) -&gt; StatusDTO:\n            Extracts the status information from an HTTP response.\n\n        make_request(self, minio: MinioClient, audio_path: str) -&gt; None:\n            Download a video from Minio, convert it to audio, and save the audio file.\n\n        convert_video_bytes_to_audio(self, video_bytes: bytes, audio_path: str) -&gt; None:\n            Convert a video in bytes format to audio and save it as a separate file.\n\n        run(self) -&gt; Tuple[dict, StatusDTO, str]:\n            Runs the job, making the HTTP request and handling the response.\n\n    \"\"\"\n\n    def __init__(self, config: ConfigDTO, input_data: type[warlock.model.Model]) -&gt; None:\n        \"\"\"\n        Initialize the Job instance.\n\n        Args:\n            config (ConfigDTO): The configuration data for the job.\n            input_data (type[warlock.model.Model]): The input data for the job.\n\n        Returns:\n            None\n        \"\"\"\n        self._config = config\n        self._source = config.source\n        self._context = config.context\n        self._input_data = input_data\n        self._partition = input_data.partition\n        self._target_endpoint = input_data.documentUri\n\n    def _get_bucket_name(self, layer: str) -&gt; str:\n        \"\"\"\n        Generates the bucket name for Minio storage.\n\n        Args:\n            layer (str): The layer of the bucket.\n\n        Returns:\n            str: The bucket name.\n        \"\"\"\n        return \"{layer}-{context}-source-{source}\".format(\n            layer=layer,\n            context=self._context,\n            source=self._source,\n        )\n\n    def _get_status(self) -&gt; StatusDTO:\n        \"\"\"\n        Extracts the status information from an HTTP response.\n\n        Returns:\n            StatusDTO: The status information.\n        \"\"\"\n        return StatusDTO(\n            code=200,\n            detail=\"Success\",\n        )\n\n    def make_request(self, minio: MinioClient, audio_path: str) -&gt; None:\n        \"\"\"\n        Download a video from Minio, convert it to audio, and save the audio file.\n\n        Args:\n            minio (MinioClient): An instance of the MinioClient for interacting with Minio.\n            audio_path (str): The local path where the audio file will be saved.\n\n        Returns:\n            None\n\n        \"\"\"\n        logger.info(f\"endpoint: {self._target_endpoint}\")\n        file_bytes = minio.download_file_as_bytes(self._get_bucket_name(layer=\"landing\"), f\"{self._partition}/video.mp4\")\n        self.convert_video_bytes_to_audio(file_bytes, audio_path)\n\n    def convert_video_bytes_to_audio(self, video_bytes: bytes, audio_path: str) -&gt; None:\n        \"\"\"\n        Convert a video in bytes format to audio and save it as a separate file.\n\n        Args:\n            video_bytes (bytes): The video content in bytes.\n            audio_path (str): The local path where the audio file will be saved.\n\n        Raises:\n            Exception: If there is an error converting the video to audio.\n        \"\"\"\n        try:\n            # Create a temporary file to write the video bytes\n            with tempfile.NamedTemporaryFile(delete=False) as temp_video_file:\n                temp_video_file.write(video_bytes)\n\n            # Use VideoFileClip with the temporary file\n            video_clip = VideoFileClip(temp_video_file.name)\n\n            audio_clip = video_clip.audio\n            audio_clip.write_audiofile(audio_path)\n            audio_clip.close()\n            video_clip.close()\n\n            os.remove(temp_video_file.name)\n            logger.info(\"Video converted to audio successfully.\")\n        except Exception as err:\n            raise Exception(f\"Error converting video to audio: {err}\")\n\n\n    def run(self) -&gt; Tuple[dict, StatusDTO]:\n        \"\"\"\n        Convert video content in bytes format to audio and save it as a separate file.\n\n        Returns:\n            tuple: A tuple containing result data and status information.\n\n        \"\"\"\n        logger.info(f\"Job triggered with input: {self._input_data}\")\n        minio = minio_client()\n        audio_path = f\"video-audio.mp3\"\n        video_audio = self.make_request(minio, audio_path)\n                # Upload the audio file to the remote bucket\n        with open(audio_path, 'rb') as audio_file:\n            audio_data = audio_file.read()\n        uri = minio.upload_bytes(self._get_bucket_name(layer=\"raw\"), f\"{self._partition}/audio.mp3\", audio_data)\n        os.remove(audio_path)\n        logger.info(f\"File storage uri: {uri}\")\n        result = {\"documentUri\": uri, \"partition\": self._partition}\n        logger.info(f\"Job result: {result}\")\n        return result, self._get_status()\n</code></pre>"},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/jobs/handlers/audio_clip/job/#apps.services-raw-layer.media-transcoder.media_transcoder.jobs.handlers.audio_clip.job.Job.__init__","title":"<code>__init__(config, input_data)</code>","text":"<p>Initialize the Job instance.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ConfigDTO</code> <p>The configuration data for the job.</p> required <code>input_data</code> <code>type[Model]</code> <p>The input data for the job.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>apps/services-raw-layer/media-transcoder/media_transcoder/jobs/handlers/audio_clip/job.py</code> <pre><code>def __init__(self, config: ConfigDTO, input_data: type[warlock.model.Model]) -&gt; None:\n    \"\"\"\n    Initialize the Job instance.\n\n    Args:\n        config (ConfigDTO): The configuration data for the job.\n        input_data (type[warlock.model.Model]): The input data for the job.\n\n    Returns:\n        None\n    \"\"\"\n    self._config = config\n    self._source = config.source\n    self._context = config.context\n    self._input_data = input_data\n    self._partition = input_data.partition\n    self._target_endpoint = input_data.documentUri\n</code></pre>"},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/jobs/handlers/audio_clip/job/#apps.services-raw-layer.media-transcoder.media_transcoder.jobs.handlers.audio_clip.job.Job.make_request","title":"<code>make_request(minio, audio_path)</code>","text":"<p>Download a video from Minio, convert it to audio, and save the audio file.</p> <p>Parameters:</p> Name Type Description Default <code>minio</code> <code>MinioClient</code> <p>An instance of the MinioClient for interacting with Minio.</p> required <code>audio_path</code> <code>str</code> <p>The local path where the audio file will be saved.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>apps/services-raw-layer/media-transcoder/media_transcoder/jobs/handlers/audio_clip/job.py</code> <pre><code>def make_request(self, minio: MinioClient, audio_path: str) -&gt; None:\n    \"\"\"\n    Download a video from Minio, convert it to audio, and save the audio file.\n\n    Args:\n        minio (MinioClient): An instance of the MinioClient for interacting with Minio.\n        audio_path (str): The local path where the audio file will be saved.\n\n    Returns:\n        None\n\n    \"\"\"\n    logger.info(f\"endpoint: {self._target_endpoint}\")\n    file_bytes = minio.download_file_as_bytes(self._get_bucket_name(layer=\"landing\"), f\"{self._partition}/video.mp4\")\n    self.convert_video_bytes_to_audio(file_bytes, audio_path)\n</code></pre>"},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/jobs/handlers/audio_clip/job/#apps.services-raw-layer.media-transcoder.media_transcoder.jobs.handlers.audio_clip.job.Job.convert_video_bytes_to_audio","title":"<code>convert_video_bytes_to_audio(video_bytes, audio_path)</code>","text":"<p>Convert a video in bytes format to audio and save it as a separate file.</p> <p>Parameters:</p> Name Type Description Default <code>video_bytes</code> <code>bytes</code> <p>The video content in bytes.</p> required <code>audio_path</code> <code>str</code> <p>The local path where the audio file will be saved.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If there is an error converting the video to audio.</p> Source code in <code>apps/services-raw-layer/media-transcoder/media_transcoder/jobs/handlers/audio_clip/job.py</code> <pre><code>def convert_video_bytes_to_audio(self, video_bytes: bytes, audio_path: str) -&gt; None:\n    \"\"\"\n    Convert a video in bytes format to audio and save it as a separate file.\n\n    Args:\n        video_bytes (bytes): The video content in bytes.\n        audio_path (str): The local path where the audio file will be saved.\n\n    Raises:\n        Exception: If there is an error converting the video to audio.\n    \"\"\"\n    try:\n        # Create a temporary file to write the video bytes\n        with tempfile.NamedTemporaryFile(delete=False) as temp_video_file:\n            temp_video_file.write(video_bytes)\n\n        # Use VideoFileClip with the temporary file\n        video_clip = VideoFileClip(temp_video_file.name)\n\n        audio_clip = video_clip.audio\n        audio_clip.write_audiofile(audio_path)\n        audio_clip.close()\n        video_clip.close()\n\n        os.remove(temp_video_file.name)\n        logger.info(\"Video converted to audio successfully.\")\n    except Exception as err:\n        raise Exception(f\"Error converting video to audio: {err}\")\n</code></pre>"},{"location":"reference/apps/services-raw-layer/media-transcoder/code_reference/media_transcoder/jobs/handlers/audio_clip/job/#apps.services-raw-layer.media-transcoder.media_transcoder.jobs.handlers.audio_clip.job.Job.run","title":"<code>run()</code>","text":"<p>Convert video content in bytes format to audio and save it as a separate file.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>Tuple[dict, StatusDTO]</code> <p>A tuple containing result data and status information.</p> Source code in <code>apps/services-raw-layer/media-transcoder/media_transcoder/jobs/handlers/audio_clip/job.py</code> <pre><code>def run(self) -&gt; Tuple[dict, StatusDTO]:\n    \"\"\"\n    Convert video content in bytes format to audio and save it as a separate file.\n\n    Returns:\n        tuple: A tuple containing result data and status information.\n\n    \"\"\"\n    logger.info(f\"Job triggered with input: {self._input_data}\")\n    minio = minio_client()\n    audio_path = f\"video-audio.mp3\"\n    video_audio = self.make_request(minio, audio_path)\n            # Upload the audio file to the remote bucket\n    with open(audio_path, 'rb') as audio_file:\n        audio_data = audio_file.read()\n    uri = minio.upload_bytes(self._get_bucket_name(layer=\"raw\"), f\"{self._partition}/audio.mp3\", audio_data)\n    os.remove(audio_path)\n    logger.info(f\"File storage uri: {uri}\")\n    result = {\"documentUri\": uri, \"partition\": self._partition}\n    logger.info(f\"Job result: {result}\")\n    return result, self._get_status()\n</code></pre>"},{"location":"reference/libs/golang/resources/go-minio/","title":"go-minio","text":"<p><code>go-minio</code> is a Go library that simplifies interaction with the MinIO object storage server. It provides a convenient way to work with MinIO buckets and objects, including uploading, downloading, and creating buckets.</p>"},{"location":"reference/libs/golang/resources/go-minio/#usage","title":"Usage","text":""},{"location":"reference/libs/golang/resources/go-minio/#importing-the-package","title":"Importing the Package","text":"<p>Import the <code>go-minio</code> package into your Go code:</p> <pre><code>import gominio \"libs/golang/resources/go-minio/client\"\n</code></pre>"},{"location":"reference/libs/golang/resources/go-minio/#creating-a-minioclient","title":"Creating a MinioClient","text":"<p>You can create a <code>MinioClient</code> by providing the MinIO endpoint, access key, and secret key.</p> <pre><code>minioEndpoint := \"minio:9000\"\nminioAccessKey := \"your-access-key\"\nminioSecretKey := \"your-secret-key\"\n\nclient := gominio.NewMinioClient(minioEndpoint, minioAccessKey, minioSecretKey)\n</code></pre>"},{"location":"reference/libs/golang/resources/go-minio/#downloading-an-object","title":"Downloading an Object","text":"<p>To download an object from a MinIO bucket, use the <code>DownloadFile</code> method. Provide the URI of the object you want to download.</p> <pre><code>uri := \"minio.example.com/mybucket/myobject\"\ncontent, err := client.DownloadFile(uri)\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/resources/go-minio/#uploading-a-file","title":"Uploading a File","text":"<p>To upload a file to a MinIO bucket, use the <code>UploadFile</code> method. Provide the bucket name, file name, partition, and the file content as a byte slice.</p> <pre><code>bucketName := \"mybucket\"\nfileName := \"myobject.jpg\"\npartition := \"2023-10-31\"\nfileContent := []byte(\"Your file content here\")\n\npath, err := client.UploadFile(bucketName, fileName, partition, fileContent)\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/resources/go-mongo/","title":"go-mongo","text":"<p><code>go-mongo</code> is a Go library that simplifies interaction with the MongoDB database using the official MongoDB Go driver. It provides a convenient way to create, configure, and manage database connections and access MongoDB features in your Go applications.</p>"},{"location":"reference/libs/golang/resources/go-mongo/#usage","title":"Usage","text":""},{"location":"reference/libs/golang/resources/go-mongo/#importing-the-package","title":"Importing the Package","text":"<p>Import the <code>go-mongo</code> package into your Go code:</p> <pre><code>import mongodb \"libs/golang/resources/go-mongo/client\"\n</code></pre>"},{"location":"reference/libs/golang/resources/go-mongo/#creating-a-mongodb-instance","title":"Creating a MongoDB Instance","text":"<p>You can create a MongoDB instance using the <code>NewMongoDB</code> function. Provide the driver, user, password, host, port, database name, and a context.</p> <pre><code>driver := \"mongodb\"\nuser := \"your-username\"\npassword := \"your-password\"\nhost := \"localhost\"\nport := \"27017\"\ndbName := \"your-database\"\nctx := context.TODO()\n\nmongoDB := mongodb.NewMongoDB(driver, user, password, host, port, dbName, ctx)\n</code></pre>"},{"location":"reference/libs/golang/resources/go-mongo/#connecting-to-mongodb","title":"Connecting to MongoDB","text":"<p>To establish a connection with MongoDB, use the <code>Connect</code> method. This method will make multiple attempts to connect, and you can specify the number of attempts and the interval between them. This helps in handling potential connection issues.</p> <pre><code>client, err := mongoDB.Connect()\nif err != nil {\n    // Handle the connection error\n}\ndefer mongoDB.Disconnect(client)\n</code></pre>"},{"location":"reference/libs/golang/resources/go-mongo/#accessing-the-mongodb-client","title":"Accessing the MongoDB Client","text":"<p>Once connected, you can access the MongoDB client for performing database operations:</p> <pre><code>collection := client.Database(dbName).Collection(\"your-collection\")\n</code></pre>"},{"location":"reference/libs/golang/resources/go-mongo/#disconnecting-from-mongodb","title":"Disconnecting from MongoDB","text":"<p>After using the MongoDB client, make sure to disconnect from the database to release resources. Use the <code>Disconnect</code> method for this purpose.</p>"},{"location":"reference/libs/golang/resources/go-mongo/#example","title":"Example","text":"<p>Here is a simple example of how to use <code>go-mongo</code> to connect to MongoDB and perform a basic operation:</p> <pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"github.com/yourusername/go-mongo\"\n)\n\nfunc main() {\n    driver := \"mongodb\"\n    user := \"your-username\"\n    password := \"your-password\"\n    host := \"localhost\"\n    port := \"27017\"\n    dbName := \"your-database\"\n    ctx := context.TODO()\n\n    mongoDB := mongodb.NewMongoDB(driver, user, password, host, port, dbName, ctx)\n\n    client, err := mongoDB.Connect()\n    if err != nil {\n        fmt.Printf(\"Failed to connect to MongoDB: %v\\n\", err)\n        return\n    }\n    defer mongoDB.Disconnect(client)\n\n    collection := client.Database(dbName).Collection(\"your-collection\")\n    // Perform database operations here\n}\n</code></pre>"},{"location":"reference/libs/golang/resources/go-rabbitmq/","title":"go-rabbitmq","text":"<p><code>go-rabbitmq</code> is a Go library that simplifies interaction with RabbitMQ using the official RabbitMQ Go client library (amqp091-go). It provides a convenient way to create, configure, and manage RabbitMQ connections, channels, and message handling in your Go applications.</p>"},{"location":"reference/libs/golang/resources/go-rabbitmq/#usage","title":"Usage","text":""},{"location":"reference/libs/golang/resources/go-rabbitmq/#importing-the-package","title":"Importing the Package","text":"<p>Import the <code>go-rabbitmq</code> package into your Go code:</p> <pre><code>import \"github.com/yourusername/go-rabbitmq/queue\"\n</code></pre>"},{"location":"reference/libs/golang/resources/go-rabbitmq/#creating-a-rabbitmq-instance","title":"Creating a RabbitMQ Instance","text":"<p>You can create a RabbitMQ instance using the <code>NewRabbitMQ</code> function. Provide the user, password, host, port, vhost, consumer queue name, consumer name, dead-letter exchange name, and protocol.</p> <pre><code>user := \"your-username\"\npassword := \"your-password\"\nhost := \"localhost\"\nport := \"5672\"\nvhost := \"/\"\nconsumerQueueName := \"your-queue\"\nconsumerName := \"your-consumer\"\ndlxName := \"your-dlx\"\nprotocol := \"amqp\"\n\nrabbitMQ := rabbitmq.NewRabbitMQ(user, password, host, port, vhost, consumerQueueName, consumerName, dlxName, protocol)\n</code></pre>"},{"location":"reference/libs/golang/resources/go-rabbitmq/#connecting-to-rabbitmq","title":"Connecting to RabbitMQ","text":"<p>To establish a connection with RabbitMQ, use the <code>Connect</code> method. This method will make multiple attempts to connect, and you can specify the number of attempts and the interval between them. This helps in handling potential connection issues.</p> <pre><code>channel, err := rabbitMQ.Connect()\nif err != nil {\n    // Handle the connection error\n}\ndefer rabbitMQ.Close()\n</code></pre>"},{"location":"reference/libs/golang/resources/go-rabbitmq/#declaring-an-exchange","title":"Declaring an Exchange","text":"<p>You can declare an exchange using the <code>DeclareExchange</code> method. This method checks if the exchange has been declared already and declares it if not.</p> <pre><code>exchangeName := \"your-exchange\"\nexchangeType := \"direct\"\nrabbitMQ.DeclareExchange(exchangeName, exchangeType)\n</code></pre>"},{"location":"reference/libs/golang/resources/go-rabbitmq/#consuming-messages","title":"Consuming Messages","text":"<p>To consume messages from RabbitMQ, use the <code>Consume</code> method. This method sets up a consumer that receives messages from the specified queue and sends them to the provided message channel.</p> <pre><code>messageChannel := make(chan amqp.Delivery)\nexchangeName := \"your-exchange\"\nbindingKey := \"your-binding-key\"\nqueueName := \"your-queue\"\nconsumerName := \"your-consumer\"\ngo rabbitMQ.Consume(messageChannel, exchangeName, bindingKey, queueName, consumerName)\n\nfor message := range messageChannel {\n    // Handle the incoming message\n}\n</code></pre>"},{"location":"reference/libs/golang/resources/go-rabbitmq/#publishing-messages","title":"Publishing Messages","text":"<p>To publish messages to RabbitMQ, use the <code>Notify</code> method. This method allows you to send a message to a specified exchange with the given routing key.</p> <pre><code>message := []byte(\"Your message content\")\ncontentType := \"text/plain\"\nexchange := \"your-exchange\"\nroutingKey := \"your-routing-key\"\n\nerr := rabbitMQ.Notify(message, contentType, exchange, routingKey)\nif err != nil {\n    // Handle the publishing error\n}\n</code></pre>"},{"location":"reference/libs/golang/resources/go-rabbitmq/#example","title":"Example","text":"<p>Here is a simple example of how to use <code>go-rabbitmq</code> to connect to RabbitMQ and consume and publish messages:</p> <pre><code>package main\n\nimport (\n    rabbitmq \"github.com/yourusername/go-rabbitmq/queue\"\n    \"github.com/rabbitmq/amqp091-go\"\n    \"log\"\n)\n\nfunc main() {\n    user := \"your-username\"\n    password := \"your-password\"\n    host := \"localhost\"\n    port := \"5672\"\n    vhost := \"/\"\n    consumerQueueName := \"your-queue\"\n    consumerName := \"your-consumer\"\n    dlxName := \"your-dlx\"\n    protocol := \"amqp\"\n\n    rabbitMQ := rabbitmq.NewRabbitMQ(user, password, host, port, vhost, consumerQueueName, consumerName, dlxName, protocol)\n\n    channel, err := rabbitMQ.Connect()\n    if err != nil {\n        log.Fatalf(\"Failed to connect to RabbitMQ: %v\", err)\n        return\n    }\n    defer rabbitMQ.Close()\n\n    exchangeName := \"your-exchange\"\n    exchangeType := \"direct\"\n    rabbitMQ.DeclareExchange(exchangeName, exchangeType)\n\n    messageChannel := make(chan amqp.Delivery)\n    bindingKey := \"your-binding-key\"\n    queueName := \"your-queue\"\n    consumerName := \"your-consumer\"\n    go rabbitMQ.Consume(messageChannel, exchangeName, bindingKey, queueName, consumerName)\n\n    // Publish a message\n    message := []byte(\"Hello, RabbitMQ!\")\n    contentType := \"text/plain\"\n    exchange := \"your-exchange\"\n    routingKey := \"your-routing-key\"\n\n    err = rabbitMQ.Notify(message, contentType, exchange, routingKey)\n    if err != nil {\n        log.Printf(\"Failed to publish message: %v\", err)\n    }\n\n    for message := range messageChannel {\n        log.Printf(\"Received message: %s\", string(message.Body))\n    }\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-config-handler/","title":"services-config-handler","text":"<p>The <code>services-config-handler</code> API Client is a Go library that allows you to interact with a remote HTTP API for managing configuration data. This client provides a set of methods to perform various operations on configurations, such as creating new configurations, listing all configurations, and retrieving specific configurations by different criteria.</p>"},{"location":"reference/libs/golang/services/api-clients/services-config-handler/#getting-started","title":"Getting Started","text":""},{"location":"reference/libs/golang/services/api-clients/services-config-handler/#creating-a-client","title":"Creating a Client","text":"<p>To create a new instance of the <code>services-config-handler</code> API Client, use the <code>NewClient</code> function. It initializes the client with default configuration:</p> <pre><code>client := configClient.NewClient()\n</code></pre> <p>You can also customize the client's configuration by setting a custom base URL or providing a context.</p>"},{"location":"reference/libs/golang/services/api-clients/services-config-handler/#creating-a-configuration","title":"Creating a Configuration","text":"<p>You can create a new configuration using the <code>CreateConfig</code> method. It takes a <code>ConfigDTO</code> as input and sends a POST request to the API to create a new configuration.</p> <pre><code>configData := inputDTO.ConfigDTO{\n    // Set your configuration details here\n}\n\nconfig, err := client.CreateConfig(configData)\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-config-handler/#listing-all-configurations","title":"Listing All Configurations","text":"<p>You can retrieve a list of all configurations using the <code>ListAllConfigs</code> method. It sends a GET request to the API to fetch all available configurations.</p> <pre><code>configList, err := client.ListAllConfigs()\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-config-handler/#retrieving-a-configuration-by-id","title":"Retrieving a Configuration by ID","text":"<p>To retrieve a specific configuration by its ID, you can use the <code>ListOneConfigById</code> method. Provide the ID as a parameter, and it will send a GET request to the API to fetch the configuration.</p> <pre><code>configID := \"your-config-id\"\nconfig, err := client.ListOneConfigById(configID)\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-config-handler/#listing-configurations-by-service","title":"Listing Configurations by Service","text":"<p>You can retrieve configurations that belong to a specific service using the <code>ListAllConfigsByService</code> method. Provide the service name as a parameter to get the configurations associated with that service.</p> <pre><code>serviceName := \"your-service-name\"\nconfigList, err := client.ListAllConfigsByService(serviceName)\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-config-handler/#listing-configurations-by-service-and-context","title":"Listing Configurations by Service and Context","text":"<p>To retrieve configurations based on a specific service and context, use the <code>ListAllConfigsByServiceAndContext</code> method. Provide the service and context as parameters to get the configurations that match these criteria.</p> <pre><code>serviceName := \"your-service-name\"\ncontextEnv := \"your-context\"\nconfigList, err := client.ListAllConfigsByServiceAndContext(serviceName, contextEnv)\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-config-handler/#listing-configurations-by-dependent-job","title":"Listing Configurations by Dependent Job","text":"<p>You can retrieve configurations related to a specific service and source (dependent job) using the <code>ListAllConfigsByDependentJob</code> method. Provide the service and source as parameters to get the configurations associated with the given criteria.</p> <pre><code>serviceName := \"your-service-name\"\nsource := \"your-source\"\nconfigList, err := client.ListAllConfigsByDependentJob(serviceName, source)\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-config-handler/#error-handling","title":"Error Handling","text":"<p>In case of any errors during API requests, the methods return an error value that you can handle according to your application's needs.</p>"},{"location":"reference/libs/golang/services/api-clients/services-config-handler/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues or have suggestions for improvements, feel free to create an issue or submit a pull request.</p> <p>Feel free to customize this README to include information specific to your library and its usage.</p>"},{"location":"reference/libs/golang/services/api-clients/services-input-handler/","title":"services-input-handler","text":"<p>The <code>services-input-handler</code> API Client is a Go library that allows you to interact with a remote HTTP API for managing input data. This client provides a set of methods to perform various operations on inputs, such as creating new input, updating an input, listing all inputs, and retrieving specific input by different criteria.</p>"},{"location":"reference/libs/golang/services/api-clients/services-input-handler/#getting-started","title":"Getting Started","text":""},{"location":"reference/libs/golang/services/api-clients/services-input-handler/#creating-a-client","title":"Creating a Client","text":"<p>To create a new instance of the <code>services-input-handler</code> API Client, use the <code>NewClient</code> function. It initializes the client with default configuration:</p> <pre><code>client := inputClient.NewClient()\n</code></pre> <p>You can also customize the client's configuration by setting a custom base URL or providing a context.</p>"},{"location":"reference/libs/golang/services/api-clients/services-input-handler/#creating-an-input","title":"Creating an Input","text":"<p>You can create a new input using the <code>CreateInput</code> method. It takes a <code>InputDTO</code> as input and sends a POST request to the API to create a new input.</p> <pre><code>inputData := inputDTO.InputDTO{\n    // Set your input details here\n}\n\ninput, err := client.CreateConfig(inputData)\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-input-handler/#listing-inputs","title":"Listing Inputs","text":"<p>You can retrieve a list of inputs based on various criteria. Here are some examples:</p>"},{"location":"reference/libs/golang/services/api-clients/services-input-handler/#list-all-inputs-by-service-and-source","title":"List All Inputs by Service and Source","text":"<pre><code>inputs, err := client.ListAllInputsByServiceAndSource(\"your-service-name\", \"your-source-name\")\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-input-handler/#list-all-inputs-by-service","title":"List All Inputs by Service","text":"<pre><code>inputs, err := client.ListAllInputsByService(\"your-service-name\")\nif err is not nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-input-handler/#list-one-input-by-id-service-and-source","title":"List One Input by ID, Service, and Source","text":"<pre><code>input, err := client.ListOneInputByIdAndService(\"your-input-id\", \"your-service-name\", \"your-source-name\")\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-input-handler/#list-all-inputs-by-service-source-and-status","title":"List All Inputs by Service, Source, and Status","text":"<pre><code>inputs, err := client.ListAllInputsByServiceAndSourceAndStatus(\"your-service-name\", \"your-source-name\", your-status)\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-input-handler/#updating-input-status","title":"Updating Input Status","text":"<p>You can update the status of an input using the UpdateInputStatus method. It takes the new status, context environment, service name, source name, and input ID as input and sends a POST request to the API to update the input's status.</p> <pre><code>newStatus := sharedDTO.Status{\n    // Set the new status details here\n}\n\nupdatedInput, err := client.UpdateInputStatus(newStatus, \"your-context-environment\", \"your-service-name\", \"your-source-name\", \"your-input-id\")\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-input-handler/#error-handling","title":"Error Handling","text":"<p>In case of any errors during API requests, the methods return an error value that you can handle according to your application's needs.</p>"},{"location":"reference/libs/golang/services/api-clients/services-input-handler/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues or have suggestions for improvements, feel free to create an issue or submit a pull request.</p> <p>Feel free to customize this README to include information specific to your library and its usage.</p>"},{"location":"reference/libs/golang/services/api-clients/services-output-handler/","title":"services-output-handler","text":"<p>The <code>services-output-handler</code> API Client is a Go library that allows you to interact with a remote HTTP API for managing output data. This client provides a set of methods to perform various operations on outputs, such as creating new output, listing all outputs, and retrieving specific output by different criteria.</p>"},{"location":"reference/libs/golang/services/api-clients/services-output-handler/#getting-started","title":"Getting Started","text":""},{"location":"reference/libs/golang/services/api-clients/services-output-handler/#creating-a-client","title":"Creating a Client","text":"<p>To create a new instance of the <code>services-output-handler</code> API Client, use the <code>NewClient</code> function. It initializes the client with default configuration:</p> <pre><code>client := outputClient.NewClient()\n</code></pre> <p>You can also customize the client's configuration by setting a custom base URL or providing a context.</p>"},{"location":"reference/libs/golang/services/api-clients/services-output-handler/#creating-an-input","title":"Creating an Input","text":"<p>You can create a new output using the <code>CreateOutput</code> method. It takes a <code>ServiceOutputDTO</code> as input and sends a POST request to the API to create a new output.</p> <pre><code>outputData := inputDTO.ServiceOutputDTO{\n    // Set your output details here\n}\n\noutput, err := client.CreateOutput(outputData)\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-output-handler/#listing-outputs","title":"Listing Outputs","text":"<p>You can retrieve a list of outputs based on various criteria. Here are some examples:</p>"},{"location":"reference/libs/golang/services/api-clients/services-output-handler/#list-all-outputs-by-service-and-source","title":"List All Outputs by Service and Source","text":"<pre><code>outputs, err := client.ListAllOutputsByServiceAndSource(\"your-service-name\", \"your-source-name\")\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-output-handler/#list-all-outputs-by-service","title":"List All Outputs by Service","text":"<pre><code>outputs, err := client.ListAllOutputsByService(\"your-service-name\")\nif err is not nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-output-handler/#list-one-output-by-id-service-and-source","title":"List One Output by ID, Service, and Source","text":"<pre><code>outputs, err := client.ListOneOutputsByServiceAndId(\"your-output-id\", \"your-service-name\", \"your-source-name\")\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-output-handler/#error-handling","title":"Error Handling","text":"<p>In case of any errors during API requests, the methods return an error value that you can handle according to your application's needs.</p>"},{"location":"reference/libs/golang/services/api-clients/services-output-handler/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues or have suggestions for improvements, feel free to create an issue or submit a pull request.</p> <p>Feel free to customize this README to include information specific to your library and its usage.</p>"},{"location":"reference/libs/golang/services/api-clients/services-staging-handler/","title":"services-output-handler","text":"<p>The <code>services-staging-handler</code> API Client is a Go library that allows you to interact with a remote HTTP API for managing staging data of processing jobs. This client provides a set of methods to perform various operations on staging data of processing jobs, such as creating new staging data for a dependent job og the actual job running, listing one staging data of processing jobs by id, remove a staging data of processing jobs and update an status of a the running job in the staging data of processing jobs.</p>"},{"location":"reference/libs/golang/services/api-clients/services-staging-handler/#getting-started","title":"Getting Started","text":""},{"location":"reference/libs/golang/services/api-clients/services-staging-handler/#creating-a-client","title":"Creating a Client","text":"<p>To create a new instance of the <code>services-staging-handler</code> API Client, use the <code>NewClient</code> function. It initializes the client with default configuration:</p> <pre><code>client := stagingClient.NewClient()\n</code></pre> <p>You can also customize the client's configuration by setting a custom base URL or providing a context.</p>"},{"location":"reference/libs/golang/services/api-clients/services-staging-handler/#creating-a-processing-job-dependencies","title":"Creating a Processing Job Dependencies","text":"<p>You can create a new staging processing job dependency using the <code>CreateProcessingJobDependencies</code> method. It takes a <code>ProcessingJobDependenciesDTO</code> as input and sends a POST request to the API to create a new processing job dependencies.</p> <pre><code>processingDepData := inputDTO.ProcessingJobDependenciesDTO{\n    // Set your processing job dependencies details here\n}\n\nprocessingDep, err := client.CreateProcessingJobDependencies(processingDepData)\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-staging-handler/#list-one-processing-job-dependencies-by-id","title":"List One Processing Job Dependencies by ID","text":"<pre><code>processingDeps, err := client.ListOneProcessingJobDependenciesById(\"your-processing-job-dependencies-id\")\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-staging-handler/#remove-a-processing-job-dependencies","title":"Remove a Processing Job Dependencies","text":"<pre><code>processingDeps, err := client.RemoveProcessingJobDependencies(\"your-processing-job-dependencies-id\")\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-staging-handler/#update-job-dependencies-of-a-processing-job-dependencies","title":"Update Job Dependencies of a Processing Job Dependencies","text":"<pre><code>processingDepData := sharedDTO.ProcessingJobDependencies{\n    // Set your processing job dependencies details here\n}\n\nprocessingDeps, err := client.UpdateProcessingJobDependencies(\"your-processing-job-dependencies-id\")\nif err != nil {\n    // Handle the error\n}\n</code></pre>"},{"location":"reference/libs/golang/services/api-clients/services-staging-handler/#error-handling","title":"Error Handling","text":"<p>In case of any errors during API requests, the methods return an error value that you can handle according to your application's needs.</p>"},{"location":"reference/libs/golang/services/api-clients/services-staging-handler/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues or have suggestions for improvements, feel free to create an issue or submit a pull request.</p> <p>Feel free to customize this README to include information specific to your library and its usage.</p>"},{"location":"reference/libs/golang/services/dtos/services-config-handler/","title":"services-config-handler","text":"<p>The <code>services-config-handler</code> library contains Data Transfer Objects (DTOs) for the <code>services-config-handler</code> service. These DTOs are used to define the structure of data exchanged between different parts of the service, providing a clear and standardized representation of data.</p>"},{"location":"reference/libs/golang/services/dtos/services-config-handler/#usage","title":"Usage","text":"<p>To use the DTOs provided by this library, import the necessary package in your Go code. You can then create instances of these DTOs to work with data in a structured and consistent way.</p>"},{"location":"reference/libs/golang/services/dtos/services-config-handler/#importing-the-library","title":"Importing the Library","text":"<p>Import the library in your Go code as follows:</p> <pre><code>import \"libs/golang/services/dtos/services-config-handler/input\"\nimport \"libs/golang/services/dtos/services-config-handler/output\"\nimport \"libs/golang/services/dtos/services-config-handler/shared\"\n</code></pre>"},{"location":"reference/libs/golang/services/dtos/services-config-handler/#using-the-dtos","title":"Using the DTOs","text":"<p>You can use the DTOs in your code to represent and work with data structures related to the <code>services-config-handler</code> service.</p>"},{"location":"reference/libs/golang/services/dtos/services-config-handler/#example","title":"Example:","text":"<pre><code>import (\n    inputDTO \"libs/golang/services/dtos/services-config-handler/input\"\n    \"encoding/json\"\n    \"fmt\"\n)\n\nfunc main() {\n    // Create a ConfigDTO instance\n    config := inputDTO.ConfigDTO{\n        Name:      \"Sample Config\",\n        Active:    true,\n        Frequency: \"daily\",\n        Service:   \"sample-service\",\n        // ... other fields\n    }\n\n    // Convert the ConfigDTO to JSON\n    configJSON, err := json.Marshal(config)\n    if err != nil {\n        fmt.Println(\"Error marshaling JSON:\", err)\n        return\n    }\n\n    fmt.Println(\"ConfigDTO JSON:\", string(configJSON))\n}\n</code></pre>"},{"location":"reference/libs/golang/services/dtos/services-config-handler/#dtos-provided","title":"DTOs Provided","text":"<p>The library provides the following DTOs for use in the <code>services-config-handler</code> service:</p>"},{"location":"reference/libs/golang/services/dtos/services-config-handler/#configdto-input-and-output-packages","title":"<code>ConfigDTO</code> (input and output packages)","text":"<p>This DTO represents the configuration for a service, including various attributes such as name, service parameters, and job parameters. It is used for both input and output data.</p>"},{"location":"reference/libs/golang/services/dtos/services-config-handler/#configversiondata-input-and-output-packages","title":"<code>ConfigVersionData</code> (input and output packages)","text":"<p>This DTO represents data related to a specific configuration version, including the ConfigID and the corresponding ConfigDTO. It is used for both input and output data.</p>"},{"location":"reference/libs/golang/services/dtos/services-config-handler/#configversiondto-input-and-output-packages","title":"<code>ConfigVersionDTO</code> (input and output packages)","text":"<p>This DTO represents a collection of configuration versions associated with a specific ID. It includes an ID and a list of <code>ConfigVersionData</code> instances. It is used for both input and output data.</p>"},{"location":"reference/libs/golang/services/dtos/services-config-handler/#jobdependencies-shared-package","title":"<code>JobDependencies</code> (shared package)","text":"<p>This DTO represents job dependencies with service and source attributes. It is used to define dependencies between jobs.</p> <p>Please refer to the Go code and documentation for further details on the structure and usage of these DTOs.</p>"},{"location":"reference/libs/golang/services/dtos/services-config-handler/#contributions","title":"Contributions","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request.</p>"},{"location":"reference/libs/golang/services/dtos/services-events-handler/","title":"services-events-handler","text":"<p>The <code>services-events-handler</code> library contains Data Transfer Objects (DTOs) for the <code>services-events-handler</code> service. These DTOs are used to define the structure of data exchanged between different parts of the service, providing a clear and standardized representation of data.</p>"},{"location":"reference/libs/golang/services/dtos/services-events-handler/#usage","title":"Usage","text":"<p>To use the DTOs provided by this library, import the necessary package in your Go code. You can then create instances of these DTOs to work with data in a structured and consistent way.</p>"},{"location":"reference/libs/golang/services/dtos/services-events-handler/#importing-the-library","title":"Importing the Library","text":"<p>Import the library in your Go code as follows:</p> <pre><code>import \"libs/golang/services/dtos/services-events-handler/input\"\nimport \"libs/golang/services/dtos/services-events-handler/output\"\nimport \"libs/golang/services/dtos/services-events-handler/shared\"\n</code></pre>"},{"location":"reference/libs/golang/services/dtos/services-events-handler/#using-the-dtos","title":"Using the DTOs","text":"<p>You can use the DTOs in your code to represent and work with data structures related to the <code>services-events-handler</code> service.</p>"},{"location":"reference/libs/golang/services/dtos/services-events-handler/#example","title":"Example:","text":"<pre><code>package main\n\nimport (\n    \"encoding/json\"\n    \"fmt\"\n    inputDTO \"libs/golang/services/dtos/services-events-handler/input\"\n    outputDTO \"libs/golang/services/dtos/services-events-handler/output\"\n    sharedDTO \"libs/golang/services/dtos/services-events-handler/shared\"\n)\n\nfunc main() {\n    // Create a sample input ServiceFeedbackDTO\n    inputFeedback := inputDTO.ServiceFeedbackDTO{\n        Data: map[string]interface{}{\n            \"param1\": \"value1\",\n            \"param2\": 42,\n        },\n        Metadata: sharedDTO.Metadata{\n            Input: sharedDTO.MetadataInput{\n                ID:                  \"input123\",\n                Data:                map[string]interface{}{\"inputParam\": \"inputValue\"},\n                ProcessingId:        \"process123\",\n                ProcessingTimestamp: \"2023-11-02T12:34:56\",\n                InputSchemaId:       \"schema123\",\n            },\n            Service:             \"example-service\",\n            Source:              \"example-source\",\n            Context:             \"example-context\",\n            ProcessingTimestamp: \"2023-11-02T12:34:56\",\n            JobFrequency:        \"daily\",\n            JobConfigId:         \"config123\",\n        },\n        Status: sharedDTO.Status{\n            Code: 200,\n            Detail: \"OK\"\n        },\n    }\n\n    // Convert the ConfigDTO to JSON\n    inputFeedbackJSON, err := json.Marshal(inputFeedback)\n    if err != nil {\n        fmt.Println(\"Error marshaling JSON:\", err)\n        return\n    }\n\n    fmt.Println(\"ConfigDTO JSON:\", string(inputFeedbackJSON))\n\n}\n</code></pre>"},{"location":"reference/libs/golang/services/dtos/services-events-handler/#dtos-provided","title":"DTOs Provided","text":"<p>The library provides the following DTOs for use in the <code>services-events-handler</code> service:</p>"},{"location":"reference/libs/golang/services/dtos/services-events-handler/#servicefeedbackdto-input-and-output","title":"<code>ServiceFeedbackDTO</code> (input and output)","text":"<p>This DTO represents the feedback for a service, including various attributes such as name, service parameters, and job parameters. It is used for both input and output data.</p>"},{"location":"reference/libs/golang/services/dtos/services-events-handler/#metadatainput-shared","title":"<code>MetadataInput</code> (shared)","text":"<p>This DTO represents metadata related to the input data, including ID, data, processing ID, processing timestamp, and input schema ID.</p>"},{"location":"reference/libs/golang/services/dtos/services-events-handler/#metadata-shared","title":"<code>Metadata</code> (shared)","text":"<p>This DTO represents general metadata, including input metadata, service name, source, context, processing timestamp, job frequency, and job config ID.</p>"},{"location":"reference/libs/golang/services/dtos/services-events-handler/#status-shared","title":"<code>Status</code> (shared)","text":"<p>This DTO represents the status of a service feedback, including a status code and a detailed description.</p> <p>Please refer to the Go code and documentation for further details on the structure and usage of these DTOs.</p>"},{"location":"reference/libs/golang/services/dtos/services-events-handler/#contributions","title":"Contributions","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request.</p>"},{"location":"reference/libs/golang/services/dtos/services-file-catalog-handler/","title":"services-file-catalog-handler","text":"<p>The <code>services-file-catalog-handler</code> library contains Data Transfer Objects (DTOs) for the <code>services-file-catalog-handler</code> service. These DTOs are used to define the structure of data exchanged between different parts of the service, providing a clear and standardized representation of data.</p>"},{"location":"reference/libs/golang/services/dtos/services-file-catalog-handler/#usage","title":"Usage","text":"<p>To use the DTOs provided by this library, import the necessary package in your Go code. You can then create instances of these DTOs to work with data in a structured and consistent way.</p>"},{"location":"reference/libs/golang/services/dtos/services-file-catalog-handler/#importing-the-library","title":"Importing the Library","text":"<p>Import the library in your Go code as follows:</p> <pre><code>import \"libs/golang/services/dtos/services-file-catalog-handler/input\"\nimport \"libs/golang/services/dtos/services-file-catalog-handler/output\"\n</code></pre>"},{"location":"reference/libs/golang/services/dtos/services-file-catalog-handler/#using-the-dtos","title":"Using the DTOs","text":"<p>You can use the DTOs in your code to represent and work with data structures related to the <code>services-file-catalog-handler</code> service.</p> <p>Here's an example of how to use the <code>FileCatalogDTO</code> from the input package:</p> <pre><code>import (\n    \"fmt\"\n    inputDTO \"libs/golang/services/dtos/services-file-catalog-handler/input\"\n)\n\nfunc main() {\n    // Example of using the FileCatalogDTO from the input package\n    inputFileCatalog := inputDTO.FileCatalogDTO{\n        Service:    \"example-service\",\n        Source:     \"example-source\",\n        Context:    \"example-context\",\n        LakeLayer:  \"example-lake-layer\",\n        SchemaType: \"example-schema-type\",\n        Catalog: map[string]interface{}{\n            \"key1\": [\"value1\"],\n            \"key2\": [\"value2\"],\n            \"key3\": [\"value2\"],\n        },\n    }\n\n    fmt.Println(\"Input File Catalog DTO:\")\n    fmt.Printf(\"%+v\\n\", inputFileCatalog)\n}\n</code></pre>"},{"location":"reference/libs/golang/services/dtos/services-file-catalog-handler/#dtos-provided","title":"DTOs Provided","text":"<p>The library provides the following DTOs for use in the <code>services-file-catalog-handler</code> service:</p>"},{"location":"reference/libs/golang/services/dtos/services-file-catalog-handler/#filecatalogdto-input-and-output","title":"<code>FileCatalogDTO</code> (input and output)","text":"<p>This DTO represents the main data structure exchanged by the service, including data.</p> <p>Please refer to the Go code and documentation for further details on the structure and usage of these DTOs.</p>"},{"location":"reference/libs/golang/services/dtos/services-file-catalog-handler/#contributions","title":"Contributions","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/golang/services/dtos/services-input-handler/","title":"services-input-handler","text":"<p>The <code>services-input-handler</code> library contains Data Transfer Objects (DTOs) for the <code>services-input-handler</code> service. These DTOs are used to define the structure of data exchanged between different parts of the service, providing a clear and standardized representation of data.</p>"},{"location":"reference/libs/golang/services/dtos/services-input-handler/#usage","title":"Usage","text":"<p>To use the DTOs provided by this library, import the necessary package in your Go code. You can then create instances of these DTOs to work with data in a structured and consistent way.</p>"},{"location":"reference/libs/golang/services/dtos/services-input-handler/#importing-the-library","title":"Importing the Library","text":"<p>Import the library in your Go code as follows:</p> <pre><code>import \"libs/golang/services/dtos/services-input-handler/input\"\nimport \"libs/golang/services/dtos/services-input-handler/output\"\nimport \"libs/golang/services/dtos/services-input-handler/shared\"\n</code></pre>"},{"location":"reference/libs/golang/services/dtos/services-input-handler/#using-the-dtos","title":"Using the DTOs","text":"<p>You can use the DTOs in your code to represent and work with data structures related to the <code>services-input-handler</code> service.</p> <p>Here's an example of how to use the <code>InputDTO</code> from the input package:</p> <pre><code>import (\n    inputDTO \"libs/golang/services/dtos/services-input-handler/input\"\n    \"encoding/json\"\n    \"fmt\"\n)\n\nfunc main() {\n    // Create an InputDTO instance\n    data := map[string]interface{}{\n        \"key1\": \"value1\",\n        \"key2\": 42,\n    }\n\n    input := inputDTO.InputDTO{\n        Data: data,\n    }\n\n    // Convert to JSON for output or further processing\n    jsonBytes, err := json.Marshal(input)\n    if err != nil {\n        fmt.Println(\"Error:\", err)\n        return\n    }\n\n    fmt.Println(string(jsonBytes))\n}\n</code></pre>"},{"location":"reference/libs/golang/services/dtos/services-input-handler/#dtos-provided","title":"DTOs Provided","text":"<p>The library provides the following DTOs for use in the <code>services-input-handler</code> service:</p>"},{"location":"reference/libs/golang/services/dtos/services-input-handler/#inputdto-input-and-output","title":"<code>InputDTO</code> (input and output)","text":"<p>This DTO represents the main data structure exchanged by the service, including data.</p>"},{"location":"reference/libs/golang/services/dtos/services-input-handler/#metadata-shared","title":"<code>Metadata</code> (shared)","text":"<p>This DTO includes metadata information, such as processing ID, processing timestamp, context, source, and service.</p>"},{"location":"reference/libs/golang/services/dtos/services-input-handler/#status-shared","title":"<code>Status</code> (shared)","text":"<p>The <code>Status</code> DTO contains information about the status of the input, including a status code and a detail message.</p> <p>Please refer to the Go code and documentation for further details on the structure and usage of these DTOs.</p>"},{"location":"reference/libs/golang/services/dtos/services-input-handler/#contributions","title":"Contributions","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/golang/services/dtos/services-output-handler/","title":"services-output-handler","text":"<p>The <code>services-output-handler</code> library contains Data Transfer Objects (DTOs) for the <code>services-output-handler</code> service. These DTOs are used to define the structure of data exchanged between different parts of the service, providing a clear and standardized representation of data.</p>"},{"location":"reference/libs/golang/services/dtos/services-output-handler/#usage","title":"Usage","text":"<p>To use the DTOs provided by this library, import the necessary package in your Go code. You can then create instances of these DTOs to work with data in a structured and consistent way.</p>"},{"location":"reference/libs/golang/services/dtos/services-output-handler/#importing-the-library","title":"Importing the Library","text":"<p>Import the library in your Go code as follows:</p> <pre><code>import \"libs/golang/services/dtos/services-output-handler/input\"\nimport \"libs/golang/services/dtos/services-output-handler/output\"\nimport \"libs/golang/services/dtos/services-output-handler/shared\"\n</code></pre>"},{"location":"reference/libs/golang/services/dtos/services-output-handler/#using-the-dtos","title":"Using the DTOs","text":"<p>You can use the DTOs in your code to represent and work with data structures related to the <code>services-output-handler</code> service.</p> <p>Here's an example of how to use the <code>ServiceOutputDTO</code> from the input package:</p> <pre><code>import (\n    inputDTO \"libs/golang/services/dtos/services-output-handler/input\"\n    \"encoding/json\"\n    \"fmt\"\n)\n\nfunc main() {\n    // Create a ServiceOutputDTO instance\n    data := map[string]interface{}{\n        \"key1\": \"value1\",\n        \"key2\": 42,\n    }\n\n    metadata := sharedDTO.Metadata{\n        InputId: \"input123\",\n        Input: sharedDTO.MetadataInput{\n            ID:                  \"metadataId\",\n            Data:                map[string]interface{}{\"metaKey\": \"metaValue\"},\n            ProcessingId:        \"processing123\",\n            ProcessingTimestamp: \"2023-11-01T12:00:00Z\",\n        },\n        Service: \"my-service\",\n        Source:  \"my-source\",\n    }\n\n    serviceOutput := inputDTO.ServiceOutputDTO{\n        Data:     data,\n        Metadata: metadata,\n        Context:  \"my-context\",\n    }\n\n    // Convert to JSON for output or further processing\n    jsonBytes, err := json.Marshal(serviceOutput)\n    if err != nil {\n        fmt.Println(\"Error:\", err)\n        return\n    }\n\n    fmt.Println(string(jsonBytes))\n}\n</code></pre>"},{"location":"reference/libs/golang/services/dtos/services-output-handler/#dtos-provided","title":"DTOs Provided","text":"<p>The library provides the following DTOs for use in the <code>services-output-handler</code> service:</p>"},{"location":"reference/libs/golang/services/dtos/services-output-handler/#serviceoutputdto-input-and-output","title":"<code>ServiceOutputDTO</code> (input and output)","text":"<p>This DTO is used for input and output and represents the main data structure exchanged by the service. It includes data, metadata, and context information.</p>"},{"location":"reference/libs/golang/services/dtos/services-output-handler/#metadatainput-shared","title":"<code>MetadataInput</code> (shared)","text":"<p>This DTO represents the metadata for input data. It includes information like ID, data, processing ID, and processing timestamp.</p>"},{"location":"reference/libs/golang/services/dtos/services-output-handler/#metadata-shared","title":"<code>Metadata</code> (shared)","text":"<p>This DTO represents the metadata associated with the service output. It includes input ID, input metadata, service, source, and more.</p>"},{"location":"reference/libs/golang/services/dtos/services-output-handler/#contributions","title":"Contributions","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request.</p>"},{"location":"reference/libs/golang/services/dtos/services-schema-handler/","title":"services-schema-handler","text":"<p>The <code>services-schema-handler</code> library contains Data Transfer Objects (DTOs) for the <code>services-schema-handler</code> service. These DTOs are used to define the structure of data exchanged between different parts of the service, providing a clear and standardized representation of data.</p>"},{"location":"reference/libs/golang/services/dtos/services-schema-handler/#usage","title":"Usage","text":"<p>To use the DTOs provided by this library, import the necessary package in your Go code. You can then create instances of these DTOs to work with data in a structured and consistent way.</p>"},{"location":"reference/libs/golang/services/dtos/services-schema-handler/#importing-the-library","title":"Importing the Library","text":"<p>Import the library in your Go code as follows:</p> <pre><code>import \"libs/golang/services/dtos/services-schema-handler/input\"\nimport \"libs/golang/services/dtos/services-schema-handler/output\"\n</code></pre>"},{"location":"reference/libs/golang/services/dtos/services-schema-handler/#using-the-dtos","title":"Using the DTOs","text":"<p>You can use the DTOs in your code to represent and work with data structures related to the <code>services-schema-handler</code> service.</p>"},{"location":"reference/libs/golang/services/dtos/services-schema-handler/#example","title":"Example:","text":"<pre><code>// Import the necessary packages\nimport (\n    \"libs/golang/services/dtos/services-schema-handler/input\"\n    \"libs/golang/services/dtos/services-schema-handler/output\"\n)\n\n// Create instances of DTOs\nschemaInputDTO := input.SchemaDTO{\n    SchemaType: \"example\",\n    Service: \"sample-service\",\n    Source: \"sample-source\",\n    Context: \"sample-context\",\n    JsonSchema: map[string]interface{}{\n        \"key1\": \"value1\",\n        \"key2\": \"value2\",\n    },\n}\n\nschemaOutputDTO := output.SchemaDTO{\n    ID: \"12345\",\n    SchemaType: \"example\",\n    Service: \"sample-service\",\n    Source: \"sample-source\",\n    Context: \"sample-context\",\n    JsonSchema: map[string]interface{}{\n        \"key1\": \"value1\",\n        \"key2\": \"value2\",\n    },\n    SchemaID: \"67890\",\n    CreatedAt: \"2023-11-01T12:00:00Z\",\n    UpdatedAt: \"2023-11-01T12:30:00Z\",\n}\n\n// Use the DTOs as needed in your code\n</code></pre>"},{"location":"reference/libs/golang/services/dtos/services-schema-handler/#dtos-provided","title":"DTOs Provided","text":"<p>The library provides the following DTOs for use in the <code>services-schema-handler</code> service:</p>"},{"location":"reference/libs/golang/services/dtos/services-schema-handler/#schemadto-input-and-output","title":"<code>SchemaDTO</code> (input and output)","text":"<p>This DTO represents schema information and includes attributes such as <code>SchemaType</code>, <code>Service</code>, <code>Source</code>, <code>Context</code>, and <code>JsonSchema</code>.</p>"},{"location":"reference/libs/golang/services/dtos/services-schema-handler/#schemaversiondata-input-and-output","title":"<code>SchemaVersionData</code> (input and output)","text":"<p>This DTO represents data related to schema versions and includes attributes like <code>SchemaID</code> and a reference to the <code>SchemaDTO</code>.</p>"},{"location":"reference/libs/golang/services/dtos/services-schema-handler/#schemaversiondto-input-and-output","title":"<code>SchemaVersionDTO</code> (input and output)","text":"<p>This DTO represents schema versions and includes attributes like <code>ID</code> and a list of <code>SchemaVersionData</code>.</p> <p>Please refer to the Go code and documentation for further details on the structure and usage of these DTOs.</p>"},{"location":"reference/libs/golang/services/dtos/services-schema-handler/#contributions","title":"Contributions","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request.</p>"},{"location":"reference/libs/golang/services/dtos/services-staging-handler/","title":"services-staging-handler","text":"<p>The <code>services-staging-handler</code> library contains Data Transfer Objects (DTOs) for the <code>services-staging-handler</code> service. These DTOs are used to define the structure of data exchanged between different parts of the service, providing a clear and standardized representation of data.</p>"},{"location":"reference/libs/golang/services/dtos/services-staging-handler/#usage","title":"Usage","text":"<p>To use the DTOs provided by this library, import the necessary package in your Go code. You can then create instances of these DTOs to work with data in a structured and consistent way.</p>"},{"location":"reference/libs/golang/services/dtos/services-staging-handler/#importing-the-library","title":"Importing the Library","text":"<p>Import the library in your Go code as follows:</p> <pre><code>import \"libs/golang/services/dtos/services-staging-handler/input\"\nimport \"libs/golang/services/dtos/services-staging-handler/staging\"\nimport \"libs/golang/services/dtos/services-staging-handler/shared\"\n</code></pre>"},{"location":"reference/libs/golang/services/dtos/services-staging-handler/#using-the-dtos","title":"Using the DTOs","text":"<p>You can use the DTOs in your code to represent and work with data structures related to the <code>services-staging-handler</code> service.</p> <p>Here's an example of how to use the <code>ProcessingJobDependenciesDTO</code> from the input package:</p> <pre><code>import (\n    inputDTO \"libs/golang/services/dtos/services-staging-handler/input\"\n    \"encoding/json\"\n    \"fmt\"\n)\n\nfunc main() {\n    // Create a ProcessingJobDependenciesDTO instance\n    jobDependencies := []sharedDTO.ProcessingJobDependencies{\n        {\n            Service:             \"dependency-service-1\",\n            Source:              \"source-1\",\n            ProcessingId:        \"process-1\",\n            ProcessingTimestamp: \"2023-11-01T12:00:00Z\",\n            StatusCode:          200,\n        },\n        {\n            Service:             \"dependency-service-2\",\n            Source:              \"source-2\",\n            ProcessingId:        \"process-2\",\n            ProcessingTimestamp: \"2023-11-01T13:00:00Z\",\n            StatusCode:          404,\n        },\n    }\n\n    processingJob := inputDTO.ProcessingJobDependenciesDTO{\n        Service:         \"my-service\",\n        Source:          \"my-source\",\n        Context:         \"my-context\",\n        JobDependencies: jobDependencies,\n    }\n\n    // Convert to JSON for output or further processing\n    jsonBytes, err := json.Marshal(processingJob)\n    if err != nil {\n        fmt.Println(\"Error:\", err)\n        return\n    }\n\n    fmt.Println(string(jsonBytes))\n}\n</code></pre>"},{"location":"reference/libs/golang/services/dtos/services-staging-handler/#dtos-provided","title":"DTOs Provided","text":"<p>The library provides the following DTOs for use in the <code>services-staging-handler</code> service:</p>"},{"location":"reference/libs/golang/services/dtos/services-staging-handler/#processingjobdependenciesdto-input-and-staging","title":"<code>ProcessingJobDependenciesDTO</code> (input and staging)","text":"<p>This DTO is used for input and staging and represents the data structure exchanged by the service. It includes information about the service, source, context, and an array of job dependencies.</p>"},{"location":"reference/libs/golang/services/dtos/services-staging-handler/#processingjobdependencies-shared","title":"<code>ProcessingJobDependencies</code> (shared)","text":"<p>This DTO represents the shared information about job dependencies, including service, source, processing ID, processing timestamp, and status code.</p>"},{"location":"reference/libs/golang/services/dtos/services-staging-handler/#metadata-shared","title":"<code>Metadata</code> (shared)","text":"<p>This shared DTO may be used for additional metadata when working with the <code>services-staging-handler</code> service.</p>"},{"location":"reference/libs/golang/services/dtos/services-staging-handler/#contributions","title":"Contributions","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/golang/shared/go-events/","title":"go-events","text":"<p>The <code>go-events</code> package provides a simple event handling mechanism for your Go applications. It allows you to define and manage events, event handlers, and event listeners. This can be particularly useful for implementing event-driven architectures and decoupling different parts of your application.</p>"},{"location":"reference/libs/golang/shared/go-events/#usage","title":"Usage","text":""},{"location":"reference/libs/golang/shared/go-events/#event-interface","title":"Event Interface","text":"<p>The EventInterface defines the methods that should be implemented by event objects:</p> <ul> <li><code>GetName() string</code>: Returns the name of the event.</li> <li><code>GetDateTime() time.Time</code>: Returns the date and time when the event occurred.</li> <li><code>GetPayload() interface{}</code>: Returns the event's payload.</li> <li><code>SetPayload(payload interface{})</code>: Sets the event's payload.</li> </ul>"},{"location":"reference/libs/golang/shared/go-events/#event-handler-interface","title":"Event Handler Interface","text":"<p>The <code>EventHandlerInterface</code> defines the method for handling events:</p> <ul> <li><code>Handle(event EventInterface, wg *sync.WaitGroup, exchangeName string, routingKey string)</code>: Handles the event, and you can specify the exchange name and routing key for further customization.</li> </ul>"},{"location":"reference/libs/golang/shared/go-events/#event-listener-interface","title":"Event Listener Interface","text":"<p>The <code>EventListenerInterface</code> defines the method for listening to events:</p> <ul> <li><code>Handle(event EventInterface, wg *sync.WaitGroup)</code>: Handles the event and can be used in scenarios where you don't need to specify exchange names or routing keys.</li> </ul>"},{"location":"reference/libs/golang/shared/go-events/#event-dispatcher-interface","title":"Event Dispatcher Interface","text":"<p>The <code>EventDispatcherInterface</code> defines methods for registering, dispatching, removing, and checking event handlers:</p> <ul> <li><code>Register(eventName string, handler EventHandlerInterface) error</code>: Registers an event handler for a specific event.</li> <li><code>Dispatch(event EventInterface, exchangeName string, routingKey string) error</code>: Dispatches an event to all registered handlers, optionally specifying the exchange name and routing key.</li> <li><code>Remove(eventName string, handler EventHandlerInterface) error</code>: Removes a specific event handler.</li> <li><code>Has(eventName string, handler EventHandlerInterface) bool</code>: Checks if a specific event handler is registered for an event.</li> <li><code>Clear()</code>: Removes all registered event handlers.</li> </ul>"},{"location":"reference/libs/golang/shared/go-events/#eventdispatcher","title":"EventDispatcher","text":"<p>The <code>EventDispatcher</code> struct implements the <code>EventDispatcherInterface</code> and provides a simple way to manage event handlers and dispatch events.</p> <pre><code>import \"libs/golang/shared/go-events/events\"\n\ned := events.NewEventDispatcher()\n\n// Register an event handler\ned.Register(\"myEvent\", myHandler)\n\n// Dispatch an event\ned.Dispatch(myEvent, \"myExchange\", \"myRoutingKey\")\n\n// Remove an event handler\ned.Remove(\"myEvent\", myHandler)\n\n// Check if an event handler is registered\nif ed.Has(\"myEvent\", myHandler) {\n    // Handler is registered\n}\n\n// Clear all event handlers\ned.Clear()\n</code></pre>"},{"location":"reference/libs/golang/shared/go-id/","title":"go-id","text":"<p>The <code>go-id</code> library provides utilities for generating and working with various types of identifiers (IDs) used in your Go applications. These IDs are designed to uniquely identify objects, schemas, or configurations within your systems.</p>"},{"location":"reference/libs/golang/shared/go-id/#usage","title":"Usage","text":""},{"location":"reference/libs/golang/shared/go-id/#configuration-id","title":"Configuration ID","text":"<p>The <code>config</code> package provides tools for creating configuration-related IDs. You can use it as follows:</p> <pre><code>import \"libs/golang/shared/go-id/config\"\n\n// Create a new configuration ID\nid := config.NewID(\"my-service\", \"my-source\")\n</code></pre>"},{"location":"reference/libs/golang/shared/go-id/#md5-id","title":"MD5 ID","text":"<p>The <code>md5</code> package allows you to generate MD5-based IDs for data and provides additional functionality for including source and service information:</p> <pre><code>import \"libs/golang/shared/go-id/md5\"\n\n// Create an MD5 ID from a map of data\ndata := map[string]interface{}{\"key1\": \"value1\", \"key2\": \"value2\"}\nid := md5.NewID(data)\n\n// Create an MD5 ID with source information\nidWithSource := md5.NewWithSourceID(data, \"my-source\")\n\n// Create an MD5 ID with both source and service information\nidWithSourceAndService := md5.NewWithSourceAndServiceID(data, \"my-source\", \"my-service\")\n</code></pre>"},{"location":"reference/libs/golang/shared/go-id/#schema-id","title":"Schema ID","text":"<p>The <code>schema</code> package helps you generate schema-related IDs based on schema type, service, and source:</p> <pre><code>import \"libs/golang/shared/go-id/schema\"\n\n// Create a schema ID\nschemaID := schema.NewID(\"user\", \"my-service\", \"my-source\")\n</code></pre>"},{"location":"reference/libs/golang/shared/go-id/#uuid-id","title":"UUID ID","text":"<p>The <code>uuid</code> package provides tools for working with UUID-based IDs:</p> <pre><code>import \"libs/golang/shared/go-id/uuid\"\n\n// Create a new UUID ID\nid := uuid.NewID()\n\n// Parse a UUID ID from a string\nparsedID, err := uuid.ParseID(\"7c9e6679-327c-43f8-9b2c-0d33d6d735f7\")\n</code></pre>"},{"location":"reference/libs/golang/shared/go-request/","title":"go-request","text":"<p>The <code>go-request</code> library provides utilities for making HTTP requests and handling responses in your Go applications. It simplifies the process of creating HTTP requests, sending them, and handling the responses. It is designed to make interacting with HTTP services easier and more convenient.</p>"},{"location":"reference/libs/golang/shared/go-request/#usage","title":"Usage","text":""},{"location":"reference/libs/golang/shared/go-request/#creating-requests","title":"Creating Requests","text":"<p>The CreateRequest function allows you to create HTTP requests with ease. It takes a context, HTTP method, URL, and an optional request body. Here's how to use it:</p> <pre><code>import gorequest \"libs/golang/shared/go-request/request\"\n\nctx := context.Background()\nmethod := \"POST\"\nurl := \"https://example.com\"\nbody := map[string]string{\"key\": \"value\"}\n\nreq, err := gorequest.CreateRequest(ctx, method, url, body)\nif err != nil {\n    log.Fatalf(\"CreateRequest() failed: %v\", err)\n}\n</code></pre>"},{"location":"reference/libs/golang/shared/go-request/#sending-requests","title":"Sending Requests","text":"<p>The <code>SendRequest</code> function simplifies sending HTTP requests and handling responses. It takes an HTTP request, an HTTP client (you can use the provided <code>DefaultHTTPClient</code> or create your own), and a result structure for the response. Here's how to use it:</p> <pre><code>import gorequest \"libs/golang/shared/go-request/request\"\n\nctx := context.Background()\nmethod := \"GET\"\nurl := \"https://example.com\"\nvar result map[string]interface{}\n\nreq, err := gorequest.CreateRequest(ctx, method, url, nil)\nif err != nil {\n    log.Fatalf(\"CreateRequest() failed: %v\", err)\n}\n\nclient := gorequest.DefaultHTTPClient\n\nerr = gorequest.SendRequest(req, client, &amp;result)\nif err != nil {\n    log.Fatalf(\"SendRequest() failed: %v\", err)\n}\n</code></pre>"},{"location":"reference/libs/nx-plugins/env-setup/","title":"env-setup","text":"<p>The <code>env-setup</code> Nx plugin provides three executors to manage your local environment configuration, including creating a bucket, inserting configurations, and inserting schemas. This README will guide you through the usage of each executor and provide essential information about the plugin.</p>"},{"location":"reference/libs/nx-plugins/env-setup/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Create Bucket Executor</li> <li>Insert Configurations Executor</li> <li>Insert Schemas Executor</li> </ul>"},{"location":"reference/libs/nx-plugins/env-setup/#create-bucket-executor","title":"Create Bucket Executor","text":"<p>The Create Bucket Executor allows you to create a bucket using the Minio client. To use this executor, follow these steps:</p>"},{"location":"reference/libs/nx-plugins/env-setup/#executor-configuration","title":"Executor Configuration","text":"<p>Add a target in <code>targets</code> of the project <code>project.json</code>:</p> <pre><code>...\n\"create-bucket\": {\n      \"executor\": \"@nx-plugins/env-setup:create-bucket\"\n    }\n...\n</code></pre>"},{"location":"reference/libs/nx-plugins/env-setup/#executor-usage","title":"Executor Usage","text":"<p>Run the Create Bucket Executor using the following command:</p> <pre><code>npx nx create-bucket your-project-name --name=your-bucket-name\n</code></pre>"},{"location":"reference/libs/nx-plugins/env-setup/#insert-configurations-executor","title":"Insert Configurations Executor","text":"<p>The Insert Configurations Executor allows you to insert configuration files into a specified endpoint. To use this executor, follow these steps:</p>"},{"location":"reference/libs/nx-plugins/env-setup/#executor-configuration_1","title":"Executor Configuration","text":"<p>Add a target in <code>targets</code> of the project <code>project.json</code>:</p> <pre><code>...\n\"insert-configs\": {\n      \"executor\": \"@nx-plugins/env-setup:insert-configs\"\n    }\n...\n</code></pre>"},{"location":"reference/libs/nx-plugins/env-setup/#executor-usage_1","title":"Executor Usage","text":"<p>Run the Insert Configurations Executor using the following command:</p> <pre><code>npx nx insert-configs your-project-name --source=your-source-name\n</code></pre>"},{"location":"reference/libs/nx-plugins/env-setup/#insert-schemas-executor","title":"Insert Schemas Executor","text":"<p>The Insert Schemas Executor allows you to insert schema files into a specified endpoint. To use this executor, follow these steps:</p>"},{"location":"reference/libs/nx-plugins/env-setup/#executor-configuration_2","title":"Executor Configuration","text":"<p>Add a target in <code>targets</code> of the project <code>project.json</code>:</p> <pre><code>...\n\"insert-schemas\": {\n      \"executor\": \"@nx-plugins/env-setup:insert-schemas\"\n    }\n...\n</code></pre>"},{"location":"reference/libs/nx-plugins/env-setup/#executor-usage_2","title":"Executor Usage","text":"<p>Run the Insert Schemas Executor using the following command:</p> <pre><code>npx nx insert-schemas your-project-name --source=your-source-name\n</code></pre>"},{"location":"reference/libs/nx-plugins/env-setup/#insert-file-catalogs-executor","title":"Insert File Catalogs Executor","text":"<p>The Insert File Catalogs Executor allows you to insert file catalog files into a specified endpoint. To use this executor, follow these steps:</p>"},{"location":"reference/libs/nx-plugins/env-setup/#executor-configuration_3","title":"Executor Configuration","text":"<p>Add a target in <code>targets</code> of the project <code>project.json</code>:</p> <pre><code>...\n\"insert-file-catalogs\": {\n      \"executor\": \"@nx-plugins/env-setup:insert-file-catalogs\"\n    }\n...\n</code></pre>"},{"location":"reference/libs/nx-plugins/env-setup/#executor-usage_3","title":"Executor Usage","text":"<p>Run the Insert Schemas Executor using the following command:</p> <pre><code>npx nx insert-file-catalogs your-project-name --source=your-source-name\n</code></pre> <p>Feel free to customize the provided executor configurations and adapt them to your project's needs. For more information on Nx and the available options, please refer to the Nx documentation.</p>"},{"location":"reference/libs/python/resources/py-minio/","title":"py-minio","text":"<p><code>py-minio</code> is a Python library that provides a client class for interacting with a Minio server. It allows you to create buckets, upload and download objects, list buckets and objects, and generate URIs for accessing objects on a Minio server.</p>"},{"location":"reference/libs/python/resources/py-minio/#features","title":"Features","text":"<ul> <li>Create new buckets on the Minio server.</li> <li>List all available buckets on the Minio server.</li> <li>Upload files to a specified bucket.</li> <li>Upload bytes data to a specified bucket.</li> <li>Download files from a specified bucket and save locally.</li> <li>Download files from a specified bucket as bytes.</li> <li>List objects in a specified bucket.</li> <li>Generate URIs for accessing objects on the Minio server.</li> </ul>"},{"location":"reference/libs/python/resources/py-minio/#installation","title":"Installation","text":"<p>You can install <code>py-minio</code> using <code>nx</code>:</p> <pre><code>npx nx add &lt;project&gt; --name python-resources-py-minio --local\n</code></pre>"},{"location":"reference/libs/python/resources/py-minio/#examples","title":"Examples","text":"<p>Here's an example of how to use py-minio:</p> <pre><code>from pyminio.client import MinioClient\n\n# Initialize the Minio client\nminio = MinioClient(endpoint=\"http://minio.example.com\", access_key=\"your_access_key\", secret_key=\"your_secret_key\")\n\n# Create a new bucket\nminio.create_bucket(\"my_bucket\")\n\n# Upload a file to the bucket\nminio.upload_file(\"my_bucket\", \"example.txt\", \"path/to/local/file.txt\")\n\n# List objects in the bucket\nobjects = minio.list_objects(\"my_bucket\")\nprint(objects)\n</code></pre>"},{"location":"reference/libs/python/resources/py-minio/#configuration","title":"Configuration","text":"<p>Before using the <code>py-minio</code> library, make sure to configure the Minio server connection with valid credentials and an endpoint URL. You can pass these details when initializing the <code>MinioClient</code>.</p>"},{"location":"reference/libs/python/resources/py-minio/#api-reference","title":"API Reference","text":"<p><code>create_bucket(bucket_name)</code>: Create a new bucket on the Minio server. <code>list_buckets()</code>: List all buckets available on the Minio server. <code>upload_file(bucket_name, object_name, file_path)</code>: Upload a file to a specified bucket on the Minio server. <code>upload_bytes(bucket_name, object_name, bytes_data)</code>: Upload bytes data to a specified bucket on the Minio server. <code>download_file(bucket_name, object_name, file_path)</code>: Download a file from a specified bucket on the Minio server and save it locally. <code>download_file_as_bytes(bucket_name, object_name)</code>: Download a file from a specified bucket on the Minio server as bytes. <code>list_objects(bucket_name)</code>: List objects in a specified bucket on the Minio server.</p>"},{"location":"reference/libs/python/resources/py-minio/#note","title":"Note","text":"<p>Make sure to configure the Minio server connection with valid credentials and an endpoint URL before using the methods of this class.</p>"},{"location":"reference/libs/python/resources/py-rabbitmq/","title":"py-rabbitmq","text":"<p><code>py-rabbitmq</code> is a Python library that simplifies interaction with RabbitMQ using asynchronous Python libraries. It provides a base class for handling RabbitMQ connections and a consumer class for consuming messages from RabbitMQ queues.</p>"},{"location":"reference/libs/python/resources/py-rabbitmq/#installation","title":"Installation","text":"<p>You can install <code>py-rabbitmq</code> using <code>nx</code>:</p> <pre><code>npx nx add &lt;project&gt; --name python-resources-py-rabbitmq --local\n</code></pre>"},{"location":"reference/libs/python/resources/py-rabbitmq/#usage","title":"Usage","text":"<p>The <code>RabbitMQConsumer</code> class is used for consuming messages from RabbitMQ queues. It extends the <code>BaseRabbitMQ</code> class. The <code>BaseRabbitMQ</code> class is a base class for interacting with RabbitMQ. It provides methods for connecting to RabbitMQ, creating channels, declaring exchanges, creating queues, and publishing messages.</p>"},{"location":"reference/libs/python/resources/py-rabbitmq/#examples","title":"Examples","text":"<pre><code>import asyncio\nfrom pylog.log import setup_logging\nimport aio_pika\nfrom pyrabbitmq.consumer import RabbitMQConsumer\n\nlogger = setup_logging(__name__)\n\n# Define a callback function to process incoming messages\nasync def process_message(message):\n    body = message.body.decode()\n    logger.info(f\"Received message: {body}\")\n\n# Create a RabbitMQConsumer instance\nasync def main():\n    consumer = RabbitMQConsumer()\n\n    # Establish a connection to RabbitMQ\n    await consumer.connect()\n\n    # Create a channel\n    channel = await consumer.create_channel()\n\n    # Define the queue name and routing key\n    queue_name = \"my_queue\"\n    exchange_name = \"my_exchange\"\n    routing_key = \"my_routing_key\"\n\n    # Create a queue and bind it to the exchange\n    queue = await consumer.create_queue(channel, queue_name, exchange_name, routing_key)\n\n    # Start listening for messages\n    await consumer.listen(queue, process_message)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"reference/libs/python/resources/py-rabbitmq/code_reference/pyrabbitmq/base/","title":"Base","text":""},{"location":"reference/libs/python/resources/py-rabbitmq/code_reference/pyrabbitmq/base/#libs.python.resources.py-rabbitmq.pyrabbitmq.base.BaseRabbitMQ","title":"<code>BaseRabbitMQ</code>","text":"<p>A base class for interacting with RabbitMQ.</p> <p>Attributes:</p> Name Type Description <code>_sd</code> <p>The service discovery instance.</p> <code>url</code> <p>The RabbitMQ connection URL.</p> <code>connection</code> <p>The RabbitMQ connection.</p> <code>exchange</code> <p>The RabbitMQ exchange.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>Initialize the BaseRabbitMQ object.</p> <code>_connect</code> <p>Connect to RabbitMQ.</p> <code>connect</code> <p>Retry connecting to RabbitMQ until successful.</p> <code>on_connection_error</code> <p>Handle connection errors.</p> <code>create_channel</code> <p>Create a new channel in the RabbitMQ connection.</p> <code>declare_exchange</code> <p>Declare a RabbitMQ exchange.</p> <code>create_queue</code> <p>Create a RabbitMQ queue and bind it to an exchange.</p> <code>close_connection</code> <p>Close the RabbitMQ connection.</p> <code>publish_message</code> <p>Publish a message to a RabbitMQ exchange.</p> Source code in <code>libs/python/resources/py-rabbitmq/pyrabbitmq/base.py</code> <pre><code>class BaseRabbitMQ:\n    \"\"\"A base class for interacting with RabbitMQ.\n\n    Args:\n        None\n\n    Attributes:\n        _sd: The service discovery instance.\n        url: The RabbitMQ connection URL.\n        connection: The RabbitMQ connection.\n        exchange: The RabbitMQ exchange.\n\n    Methods:\n        __init__: Initialize the BaseRabbitMQ object.\n        _connect: Connect to RabbitMQ.\n        connect: Retry connecting to RabbitMQ until successful.\n        on_connection_error: Handle connection errors.\n        create_channel: Create a new channel in the RabbitMQ connection.\n        declare_exchange: Declare a RabbitMQ exchange.\n        create_queue: Create a RabbitMQ queue and bind it to an exchange.\n        close_connection: Close the RabbitMQ connection.\n        publish_message: Publish a message to a RabbitMQ exchange.\n\n    \"\"\"\n    def __init__(self) -&gt; None:\n        self._sd = new_from_env()\n        self.url = self._sd.rabbitmq_endpoint()\n        self.connection = None\n        self.exchange = None\n\n    async def _connect(self) -&gt; None:\n        \"\"\"Connect to RabbitMQ.\n\n        Args:\n            None\n\n        Returns:\n            None\n\n        \"\"\"\n        parsed_url = urllib.parse.urlparse(self.url)\n        self.connection = await aio_pika.connect(\n            host=parsed_url.hostname,\n            port=parsed_url.port,\n            login=parsed_url.username,\n            password=parsed_url.password,\n            timeout=100,\n            heartbeat=60,\n        )\n\n    async def connect(self, max_retries: int = 5) -&gt; None:\n        \"\"\"Retry connecting to RabbitMQ until successful.\n\n        Args:\n            max_retries (int): The maximum number of connection retries.\n\n        Raises:\n            RuntimeError: If failed to connect to RabbitMQ after multiple retries.\n\n        Returns:\n            None\n        \"\"\"\n        retries = 0\n        while retries &lt; max_retries:\n            try:\n                await self._connect()\n                break\n            except Exception as err:\n                logger.error('[CONNECTION] - Could not connect to RabbitMQ, retrying in 2 seconds...')\n                self.on_connection_error(err)\n                await asyncio.sleep(2)\n                retries += 1\n        else:\n            raise RuntimeError(\"Failed to connect to RabbitMQ after multiple retries\")\n\n\n\n    def on_connection_error(self, error: Exception) -&gt; None:\n        \"\"\"Handle connection errors.\n\n        Args:\n            error (Exception): The connection error.\n\n        Returns:\n            None\n\n        \"\"\"\n        logger.error(f\"Connection error: {error}\")\n        logger.error(f\"Connection parameters: {self.url}\")\n\n    async def create_channel(self) -&gt; aio_pika.Channel:\n        channel = await self.connection.channel()\n        await channel.set_qos(prefetch_count=1)\n        return channel\n\n    async def declare_exchange(self, channel: aio_pika.Channel, exchange_name: str) -&gt; None:\n        \"\"\"Declare a RabbitMQ exchange.\n\n        Args:\n            channel (aio_pika.Channel): The channel to declare the exchange on.\n            exchange_name (str): The name of the exchange.\n\n        Returns:\n            None\n\n        \"\"\"\n        self.exchange = await channel.declare_exchange(\n            exchange_name, aio_pika.ExchangeType.TOPIC, durable=True\n        )\n\n    async def create_queue(self, channel: aio_pika.Channel, queue_name: str, exchange_name: str, routing_key: str) -&gt; aio_pika.Queue:\n        \"\"\"Create a RabbitMQ queue and bind it to an exchange.\n\n        Args:\n            channel (aio_pika.Channel): The channel to create the queue on.\n            queue_name (str): The name of the queue.\n            exchange_name (str): The name of the exchange to bind the queue to.\n            routing_key (str): The routing key to use for binding.\n\n        Returns:\n            aio_pika.Queue: The created queue.\n\n        \"\"\"\n        await self.declare_exchange(channel, exchange_name)\n        queue = await channel.declare_queue(queue_name, durable=True)\n        await queue.bind(self.exchange, routing_key)\n\n        return queue\n\n    async def close_connection(self) -&gt; None:\n        \"\"\"Close the RabbitMQ connection.\n\n        Args:\n            None\n\n        Returns:\n            None\n\n        \"\"\"\n        if self.connection is not None:\n            await self.connection.close()\n            self.connection = None\n\n    async def publish_message(self, exchange_name: str, routing_key: str, message: str) -&gt; None:\n        \"\"\"Publish a message to a RabbitMQ exchange.\n\n        Args:\n            exchange_name (str): The name of the exchange to publish to.\n            routing_key (str): The routing key for the message.\n            message (str): The message to publish.\n\n        Returns:\n            None\n\n        \"\"\"\n        try:\n            await self.exchange.publish(\n                aio_pika.Message(\n                    body=message.encode(),\n                    delivery_mode=aio_pika.DeliveryMode.PERSISTENT,\n                ),\n                routing_key=routing_key,\n            )\n            logger.info(f\"Published message to exchange '{exchange_name}' with routing key '{routing_key}'\")\n        except Exception as e:\n            logger.error(f\"Error while publishing message: {e}\")\n</code></pre>"},{"location":"reference/libs/python/resources/py-rabbitmq/code_reference/pyrabbitmq/base/#libs.python.resources.py-rabbitmq.pyrabbitmq.base.BaseRabbitMQ.connect","title":"<code>connect(max_retries=5)</code>  <code>async</code>","text":"<p>Retry connecting to RabbitMQ until successful.</p> <p>Parameters:</p> Name Type Description Default <code>max_retries</code> <code>int</code> <p>The maximum number of connection retries.</p> <code>5</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If failed to connect to RabbitMQ after multiple retries.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>libs/python/resources/py-rabbitmq/pyrabbitmq/base.py</code> <pre><code>async def connect(self, max_retries: int = 5) -&gt; None:\n    \"\"\"Retry connecting to RabbitMQ until successful.\n\n    Args:\n        max_retries (int): The maximum number of connection retries.\n\n    Raises:\n        RuntimeError: If failed to connect to RabbitMQ after multiple retries.\n\n    Returns:\n        None\n    \"\"\"\n    retries = 0\n    while retries &lt; max_retries:\n        try:\n            await self._connect()\n            break\n        except Exception as err:\n            logger.error('[CONNECTION] - Could not connect to RabbitMQ, retrying in 2 seconds...')\n            self.on_connection_error(err)\n            await asyncio.sleep(2)\n            retries += 1\n    else:\n        raise RuntimeError(\"Failed to connect to RabbitMQ after multiple retries\")\n</code></pre>"},{"location":"reference/libs/python/resources/py-rabbitmq/code_reference/pyrabbitmq/base/#libs.python.resources.py-rabbitmq.pyrabbitmq.base.BaseRabbitMQ.on_connection_error","title":"<code>on_connection_error(error)</code>","text":"<p>Handle connection errors.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>Exception</code> <p>The connection error.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>libs/python/resources/py-rabbitmq/pyrabbitmq/base.py</code> <pre><code>def on_connection_error(self, error: Exception) -&gt; None:\n    \"\"\"Handle connection errors.\n\n    Args:\n        error (Exception): The connection error.\n\n    Returns:\n        None\n\n    \"\"\"\n    logger.error(f\"Connection error: {error}\")\n    logger.error(f\"Connection parameters: {self.url}\")\n</code></pre>"},{"location":"reference/libs/python/resources/py-rabbitmq/code_reference/pyrabbitmq/base/#libs.python.resources.py-rabbitmq.pyrabbitmq.base.BaseRabbitMQ.declare_exchange","title":"<code>declare_exchange(channel, exchange_name)</code>  <code>async</code>","text":"<p>Declare a RabbitMQ exchange.</p> <p>Parameters:</p> Name Type Description Default <code>channel</code> <code>Channel</code> <p>The channel to declare the exchange on.</p> required <code>exchange_name</code> <code>str</code> <p>The name of the exchange.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>libs/python/resources/py-rabbitmq/pyrabbitmq/base.py</code> <pre><code>async def declare_exchange(self, channel: aio_pika.Channel, exchange_name: str) -&gt; None:\n    \"\"\"Declare a RabbitMQ exchange.\n\n    Args:\n        channel (aio_pika.Channel): The channel to declare the exchange on.\n        exchange_name (str): The name of the exchange.\n\n    Returns:\n        None\n\n    \"\"\"\n    self.exchange = await channel.declare_exchange(\n        exchange_name, aio_pika.ExchangeType.TOPIC, durable=True\n    )\n</code></pre>"},{"location":"reference/libs/python/resources/py-rabbitmq/code_reference/pyrabbitmq/base/#libs.python.resources.py-rabbitmq.pyrabbitmq.base.BaseRabbitMQ.create_queue","title":"<code>create_queue(channel, queue_name, exchange_name, routing_key)</code>  <code>async</code>","text":"<p>Create a RabbitMQ queue and bind it to an exchange.</p> <p>Parameters:</p> Name Type Description Default <code>channel</code> <code>Channel</code> <p>The channel to create the queue on.</p> required <code>queue_name</code> <code>str</code> <p>The name of the queue.</p> required <code>exchange_name</code> <code>str</code> <p>The name of the exchange to bind the queue to.</p> required <code>routing_key</code> <code>str</code> <p>The routing key to use for binding.</p> required <p>Returns:</p> Type Description <code>Queue</code> <p>aio_pika.Queue: The created queue.</p> Source code in <code>libs/python/resources/py-rabbitmq/pyrabbitmq/base.py</code> <pre><code>async def create_queue(self, channel: aio_pika.Channel, queue_name: str, exchange_name: str, routing_key: str) -&gt; aio_pika.Queue:\n    \"\"\"Create a RabbitMQ queue and bind it to an exchange.\n\n    Args:\n        channel (aio_pika.Channel): The channel to create the queue on.\n        queue_name (str): The name of the queue.\n        exchange_name (str): The name of the exchange to bind the queue to.\n        routing_key (str): The routing key to use for binding.\n\n    Returns:\n        aio_pika.Queue: The created queue.\n\n    \"\"\"\n    await self.declare_exchange(channel, exchange_name)\n    queue = await channel.declare_queue(queue_name, durable=True)\n    await queue.bind(self.exchange, routing_key)\n\n    return queue\n</code></pre>"},{"location":"reference/libs/python/resources/py-rabbitmq/code_reference/pyrabbitmq/base/#libs.python.resources.py-rabbitmq.pyrabbitmq.base.BaseRabbitMQ.close_connection","title":"<code>close_connection()</code>  <code>async</code>","text":"<p>Close the RabbitMQ connection.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>libs/python/resources/py-rabbitmq/pyrabbitmq/base.py</code> <pre><code>async def close_connection(self) -&gt; None:\n    \"\"\"Close the RabbitMQ connection.\n\n    Args:\n        None\n\n    Returns:\n        None\n\n    \"\"\"\n    if self.connection is not None:\n        await self.connection.close()\n        self.connection = None\n</code></pre>"},{"location":"reference/libs/python/resources/py-rabbitmq/code_reference/pyrabbitmq/base/#libs.python.resources.py-rabbitmq.pyrabbitmq.base.BaseRabbitMQ.publish_message","title":"<code>publish_message(exchange_name, routing_key, message)</code>  <code>async</code>","text":"<p>Publish a message to a RabbitMQ exchange.</p> <p>Parameters:</p> Name Type Description Default <code>exchange_name</code> <code>str</code> <p>The name of the exchange to publish to.</p> required <code>routing_key</code> <code>str</code> <p>The routing key for the message.</p> required <code>message</code> <code>str</code> <p>The message to publish.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>libs/python/resources/py-rabbitmq/pyrabbitmq/base.py</code> <pre><code>async def publish_message(self, exchange_name: str, routing_key: str, message: str) -&gt; None:\n    \"\"\"Publish a message to a RabbitMQ exchange.\n\n    Args:\n        exchange_name (str): The name of the exchange to publish to.\n        routing_key (str): The routing key for the message.\n        message (str): The message to publish.\n\n    Returns:\n        None\n\n    \"\"\"\n    try:\n        await self.exchange.publish(\n            aio_pika.Message(\n                body=message.encode(),\n                delivery_mode=aio_pika.DeliveryMode.PERSISTENT,\n            ),\n            routing_key=routing_key,\n        )\n        logger.info(f\"Published message to exchange '{exchange_name}' with routing key '{routing_key}'\")\n    except Exception as e:\n        logger.error(f\"Error while publishing message: {e}\")\n</code></pre>"},{"location":"reference/libs/python/resources/py-rabbitmq/code_reference/pyrabbitmq/consumer/","title":"Consumer","text":""},{"location":"reference/libs/python/resources/py-rabbitmq/code_reference/pyrabbitmq/consumer/#libs.python.resources.py-rabbitmq.pyrabbitmq.consumer.RabbitMQConsumer","title":"<code>RabbitMQConsumer</code>","text":"<p>             Bases: <code>BaseRabbitMQ</code></p> <p>A RabbitMQ consumer class that extends BaseRabbitMQ.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>Initialize the RabbitMQConsumer object.</p> <code>listen</code> <p>Asynchronously listen to a queue and call the callback function on message arrival.</p> Source code in <code>libs/python/resources/py-rabbitmq/pyrabbitmq/consumer.py</code> <pre><code>class RabbitMQConsumer(BaseRabbitMQ):\n    \"\"\"A RabbitMQ consumer class that extends BaseRabbitMQ.\n\n    Args:\n        None\n\n    Attributes:\n        None\n\n    Methods:\n        __init__: Initialize the RabbitMQConsumer object.\n        listen: Asynchronously listen to a queue and call the callback function on message arrival.\n\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n\n    async def listen(self, queue: aio_pika.Queue, callback: callable) -&gt; None:\n        \"\"\"Listen to a RabbitMQ queue and call the specified callback on message arrival.\n\n        Args:\n            queue (aio_pika.Queue): The queue to listen to.\n            callback (callable): The callback function to execute on message arrival.\n\n        Returns:\n            None\n\n        \"\"\"\n        async with queue.iterator() as queue_iter:\n            message: aio_pika.AbstractIncomingMessage\n            async for message in queue_iter:\n                await callback(message)\n</code></pre>"},{"location":"reference/libs/python/resources/py-rabbitmq/code_reference/pyrabbitmq/consumer/#libs.python.resources.py-rabbitmq.pyrabbitmq.consumer.RabbitMQConsumer.listen","title":"<code>listen(queue, callback)</code>  <code>async</code>","text":"<p>Listen to a RabbitMQ queue and call the specified callback on message arrival.</p> <p>Parameters:</p> Name Type Description Default <code>queue</code> <code>Queue</code> <p>The queue to listen to.</p> required <code>callback</code> <code>callable</code> <p>The callback function to execute on message arrival.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>libs/python/resources/py-rabbitmq/pyrabbitmq/consumer.py</code> <pre><code>async def listen(self, queue: aio_pika.Queue, callback: callable) -&gt; None:\n    \"\"\"Listen to a RabbitMQ queue and call the specified callback on message arrival.\n\n    Args:\n        queue (aio_pika.Queue): The queue to listen to.\n        callback (callable): The callback function to execute on message arrival.\n\n    Returns:\n        None\n\n    \"\"\"\n    async with queue.iterator() as queue_iter:\n        message: aio_pika.AbstractIncomingMessage\n        async for message in queue_iter:\n            await callback(message)\n</code></pre>"},{"location":"reference/libs/python/services/api-clients/services-config-handler/","title":"service-config-handler","text":"<p><code>service-config-handler</code> is a Python library that provides a client for interacting with a service configuration management system. It allows you to create, list, and retrieve configuration data for various services.</p>"},{"location":"reference/libs/python/services/api-clients/services-config-handler/#installation","title":"Installation","text":"<p>You can install <code>service-config-handler</code> using <code>nx</code>:</p> <pre><code>npx nx add &lt;project&gt; --name python-services-api-clients-services-config-handler --local\n</code></pre>"},{"location":"reference/libs/python/services/api-clients/services-config-handler/#usage","title":"Usage","text":""},{"location":"reference/libs/python/services/api-clients/services-config-handler/#initializing-the-client","title":"Initializing the Client","text":"<p>You can initialize the client by providing the base URL of your service configuration management system.</p> <pre><code>config_handler_client = async_py_config_handler_client()\n</code></pre>"},{"location":"reference/libs/python/services/api-clients/services-config-handler/#creating-a-configuration","title":"Creating a Configuration","text":"<p>To create a new configuration, use the <code>create_config</code> method, passing a dictionary of configuration data.</p> <pre><code>data = {\n    \"key\": \"value\",\n    \"another_key\": \"another_value\"\n}\nnew_config = await config_handler_client.create_config(data)\n</code></pre>"},{"location":"reference/libs/python/services/api-clients/services-config-handler/#listing-all-configurations","title":"Listing All Configurations","text":"<p>To list all configurations, use the <code>list_all_configs</code> method.</p> <pre><code>configs = await config_handler_client.list_all_configs()\n</code></pre>"},{"location":"reference/libs/python/services/api-clients/services-config-handler/#listing-a-configuration-by-id","title":"Listing a Configuration by ID","text":"<p>To retrieve a specific configuration by its ID, use the <code>list_one_config_by_id</code> method.</p> <pre><code>config_id = \"your_config_id\"\nconfig = await config_handler_client.list_one_config_by_id(config_id)\n</code></pre>"},{"location":"reference/libs/python/services/api-clients/services-config-handler/#listing-configurations-by-service","title":"Listing Configurations by Service","text":"<p>To retrieve all configurations associated with a specific service, use the <code>list_all_configs_by_service</code> method.</p> <pre><code>service_name = \"your_service_name\"\nservice_configs = await config_handler_client.list_all_configs_by_service(service_name)\n</code></pre>"},{"location":"reference/libs/python/services/api-clients/services-config-handler/#listing-configurations-by-service-and-context","title":"Listing Configurations by Service and Context","text":"<p>To retrieve configurations associated with a specific service and context, use the <code>list_all_configs_by_service_and_context</code> method.</p> <pre><code>service_name = \"your_service_name\"\ncontext = \"your_context\"\nservice_context_configs = await config_handler_client.list_all_configs_by_service_and_context(service_name, context)\n</code></pre>"},{"location":"reference/libs/python/services/api-clients/services-config-handler/#service-discovery","title":"Service Discovery","text":"<p>The library also provides a convenient function <code>async_py_config_handler_client</code> to create a client using service discovery. This function automatically retrieves the base URL from your environment using <code>new_from_env()</code>.</p> <pre><code>config_handler_client = async_py_config_handler_client()\n</code></pre> <p>Make sure to set up your service discovery environment variables before using this function.</p>"},{"location":"reference/libs/python/services/api-clients/services-config-handler/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/python/services/api-clients/services-file-catalog-handler/","title":"service-file-catalog-handler","text":"<p><code>service-file-catalog-handler</code> is a Python library that provides a client for interacting with a service file catalog management system. It allows you to create, list, and retrieve file catalogs data for various services.</p>"},{"location":"reference/libs/python/services/api-clients/services-file-catalog-handler/#installation","title":"Installation","text":"<p>You can install <code>service-file-catalog-handler</code> using <code>nx</code>:</p> <pre><code>npx nx add &lt;project&gt; --name python-services-api-clients-services-file-catalog-handler --local\n</code></pre>"},{"location":"reference/libs/python/services/api-clients/services-file-catalog-handler/#usage","title":"Usage","text":""},{"location":"reference/libs/python/services/api-clients/services-file-catalog-handler/#initializing-the-client","title":"Initializing the Client","text":"<p>You can initialize the client by providing the base URL of your service configuration management system.</p> <pre><code>file_catalog_handler_client = async_py_file_catalog_handler_client()\n</code></pre>"},{"location":"reference/libs/python/services/api-clients/services-file-catalog-handler/#listing-a-file-catalog-by-id","title":"Listing a File Catalog by ID","text":"<p>To retrieve a specific configuration by its ID, use the <code>list_one_file_catalog_by_id</code> method.</p> <pre><code>file_catalog_id = \"your_file_catalog_id\"\nfile_catalog = await file_catalog_handler_client.list_one_file_catalog_by_id(file_catalog_id)\n</code></pre>"},{"location":"reference/libs/python/services/api-clients/services-file-catalog-handler/#listing-a-file-catalog-by-service-and-source","title":"Listing a File Catalog by Service and Source","text":"<p>To retrieve one file catalog associated with a specific service and source, use the <code>list_one_file_catalog_by_service_source</code> method.</p> <pre><code>service_name = \"your_service_name\"\nsource_name = \"your_source_name\"\nservice_configs = await file_catalog_handler_client.list_one_file_catalog_by_service_source(service_name, source_name)\n</code></pre>"},{"location":"reference/libs/python/services/api-clients/services-file-catalog-handler/#service-discovery","title":"Service Discovery","text":"<p>The library also provides a convenient function <code>async_py_file_catalog_handler_client</code> to create a client using service discovery. This function automatically retrieves the base URL from your environment using <code>new_from_env()</code>.</p> <pre><code>file_catalog_handler_client = async_py_file_catalog_handler_client()\n</code></pre> <p>Make sure to set up your service discovery environment variables before using this function.</p>"},{"location":"reference/libs/python/services/api-clients/services-file-catalog-handler/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/python/services/api-clients/services-schema-handler/","title":"service-schema-handler","text":"<p><code>service-schema-handler</code> is a Python library that provides a client for interacting with a service configuration management system. It allows you to create, list, and retrieve configuration data for various services.</p>"},{"location":"reference/libs/python/services/api-clients/services-schema-handler/#installation","title":"Installation","text":"<p>You can install <code>service-schema-handler</code> using <code>nx</code>:</p> <pre><code>npx nx add &lt;project&gt; --name python-services-api-clients-services-schema-handler --local\n</code></pre>"},{"location":"reference/libs/python/services/api-clients/services-schema-handler/#usage","title":"Usage","text":""},{"location":"reference/libs/python/services/api-clients/services-schema-handler/#initializing-the-client","title":"Initializing the Client","text":"<p>You can initialize the client by providing the base URL of your service configuration management system.</p> <pre><code>schema_handler_client = async_py_schema_handler_client()\n</code></pre>"},{"location":"reference/libs/python/services/api-clients/services-schema-handler/#listing-a-schema-by-service-source-and-schema-type","title":"Listing a schema by Service, Source and Schema Type","text":"<p>To retrieve a specific configuration by its ID, use the <code>list_one_schema_by_service_n_source_n_schema_type</code> method.</p> <pre><code>service_name = \"your_service_name\"\nsource_name = \"your_source_name\"\nschema_type = \"your_schema_type\"\nconfig = await config_handler_client.list_one_schema_by_service_n_source_n_schema_type(\n    service_name,\n    source_name,\n    schema_type\n)\n</code></pre>"},{"location":"reference/libs/python/services/api-clients/services-schema-handler/#listing-a-schema-by-context-service-source-and-schema-type","title":"Listing a schema by Context, Service, Source and Schema Type","text":"<p>To retrieve a specific configuration by its ID, use the <code>list_one_schema_by_service_n_source_n_context_n_schema_type</code> method.</p> <pre><code>context_name = \"your_context_name\"\nservice_name = \"your_service_name\"\nsource_name = \"your_source_name\"\nschema_type = \"your_schema_type\"\nconfig = await config_handler_client.list_one_schema_by_service_n_source_n_context_n_schema_type(\n    context_name,\n    service_name,\n    source_name,\n    schema_type\n)\n</code></pre>"},{"location":"reference/libs/python/services/api-clients/services-schema-handler/#service-discovery","title":"Service Discovery","text":"<p>The library also provides a convenient function <code>async_py_schema_handler_client</code> to create a client using service discovery. This function automatically retrieves the base URL from your environment using <code>new_from_env()</code>.</p> <pre><code>config_handler_client = async_py_schema_handler_client()\n</code></pre> <p>Make sure to set up your service discovery environment variables before using this function.</p>"},{"location":"reference/libs/python/services/api-clients/services-schema-handler/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/python/services/dtos/services-config-handler/","title":"services-config-handler","text":"<p>The <code>services-config-handler</code> library contains Data Transfer Objects (DTOs) for the <code>services-config-handler</code> service. These DTOs are used to define the structure of data exchanged between different parts of the service, providing a clear and standardized representation of data.</p>"},{"location":"reference/libs/python/services/dtos/services-config-handler/#usage","title":"Usage","text":"<p>To use the DTOs provided by this library, import the necessary package in your Python code. You can then create instances of these DTOs to work with data in a structured and consistent way.</p>"},{"location":"reference/libs/python/services/dtos/services-config-handler/#importing-the-library","title":"Importing the Library","text":"<p>Import the library in your python code as follows:</p> <pre><code>from dto_config_handler.output import InputDTO\nfrom dto_config_handler.shared import StatusDTO, MetadataDTO\n</code></pre>"},{"location":"reference/libs/python/services/dtos/services-config-handler/#using-the-dtos","title":"Using the DTOs","text":"<p>You can use the DTOs in your code to represent and work with data structures related to the <code>services-config-handler</code> service.</p> <p>Here's an example of how to use the <code>ConfigDTO</code> from the output package:</p> <pre><code>from dto_config_handler.output import ConfigDTO\nfrom dto_config_handler.shared import JobDependencies\n\n# Create an instance of ConfigDTO with sample data\nconfig_data = ConfigDTO(\n    id=\"12345\",\n    name=\"SampleConfig\",\n    active=True,\n    frequency=\"daily\",\n    service=\"services-config-handler\",\n    source=\"user\",\n    context=\"example\",\n    config_id=\"67890\",\n    depends_on=[\n        JobDependencies(service=\"dependency-service\", source=\"dependency-source\"),\n        JobDependencies(service=\"another-service\", source=\"another-source\"),\n    ],\n    service_parameters={\n        \"param1\": \"value1\",\n        \"param2\": \"value2\",\n    },\n    job_parameters={\n        \"job_param1\": \"job_value1\",\n        \"job_param2\": \"job_value2\",\n    }\n)\n\n# Access the properties within the ConfigDTO\nprint(\"ID:\", config_data.id)\nprint(\"Name:\", config_data.name)\nprint(\"Active:\", config_data.active)\nprint(\"Frequency:\", config_data.frequency)\nprint(\"Service:\", config_data.service)\nprint(\"Source:\", config_data.source)\nprint(\"Context:\", config_data.context)\nprint(\"Config ID:\", config_data.config_id)\nprint(\"Depends On:\", config_data.depends_on)\nprint(\"Service Parameters:\", config_data.service_parameters)\nprint(\"Job Parameters:\", config_data.job_parameters)\n</code></pre>"},{"location":"reference/libs/python/services/dtos/services-config-handler/#dtos-provided","title":"DTOs Provided","text":"<p>The library provides the following DTOs for use in the <code>services-config-handler</code> service:</p>"},{"location":"reference/libs/python/services/dtos/services-config-handler/#configdto-output","title":"<code>ConfigDTO</code> (output)","text":"<p>This DTO represents the main data structure exchanged by the service, including data.</p>"},{"location":"reference/libs/python/services/dtos/services-config-handler/#jobdependencies-shared","title":"<code>JobDependencies</code> (shared)","text":"<p>This DTO includes the previous job dependency if exist</p>"},{"location":"reference/libs/python/services/dtos/services-config-handler/#contributions","title":"Contributions","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/python/services/dtos/services-config-handler/code_reference/dto_config_handler/shared/","title":"Shared","text":""},{"location":"reference/libs/python/services/dtos/services-events-handler/","title":"services-events-handler","text":"<p>The <code>services-events-handler</code> library contains Data Transfer Objects (DTOs) for the <code>services-events-handler</code> service. These DTOs are used to define the structure of data exchanged between different parts of the service, providing a clear and standardized representation of data.</p>"},{"location":"reference/libs/python/services/dtos/services-events-handler/#usage","title":"Usage","text":"<p>To use the DTOs provided by this library, import the necessary package in your Python code. You can then create instances of these DTOs to work with data in a structured and consistent way.</p>"},{"location":"reference/libs/python/services/dtos/services-events-handler/#importing-the-library","title":"Importing the Library","text":"<p>Import the library in your python code as follows:</p> <pre><code>from dto_events_handler.output import ServiceFeedbackDTO\nfrom dto_input_hadto_events_handlerndler.shared import StatusDTO, MetadataInputDTO, MetadataDTO\n</code></pre>"},{"location":"reference/libs/python/services/dtos/services-events-handler/#using-the-dtos","title":"Using the DTOs","text":"<p>You can use the DTOs in your code to represent and work with data structures related to the <code>services-events-handler</code> service.</p> <p>Here's an example of how to use the <code>ServiceFeedbackDTO</code> from the output package:</p> <pre><code>from dto_events_handler.output import ServiceFeedbackDTO\nfrom dto_events_handler.shared import StatusDTO, MetadataInputDTO, MetadataDTO\n\n# Create instances of the DTOs\nfeedback_data = {\n    \"key1\": \"value1\",\n    \"key2\": \"value2\"\n}\nmetadata_input = MetadataInputDTO(\n    id=\"123\",\n    data={\"input_key\": \"input_value\"},\n    processing_id=\"456\",\n    processing_timestamp=\"2023-11-02T14:30:00\",\n    input_schema_id=\"789\"\n)\nmetadata = MetadataDTO(\n    input=metadata_input,\n    service=\"example-service\",\n    source=\"example-source\",\n    context=\"example-context\",\n    processing_timestamp=\"2023-11-02T14:30:00\",\n    job_frequency=\"daily\",\n    job_config_id=\"101\"\n)\nstatus = StatusDTO(code=200, detail=\"OK\")\n\nfeedback_dto = ServiceFeedbackDTO(data=feedback_data, metadata=metadata, status=status)\n\n# Now you can work with the feedback DTO\nprint(feedback_dto.data)\nprint(feedback_dto.metadata.input.id)\nprint(feedback_dto.status.code)\n</code></pre>"},{"location":"reference/libs/python/services/dtos/services-events-handler/#dtos-provided","title":"DTOs Provided","text":"<p>The library provides the following DTOs for use in the <code>services-events-handler</code> service:</p>"},{"location":"reference/libs/python/services/dtos/services-events-handler/#servicefeedbackdto-output","title":"<code>ServiceFeedbackDTO</code> (output)","text":"<p>This DTO represents the main data structure exchanged by the service, including data.</p>"},{"location":"reference/libs/python/services/dtos/services-events-handler/#metadatadto-shared","title":"<code>MetadataDTO</code> (shared)","text":"<p>This DTO includes metadata information around the input, such as processing ID, processing timestamp, context, source, service and job config version id.</p>"},{"location":"reference/libs/python/services/dtos/services-events-handler/#metadatainputdto-shared","title":"<code>MetadataInputDTO</code> (shared)","text":"<p>This DTO includes metadata information around the output, such as processing timestamp, context, source, service and schema input version id.</p>"},{"location":"reference/libs/python/services/dtos/services-events-handler/#statusdto-shared","title":"<code>StatusDTO</code> (shared)","text":"<p>The <code>StatusDTO</code> DTO contains information about the status of the input, including a status code and a detail message.</p>"},{"location":"reference/libs/python/services/dtos/services-events-handler/#contributions","title":"Contributions","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/python/services/dtos/services-events-handler/code_reference/dto_events_handler/shared/","title":"Shared","text":""},{"location":"reference/libs/python/services/dtos/services-file-catalog-handler/","title":"services-file-catalog-handler","text":"<p>The <code>services-file-catalog-handler</code> library contains Data Transfer Objects (DTOs) for the <code>services-file-catalog-handler</code> service. These DTOs are used to define the structure of data exchanged between different parts of the service, providing a clear and standardized representation of data.</p>"},{"location":"reference/libs/python/services/dtos/services-file-catalog-handler/#usage","title":"Usage","text":"<p>To use the DTOs provided by this library, import the necessary package in your Python code. You can then create instances of these DTOs to work with data in a structured and consistent way.</p>"},{"location":"reference/libs/python/services/dtos/services-file-catalog-handler/#importing-the-library","title":"Importing the Library","text":"<p>Import the library in your python code as follows:</p> <pre><code>from dto_file_catalog_handler.output import SchemaDTO\n</code></pre>"},{"location":"reference/libs/python/services/dtos/services-file-catalog-handler/#using-the-dtos","title":"Using the DTOs","text":"<p>You can use the DTOs in your code to represent and work with data structures related to the <code>services-file-catalog-handler</code> service.</p> <p>Here's an example of how to use the <code>FileCatalogDTO</code> from the output package:</p> <pre><code>from dataclasses import dataclass, field\nfrom typing import Dict\nfrom dto_file_catalog_handler.output import FileCatalogDTO\n\n# Create an instance of FileCatalogDTO\nfile_catalog_data = {\n    \"id\": \"123\",\n    \"service\": \"file-catalog-handler\",\n    \"source\": \"example_source\",\n    \"context\": \"example_context\",\n    \"lake_layer\": \"raw\",\n    \"schema_type\": \"avro\",\n    \"catalog_id\": \"456\",\n    \"catalog\": {\"field1\": \"value1\", \"field2\": \"value2\"},\n    \"created_at\": \"2023-11-11T12:00:00Z\",\n    \"updated_at\": \"2023-11-11T13:30:00Z\"\n}\n\nfile_catalog_instance = FileCatalogDTO(**file_catalog_data)\n\n# Accessing attributes\nprint(f\"File ID: {file_catalog_instance.id}\")\nprint(f\"Service: {file_catalog_instance.service}\")\nprint(f\"Source: {file_catalog_instance.source}\")\nprint(f\"Context: {file_catalog_instance.context}\")\nprint(f\"Lake Layer: {file_catalog_instance.lake_layer}\")\nprint(f\"Schema Type: {file_catalog_instance.schema_type}\")\nprint(f\"Catalog ID: {file_catalog_instance.catalog_id}\")\nprint(f\"Catalog Data: {file_catalog_instance.catalog}\")\nprint(f\"Created At: {file_catalog_instance.created_at}\")\nprint(f\"Updated At: {file_catalog_instance.updated_at}\")\n</code></pre>"},{"location":"reference/libs/python/services/dtos/services-file-catalog-handler/#dtos-provided","title":"DTOs Provided","text":"<p>The library provides the following DTOs for use in the <code>services-file-catalog-handler</code> service:</p>"},{"location":"reference/libs/python/services/dtos/services-file-catalog-handler/#filecatalogdto-output","title":"<code>FileCatalogDTO</code> (output)","text":"<p>This DTO represents the main data structure exchanged by the service, including data.</p>"},{"location":"reference/libs/python/services/dtos/services-file-catalog-handler/#contributions","title":"Contributions","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/python/services/dtos/services-input-handler/","title":"services-input-handler","text":"<p>The <code>services-input-handler</code> library contains Data Transfer Objects (DTOs) for the <code>services-input-handler</code> service. These DTOs are used to define the structure of data exchanged between different parts of the service, providing a clear and standardized representation of data.</p>"},{"location":"reference/libs/python/services/dtos/services-input-handler/#usage","title":"Usage","text":"<p>To use the DTOs provided by this library, import the necessary package in your Python code. You can then create instances of these DTOs to work with data in a structured and consistent way.</p>"},{"location":"reference/libs/python/services/dtos/services-input-handler/#importing-the-library","title":"Importing the Library","text":"<p>Import the library in your python code as follows:</p> <pre><code>from dto_input_handler.output import InputDTO\nfrom dto_input_handler.shared import StatusDTO, MetadataDTO\n</code></pre>"},{"location":"reference/libs/python/services/dtos/services-input-handler/#using-the-dtos","title":"Using the DTOs","text":"<p>You can use the DTOs in your code to represent and work with data structures related to the <code>services-input-handler</code> service.</p> <p>Here's an example of how to use the <code>InputDTO</code> from the output package:</p> <pre><code>from dto_input_handler.output import InputDTO\nfrom dto_input_handler.shared import StatusDTO, MetadataDTO\n\n# Create an InputDTO object\ninput_data = InputDTO(\n    data={\n        \"key1\": \"value1\",\n        \"key2\": \"value2\",\n    },\n    status=StatusDTO(\n        code=200,\n        message=\"Success\",\n    ),\n    metadata=MetadataDTO(\n        processing_id=12345,\n        processing_timestamp=\"2023-11-02T15:30:00\",\n        context=\"example\",\n        source=\"user\",\n        service=\"services-input-handler\",\n    )\n)\n\n# Access the data within the InputDTO\nprint(\"Data: \", input_data.data)\nprint(\"Status Code: \", input_data.status.code)\nprint(\"Status Message: \", input_data.status.message)\nprint(\"Processing ID: \", input_data.metadata.processing_id)\nprint(\"Processing Timestamp: \", input_data.metadata.processing_timestamp)\nprint(\"Context: \", input_data.metadata.context)\nprint(\"Source: \", input_data.metadata.source)\nprint(\"Service: \", input_data.metadata.service)\n</code></pre>"},{"location":"reference/libs/python/services/dtos/services-input-handler/#dtos-provided","title":"DTOs Provided","text":"<p>The library provides the following DTOs for use in the <code>services-input-handler</code> service:</p>"},{"location":"reference/libs/python/services/dtos/services-input-handler/#inputdto-output","title":"<code>InputDTO</code> (output)","text":"<p>This DTO represents the main data structure exchanged by the service, including data.</p>"},{"location":"reference/libs/python/services/dtos/services-input-handler/#metadatadto-shared","title":"<code>MetadataDTO</code> (shared)","text":"<p>This DTO includes metadata information, such as processing ID, processing timestamp, context, source, and service.</p>"},{"location":"reference/libs/python/services/dtos/services-input-handler/#statusdto-shared","title":"<code>StatusDTO</code> (shared)","text":"<p>The <code>StatusDTO</code> DTO contains information about the status of the input, including a status code and a detail message.</p>"},{"location":"reference/libs/python/services/dtos/services-input-handler/#contributions","title":"Contributions","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/python/services/dtos/services-input-handler/code_reference/dto_input_handler/shared/","title":"Shared","text":""},{"location":"reference/libs/python/services/dtos/services-schema-handler/","title":"services-schema-handler","text":"<p>The <code>services-schema-handler</code> library contains Data Transfer Objects (DTOs) for the <code>services-schema-handler</code> service. These DTOs are used to define the structure of data exchanged between different parts of the service, providing a clear and standardized representation of data.</p>"},{"location":"reference/libs/python/services/dtos/services-schema-handler/#usage","title":"Usage","text":"<p>To use the DTOs provided by this library, import the necessary package in your Python code. You can then create instances of these DTOs to work with data in a structured and consistent way.</p>"},{"location":"reference/libs/python/services/dtos/services-schema-handler/#importing-the-library","title":"Importing the Library","text":"<p>Import the library in your python code as follows:</p> <pre><code>from dto_schema_handler.output import SchemaDTO\n</code></pre>"},{"location":"reference/libs/python/services/dtos/services-schema-handler/#using-the-dtos","title":"Using the DTOs","text":"<p>You can use the DTOs in your code to represent and work with data structures related to the <code>services-schema-handler</code> service.</p> <p>Here's an example of how to use the <code>SchemaDTO</code> from the output package:</p> <pre><code>from dto_schema_handler.output import SchemaDTO\n\n# Create an instance of SchemaDTO with sample data\nschema_data = SchemaDTO(\n    id=\"12345\",\n    schema_type=\"data_schema\",\n    service=\"services-schema-handler\",\n    source=\"user\",\n    context=\"example\",\n    json_schema={\n        \"type\": \"object\",\n        \"properties\": {\n            \"name\": {\"type\": \"string\"},\n            \"age\": {\"type\": \"integer\"}\n        }\n    },\n    schema_id=\"67890\"\n)\n\n# Access the properties within the SchemaDTO\nprint(\"ID:\", schema_data.id)\nprint(\"Schema Type:\", schema_data.schema_type)\nprint(\"Service:\", schema_data.service)\nprint(\"Source:\", schema_data.source)\nprint(\"Context:\", schema_data.context)\nprint(\"JSON Schema:\", schema_data.json_schema)\nprint(\"Schema ID:\", schema_data.schema_id)\n</code></pre>"},{"location":"reference/libs/python/services/dtos/services-schema-handler/#dtos-provided","title":"DTOs Provided","text":"<p>The library provides the following DTOs for use in the <code>services-schema-handler</code> service:</p>"},{"location":"reference/libs/python/services/dtos/services-schema-handler/#schemadto-output","title":"<code>SchemaDTO</code> (output)","text":"<p>This DTO represents the main data structure exchanged by the service, including data.</p>"},{"location":"reference/libs/python/services/dtos/services-schema-handler/#contributions","title":"Contributions","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/python/services/setup/config-loader/","title":"config-loader","text":""},{"location":"reference/libs/python/services/setup/config-loader/#introduction","title":"Introduction","text":"<p><code>config-loader</code> is a Python library designed to simplify the process of loading configurations for a given service and context environment. This library provides the tools to fetch, register, and organize configurations in a structured manner.</p>"},{"location":"reference/libs/python/services/setup/config-loader/#installation","title":"Installation","text":"<p>You can install <code>config-loader</code> using <code>nx</code>:</p> <pre><code>npx nx add &lt;project&gt; --name python-services-setup-config-loader --local\n</code></pre>"},{"location":"reference/libs/python/services/setup/config-loader/#usage","title":"Usage","text":"<p>To use the library, you need to import the necessary components and follow the provided pattern for fetching and registering configurations.</p>"},{"location":"reference/libs/python/services/setup/config-loader/#initializing-mapping_config","title":"Initializing <code>mapping_config</code>","text":"<p><code>mapping_config</code> is a dictionary that will store configurations organized by context and ID. It needs to be initialized as an empty dictionary.</p> <pre><code>mapping_config: Dict[str, Dict[str, ConfigDTO]] = dict()\n</code></pre>"},{"location":"reference/libs/python/services/setup/config-loader/#fetching-configurations","title":"Fetching Configurations","text":"<p>Use the <code>fetch_configs</code> function to fetch configurations for a given service and context environment.</p> <pre><code>async def fetch_configs(service: str, context_env: str) -&gt; Dict[str, Dict[str, ConfigDTO]]:\n    # Fetch configurations for the specified service and context environment.\n    await ConfigLoader().fetch_configs_for_service(service_name=service, context_env=context_env)\n    return mapping_config\n</code></pre>"},{"location":"reference/libs/python/services/setup/config-loader/#the-configloader-class","title":"The <code>ConfigLoader</code> Class","text":"<p>The <code>ConfigLoader</code> class is responsible for loading configurations from the config handler API client.</p> <pre><code>class ConfigLoader:\n    def __init__(self) -&gt; None:\n        # Initialize the ConfigLoader.\n        # This class is used to load configurations from the config handler API client.\n        self.__config_handler_api_client = async_py_config_handler_client()\n        super().__init()\n\n    async def fetch_configs_for_service(self, service_name: str, context_env: str) -&gt; None:\n        # Fetch configurations for a specific service and context environment.\n        # This method fetches configurations and registers them using the `register_config` function.\n        configs = await self.__config_handler_api_client.list_all_configs_by_service_and_context(service_name, context_env)\n        for config in configs:\n            register_config(\n                config.context,\n                config.id,\n                config\n            )\n</code></pre>"},{"location":"reference/libs/python/services/setup/config-loader/#registering-configurations","title":"Registering Configurations","text":"<p>To register a configuration, use the <code>register_config</code> function. It registers configurations in the <code>mapping_config</code> dictionary.</p> <pre><code>def register_config(context: str, config_id: str, config: ConfigDTO) -&gt; None:\n    # Register a configuration in the mapping_config dictionary.\n    if context not in mapping_config:\n        mapping_config[context] = dict()\n    if config_id in mapping_config[context]:\n        raise Exception(f\"Duplicate config ID '{config_id}' for context '{context}'. Overwriting existing config.\")\n    mapping_config[context][config_id] = config\n</code></pre>"},{"location":"reference/libs/python/services/setup/config-loader/code_reference/config_loader/loader/","title":"Loader","text":""},{"location":"reference/libs/python/services/setup/config-loader/code_reference/config_loader/loader/#libs.python.services.setup.config-loader.config_loader.loader.ConfigLoader","title":"<code>ConfigLoader</code>","text":"Source code in <code>libs/python/services/setup/config-loader/config_loader/loader.py</code> <pre><code>class ConfigLoader:\n    def __init__(self) -&gt; None:\n        \"\"\"\n        Initialize the ConfigLoader.\n\n        Note:\n            This class is used to load configurations from the config handler API client.\n\n        \"\"\"\n        self.__config_handler_api_client = async_py_config_handler_client()\n        super().__init__()\n\n    async def fetch_configs_for_service(self, service_name: str, context_env: str) -&gt; None:\n        \"\"\"\n        Fetch configurations for a specific service and context environment.\n\n        Args:\n            service_name (str): The name of the service for which configurations are to be fetched.\n            context_env (str): The context environment for which configurations are to be fetched.\n\n        Returns:\n            None\n\n        Note:\n            This method fetches configurations and registers them using the `register_config` function.\n\n        \"\"\"\n        configs = await self.__config_handler_api_client.list_all_configs_by_service_and_context(service_name, context_env)\n        for config in configs:\n            register_config(\n                config.context,\n                config.id,\n                config\n            )\n</code></pre>"},{"location":"reference/libs/python/services/setup/config-loader/code_reference/config_loader/loader/#libs.python.services.setup.config-loader.config_loader.loader.ConfigLoader.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the ConfigLoader.</p> Note <p>This class is used to load configurations from the config handler API client.</p> Source code in <code>libs/python/services/setup/config-loader/config_loader/loader.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"\n    Initialize the ConfigLoader.\n\n    Note:\n        This class is used to load configurations from the config handler API client.\n\n    \"\"\"\n    self.__config_handler_api_client = async_py_config_handler_client()\n    super().__init__()\n</code></pre>"},{"location":"reference/libs/python/services/setup/config-loader/code_reference/config_loader/loader/#libs.python.services.setup.config-loader.config_loader.loader.ConfigLoader.fetch_configs_for_service","title":"<code>fetch_configs_for_service(service_name, context_env)</code>  <code>async</code>","text":"<p>Fetch configurations for a specific service and context environment.</p> <p>Parameters:</p> Name Type Description Default <code>service_name</code> <code>str</code> <p>The name of the service for which configurations are to be fetched.</p> required <code>context_env</code> <code>str</code> <p>The context environment for which configurations are to be fetched.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Note <p>This method fetches configurations and registers them using the <code>register_config</code> function.</p> Source code in <code>libs/python/services/setup/config-loader/config_loader/loader.py</code> <pre><code>async def fetch_configs_for_service(self, service_name: str, context_env: str) -&gt; None:\n    \"\"\"\n    Fetch configurations for a specific service and context environment.\n\n    Args:\n        service_name (str): The name of the service for which configurations are to be fetched.\n        context_env (str): The context environment for which configurations are to be fetched.\n\n    Returns:\n        None\n\n    Note:\n        This method fetches configurations and registers them using the `register_config` function.\n\n    \"\"\"\n    configs = await self.__config_handler_api_client.list_all_configs_by_service_and_context(service_name, context_env)\n    for config in configs:\n        register_config(\n            config.context,\n            config.id,\n            config\n        )\n</code></pre>"},{"location":"reference/libs/python/services/setup/config-loader/code_reference/config_loader/loader/#libs.python.services.setup.config-loader.config_loader.loader.fetch_configs","title":"<code>fetch_configs(service, context_env)</code>  <code>async</code>","text":"<p>Fetch configurations for a given service and context environment.</p> <p>Parameters:</p> Name Type Description Default <code>service</code> <code>str</code> <p>The name of the service for which configurations are to be fetched.</p> required <code>context_env</code> <code>str</code> <p>The context environment for which configurations are to be fetched.</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, ConfigDTO]]</code> <p>Dict[str, Dict[str, ConfigDTO]]: A dictionary containing configurations organized by context and ID.</p> Note <p>The <code>mapping_config</code> dictionary will be populated by this function.</p> Source code in <code>libs/python/services/setup/config-loader/config_loader/loader.py</code> <pre><code>async def fetch_configs(service: str, context_env: str) -&gt; Dict[str, Dict[str, ConfigDTO]]:\n    \"\"\"\n    Fetch configurations for a given service and context environment.\n\n    Args:\n        service (str): The name of the service for which configurations are to be fetched.\n        context_env (str): The context environment for which configurations are to be fetched.\n\n    Returns:\n        Dict[str, Dict[str, ConfigDTO]]: A dictionary containing configurations organized by context and ID.\n\n    Note:\n        The `mapping_config` dictionary will be populated by this function.\n\n    \"\"\"\n    await ConfigLoader().fetch_configs_for_service(service_name=service, context_env=context_env)\n    return mapping_config\n</code></pre>"},{"location":"reference/libs/python/services/setup/config-loader/code_reference/config_loader/loader/#libs.python.services.setup.config-loader.config_loader.loader.register_config","title":"<code>register_config(context, config_id, config)</code>","text":"<p>Register a configuration in the mapping_config dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>str</code> <p>The context for which the configuration is being registered.</p> required <code>config_id</code> <code>str</code> <p>The ID of the configuration.</p> required <code>config</code> <code>ConfigDTO</code> <p>The configuration object to be registered.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If a configuration with the same ID already exists</p> Source code in <code>libs/python/services/setup/config-loader/config_loader/loader.py</code> <pre><code>def register_config(context: str, config_id: str, config: ConfigDTO) -&gt; None:\n    \"\"\"\n    Register a configuration in the mapping_config dictionary.\n\n    Args:\n        context (str): The context for which the configuration is being registered.\n        config_id (str): The ID of the configuration.\n        config (ConfigDTO): The configuration object to be registered.\n\n    Returns:\n        None\n\n    Raises:\n        Exception: If a configuration with the same ID already exists\n    \"\"\"\n    if context not in mapping_config:\n        mapping_config[context] = dict()\n    if config_id in mapping_config[context]:\n        raise Exception(f\"Duplicate config ID '{config_id}' for context '{context}'. Overwriting existing config.\")\n    mapping_config[context][config_id] = config\n</code></pre>"},{"location":"reference/libs/python/shared/py-dotenv/","title":"py-dotenv","text":"<p><code>py-dotenv</code> is a Python library for loading environment variables from .env files. It provides a convenient way to manage and access environment-specific configuration settings in your Python applications.</p>"},{"location":"reference/libs/python/shared/py-dotenv/#installation","title":"Installation","text":"<p>You can install <code>py-dotenv</code> using <code>nx</code>:</p> <pre><code>npx nx add &lt;project&gt; --name python-shared-py-dotenv --local\n</code></pre>"},{"location":"reference/libs/python/shared/py-dotenv/#usage","title":"Usage","text":""},{"location":"reference/libs/python/shared/py-dotenv/#importing-the-library","title":"Importing the Library","text":"<pre><code>from dotenv import load_dotenv\n</code></pre>"},{"location":"reference/libs/python/shared/py-dotenv/#class-dotenvloader","title":"Class: DotEnvLoader","text":"<p>DotEnvLoader is a utility class provided by py-dotenv to manage the loading of environment variables from .env files.</p> <p>Initialization To begin using DotEnvLoader, you can create an instance by specifying the environment and an optional path to the directory containing .env files.</p> <p>Retrieving Environment Variables You can retrieve the value of an environment variable by its key using the get_variable method.</p> <pre><code>loader_vars = DotEnvLoader(environment=\"development\", path=Path(\"/path/to/dotenv\"))\n\nenv_value = loader.get_variable(\"SECRET_KEY\")\n</code></pre>"},{"location":"reference/libs/python/shared/py-dotenv/#configuration","title":"Configuration","text":"<p>The setup_logging function is used to configure the logger. It takes the following parameters:</p> <ul> <li><code>module_name</code> (str): The name of the module or application that is using the logger. <code>propagate</code> (bool): Whether to propagate the logging to the parent logger. <code>log_level</code> (str): The log level to set, which can be one of \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", or \"CRITICAL\". The default is \"INFO\".</li> </ul> <p>By default, <code>py-log</code> configures a JSON logger that writes log entries to the console. You can customize the log format and destination by modifying the setup_logging function to suit your specific needs.</p>"},{"location":"reference/libs/python/shared/py-dotenv/#example-json-log-output","title":"Example JSON Log Output","text":"<pre><code>{\"levelname\": \"INFO\", \"filename\": \"example.py\", \"message\": \"This is an info message\"}\n{\"levelname\": \"ERROR\", \"filename\": \"example.py\", \"message\": \"An error occurred\", \"exc_info\": \"Traceback (most recent call last):\\n  File \\\"example.py\\\", line 11, in &lt;module&gt;\\n    result = 10 / 0\\nZeroDivisionError: division by zero\"}\n{\"levelname\": \"WARNING\", \"filename\": \"example.py\", \"message\": \"This is a warning message\"}\n</code></pre>"},{"location":"reference/libs/python/shared/py-dotenv/code_reference/pydotenv/loader/","title":"Loader","text":""},{"location":"reference/libs/python/shared/py-dotenv/code_reference/pydotenv/loader/#libs.python.shared.py-dotenv.pydotenv.loader.DotEnvLoader","title":"<code>DotEnvLoader</code>","text":"<p>A utility class for loading environment variables from .env files.</p> <p>Parameters:</p> Name Type Description Default <code>environment</code> <code>str</code> <p>The environment for which to load environment variables.</p> required <code>path</code> <code>Path</code> <p>The path to the directory containing .env files. If not provided, assumes the current directory.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>_environment</code> <code>str</code> <p>The environment for which environment variables are loaded.</p> <code>_path</code> <code>Path</code> <p>The path to the directory containing .env files.</p> Example <p>loader = DotEnvLoader(environment=\"development\", path=Path(\"/path/to/dotenv\")) loader.load() value = loader.get_variable(\"SECRET_KEY\")</p> Source code in <code>libs/python/shared/py-dotenv/pydotenv/loader.py</code> <pre><code>class DotEnvLoader:\n    \"\"\"\n    A utility class for loading environment variables from .env files.\n\n    Args:\n        environment (str): The environment for which to load environment variables.\n        path (Path, optional): The path to the directory containing .env files. If not provided, assumes the current directory.\n\n    Attributes:\n        _environment (str): The environment for which environment variables are loaded.\n        _path (Path): The path to the directory containing .env files.\n\n    Methods:\n        __init__(environment, path=None)\n            Initializes a new DotEnvLoader instance.\n\n        load()\n            Loads environment variables from the corresponding .env file into the current environment.\n\n        get_variable(key)\n            Retrieves the value of an environment variable by its key.\n\n    Example:\n        loader = DotEnvLoader(environment=\"development\", path=Path(\"/path/to/dotenv\"))\n        loader.load()\n        value = loader.get_variable(\"SECRET_KEY\")\n    \"\"\"\n\n    def __init__(self, environment: str, path: Path = None) -&gt; None:\n        \"\"\"\n        Initialize a new DotEnvLoader instance.\n\n        Args:\n            environment (str): The environment for which to load environment variables.\n            path (Path, optional): The path to the directory containing .env files. If not provided, assumes the current directory.\n        \"\"\"\n        self._environment = environment\n        self._path = path\n        self.load()\n\n    def _get_env(self) -&gt; Path:\n        \"\"\"\n        Get the path to the .env file corresponding to the specified environment.\n\n        Returns:\n            Path: The path to the .env file.\n        \"\"\"\n        if self._path is not None:\n            return self._path.joinpath(\".env.{env}\".format(env=self._environment))\n        return Path(\".env.{env}\".format(env=self._environment))\n\n    def load(self) -&gt; None:\n        \"\"\"\n        Load environment variables from the .env file into the current environment.\n        \"\"\"\n        path = self._get_env()\n        load_dotenv(path)\n\n    def get_variable(self, key) -&gt; str:\n        \"\"\"\n        Retrieve the value of an environment variable by its key.\n\n        Args:\n            key (str): The key of the environment variable to retrieve.\n\n        Returns:\n            str: The value of the environment variable, or an empty string if not found.\n        \"\"\"\n        return os.getenv(key, \"\")\n</code></pre>"},{"location":"reference/libs/python/shared/py-dotenv/code_reference/pydotenv/loader/#libs.python.shared.py-dotenv.pydotenv.loader.DotEnvLoader.__init__","title":"<code>__init__(environment, path=None)</code>","text":"<p>Initialize a new DotEnvLoader instance.</p> <p>Parameters:</p> Name Type Description Default <code>environment</code> <code>str</code> <p>The environment for which to load environment variables.</p> required <code>path</code> <code>Path</code> <p>The path to the directory containing .env files. If not provided, assumes the current directory.</p> <code>None</code> Source code in <code>libs/python/shared/py-dotenv/pydotenv/loader.py</code> <pre><code>def __init__(self, environment: str, path: Path = None) -&gt; None:\n    \"\"\"\n    Initialize a new DotEnvLoader instance.\n\n    Args:\n        environment (str): The environment for which to load environment variables.\n        path (Path, optional): The path to the directory containing .env files. If not provided, assumes the current directory.\n    \"\"\"\n    self._environment = environment\n    self._path = path\n    self.load()\n</code></pre>"},{"location":"reference/libs/python/shared/py-dotenv/code_reference/pydotenv/loader/#libs.python.shared.py-dotenv.pydotenv.loader.DotEnvLoader.load","title":"<code>load()</code>","text":"<p>Load environment variables from the .env file into the current environment.</p> Source code in <code>libs/python/shared/py-dotenv/pydotenv/loader.py</code> <pre><code>def load(self) -&gt; None:\n    \"\"\"\n    Load environment variables from the .env file into the current environment.\n    \"\"\"\n    path = self._get_env()\n    load_dotenv(path)\n</code></pre>"},{"location":"reference/libs/python/shared/py-dotenv/code_reference/pydotenv/loader/#libs.python.shared.py-dotenv.pydotenv.loader.DotEnvLoader.get_variable","title":"<code>get_variable(key)</code>","text":"<p>Retrieve the value of an environment variable by its key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the environment variable to retrieve.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The value of the environment variable, or an empty string if not found.</p> Source code in <code>libs/python/shared/py-dotenv/pydotenv/loader.py</code> <pre><code>def get_variable(self, key) -&gt; str:\n    \"\"\"\n    Retrieve the value of an environment variable by its key.\n\n    Args:\n        key (str): The key of the environment variable to retrieve.\n\n    Returns:\n        str: The value of the environment variable, or an empty string if not found.\n    \"\"\"\n    return os.getenv(key, \"\")\n</code></pre>"},{"location":"reference/libs/python/shared/py-log/","title":"py-log","text":"<p><code>py-log</code> is a Python library that provides a simple way to set up logging with a JSON format. It is designed to be easy to use and configure, allowing you to quickly integrate structured logging into your Python applications.</p>"},{"location":"reference/libs/python/shared/py-log/#installation","title":"Installation","text":"<p>You can install <code>py-log</code> using <code>nx</code>:</p> <pre><code>npx nx add &lt;project&gt; --name python-shared-py-log --local\n</code></pre>"},{"location":"reference/libs/python/shared/py-log/#usage","title":"Usage","text":""},{"location":"reference/libs/python/shared/py-log/#importing-the-library","title":"Importing the Library","text":"<pre><code>from pylog.log import setup_logging\n\n# Set up logging\nlogger = setup_logging(module_name=\"your_module_name\")\n\n# Log a message\nlogger.info(\"This is an info message\")\n\n# Log an error\ntry:\n    # some code that may raise an exception\n    result = 10 / 0\nexcept ZeroDivisionError as e:\n    logger.error(\"An error occurred\", exc_info=True)\n\n# Change the log level (optional)\nlogger.setLevel(logging.WARNING)\nlogger.warning(\"This is a warning message\")\n\n# For more advanced configuration, you can also set up custom logging handlers and formatters.\n</code></pre>"},{"location":"reference/libs/python/shared/py-log/#configuration","title":"Configuration","text":"<p>The setup_logging function is used to configure the logger. It takes the following parameters:</p> <ul> <li><code>module_name</code> (str): The name of the module or application that is using the logger. <code>propagate</code> (bool): Whether to propagate the logging to the parent logger. <code>log_level</code> (str): The log level to set, which can be one of \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", or \"CRITICAL\". The default is \"INFO\".</li> </ul> <p>By default, <code>py-log</code> configures a JSON logger that writes log entries to the console. You can customize the log format and destination by modifying the setup_logging function to suit your specific needs.</p>"},{"location":"reference/libs/python/shared/py-log/#example-json-log-output","title":"Example JSON Log Output","text":"<pre><code>{\"levelname\": \"INFO\", \"filename\": \"example.py\", \"message\": \"This is an info message\"}\n{\"levelname\": \"ERROR\", \"filename\": \"example.py\", \"message\": \"An error occurred\", \"exc_info\": \"Traceback (most recent call last):\\n  File \\\"example.py\\\", line 11, in &lt;module&gt;\\n    result = 10 / 0\\nZeroDivisionError: division by zero\"}\n{\"levelname\": \"WARNING\", \"filename\": \"example.py\", \"message\": \"This is a warning message\"}\n</code></pre>"},{"location":"reference/libs/python/shared/py-log/code_reference/pylog/log/","title":"Log","text":"<p>Logging module.</p>"},{"location":"reference/libs/python/shared/py-log/code_reference/pylog/log/#libs.python.shared.py-log.pylog.log.setup_logging","title":"<code>setup_logging(module_name, propagate=False, log_level=os.getenv('LOG_LEVEL', 'INFO').upper())</code>","text":"<p>Set up logging using JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>module_name</code> <code>str</code> <p>The module name.</p> required <code>propagate</code> <code>bool</code> <p>Whether to propagate the logging to the parent logger.</p> <code>False</code> <code>log_level</code> <code>str</code> <p>The log level.</p> <code>upper()</code> <p>Returns:</p> Type Description <code>Logger</code> <p>The logger.</p> Source code in <code>libs/python/shared/py-log/pylog/log.py</code> <pre><code>def setup_logging(\n    module_name: str,\n    propagate: bool = False,\n    log_level: str = os.getenv(\"LOG_LEVEL\", \"INFO\").upper()\n) -&gt; logging.Logger:\n    \"\"\"\n    Set up logging using JSON format.\n\n    Args:\n        module_name (str): The module name.\n        propagate (bool): Whether to propagate the logging to the parent logger.\n        log_level (str): The log level.\n\n    Returns:\n        The logger.\n    \"\"\"\n    log_handler = logging.StreamHandler()\n    formatter = jsonlogger.JsonFormatter(\"%(levelname)s %(filename)s %(message)s\")\n    log_handler.setFormatter(formatter)\n\n    logger = logging.getLogger(module_name)\n    logger.addHandler(log_handler)\n    logger.propagate = propagate\n    logger.setLevel(logging.getLevelName(log_level))\n    return logger\n</code></pre>"},{"location":"reference/libs/python/shared/py-request/","title":"py-request","text":"<p><code>py-request</code> is a Python library that provides an asynchronous HTTP client with rate limiting. It allows you to make HTTP requests while ensuring that you do not exceed a maximum number of requests within a specified time period.</p>"},{"location":"reference/libs/python/shared/py-request/#installation","title":"Installation","text":"<p>You can install <code>py-dotenv</code> using <code>nx</code>:</p> <pre><code>npx nx add &lt;project&gt; --name python-shared-py-request --local\n</code></pre>"},{"location":"reference/libs/python/shared/py-request/#usage","title":"Usage","text":"<p>To use <code>py-request</code>, you first need to import the <code>RateLimitedAsyncHttpClient</code> class from the library. Here's an example of how to use it:</p> <pre><code>from pyrequest.factory import RateLimitedAsyncHttpClient\n\n# Initialize the client with your base URL, maximum calls, and period\nbase_url = \"http://example.com\"\nmax_calls = 2\nperiod = 1\nclient = RateLimitedAsyncHttpClient(base_url, max_calls, period)\n\n# Make an asynchronous HTTP request\nresponse = await client.make_request(\"GET\", \"/api/endpoint\")\n\n# The response is a dictionary representing the JSON response from the HTTP request\nprint(response)\n</code></pre>"},{"location":"reference/libs/python/shared/py-request/code_reference/pyrequest/factory/","title":"Factory","text":""},{"location":"reference/libs/python/shared/py-request/code_reference/pyrequest/factory/#libs.python.shared.py-request.pyrequest.factory.RateLimitedAsyncHttpClient","title":"<code>RateLimitedAsyncHttpClient</code>","text":"<p>An asynchronous HTTP client with rate limiting.</p> <p>This class allows you to make HTTP requests with rate limiting to prevent exceeding a maximum number of requests within a specified time period.</p> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>str</code> <p>The base URL for the HTTP requests.</p> required <code>max_calls</code> <code>int</code> <p>The maximum number of allowed calls within the specified period.</p> required <code>period</code> <code>int</code> <p>The time period (in seconds) during which the maximum calls are allowed.</p> required <p>Attributes:</p> Name Type Description <code>base_url</code> <code>str</code> <p>The base URL for the HTTP requests.</p> <code>max_calls</code> <code>int</code> <p>The maximum number of allowed calls within the specified period.</p> <code>period</code> <code>int</code> <p>The time period (in seconds) during which the maximum calls are allowed.</p> <code>semaphore</code> <code>Semaphore</code> <p>An asyncio semaphore used for rate limiting.</p> Source code in <code>libs/python/shared/py-request/pyrequest/factory.py</code> <pre><code>class RateLimitedAsyncHttpClient:\n    \"\"\"\n    An asynchronous HTTP client with rate limiting.\n\n    This class allows you to make HTTP requests with rate limiting to prevent\n    exceeding a maximum number of requests within a specified time period.\n\n    Args:\n        base_url (str): The base URL for the HTTP requests.\n        max_calls (int): The maximum number of allowed calls within the specified period.\n        period (int): The time period (in seconds) during which the maximum calls are allowed.\n\n    Attributes:\n        base_url (str): The base URL for the HTTP requests.\n        max_calls (int): The maximum number of allowed calls within the specified period.\n        period (int): The time period (in seconds) during which the maximum calls are allowed.\n        semaphore (asyncio.Semaphore): An asyncio semaphore used for rate limiting.\n\n    \"\"\"\n    def __init__(self, base_url: str, max_calls: int, period: int) -&gt; None:\n        \"\"\"\n        Initialize the RateLimitedAsyncHttpClient with the specified parameters.\n\n        Args:\n            base_url (str): The base URL for the HTTP requests.\n            max_calls (int): The maximum number of allowed calls within the specified period.\n            period (int): The time period (in seconds) during which the maximum calls are allowed.\n        \"\"\"\n        self.base_url = base_url\n        self.max_calls = max_calls\n        self.period = period\n        self.semaphore = asyncio.Semaphore(max_calls)\n\n    async def make_request(self, method: str, endpoint: str, data: Dict[str, any] = None, params: Dict[str, any] = None) -&gt; Dict[str, any]:\n        \"\"\"\n        Make an asynchronous HTTP request with rate limiting.\n\n        This method sends an HTTP request using the specified method, endpoint, data, and parameters.\n        Rate limiting is enforced to prevent exceeding the maximum number of calls within the specified period.\n\n        Args:\n            method (str): The HTTP request method (e.g., 'GET', 'POST').\n            endpoint (str): The endpoint to request, relative to the base URL.\n            data (dict, optional): A dictionary of data to send in the request body (as JSON).\n            params (dict, optional): A dictionary of query parameters to include in the request.\n\n        Returns:\n            dict: A dictionary representing the JSON response from the HTTP request.\n\n        Raises:\n            httpx.HTTPStatusError: If the HTTP request results in an error response.\n\n        \"\"\"\n        url = self.base_url + endpoint\n        async with self.semaphore:\n            async with httpx.AsyncClient() as client:\n                response = await client.request(method, url, json=data, params=params)\n                response.raise_for_status()\n                return response.json()\n</code></pre>"},{"location":"reference/libs/python/shared/py-request/code_reference/pyrequest/factory/#libs.python.shared.py-request.pyrequest.factory.RateLimitedAsyncHttpClient.__init__","title":"<code>__init__(base_url, max_calls, period)</code>","text":"<p>Initialize the RateLimitedAsyncHttpClient with the specified parameters.</p> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>str</code> <p>The base URL for the HTTP requests.</p> required <code>max_calls</code> <code>int</code> <p>The maximum number of allowed calls within the specified period.</p> required <code>period</code> <code>int</code> <p>The time period (in seconds) during which the maximum calls are allowed.</p> required Source code in <code>libs/python/shared/py-request/pyrequest/factory.py</code> <pre><code>def __init__(self, base_url: str, max_calls: int, period: int) -&gt; None:\n    \"\"\"\n    Initialize the RateLimitedAsyncHttpClient with the specified parameters.\n\n    Args:\n        base_url (str): The base URL for the HTTP requests.\n        max_calls (int): The maximum number of allowed calls within the specified period.\n        period (int): The time period (in seconds) during which the maximum calls are allowed.\n    \"\"\"\n    self.base_url = base_url\n    self.max_calls = max_calls\n    self.period = period\n    self.semaphore = asyncio.Semaphore(max_calls)\n</code></pre>"},{"location":"reference/libs/python/shared/py-request/code_reference/pyrequest/factory/#libs.python.shared.py-request.pyrequest.factory.RateLimitedAsyncHttpClient.make_request","title":"<code>make_request(method, endpoint, data=None, params=None)</code>  <code>async</code>","text":"<p>Make an asynchronous HTTP request with rate limiting.</p> <p>This method sends an HTTP request using the specified method, endpoint, data, and parameters. Rate limiting is enforced to prevent exceeding the maximum number of calls within the specified period.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>The HTTP request method (e.g., 'GET', 'POST').</p> required <code>endpoint</code> <code>str</code> <p>The endpoint to request, relative to the base URL.</p> required <code>data</code> <code>dict</code> <p>A dictionary of data to send in the request body (as JSON).</p> <code>None</code> <code>params</code> <code>dict</code> <p>A dictionary of query parameters to include in the request.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>Dict[str, any]</code> <p>A dictionary representing the JSON response from the HTTP request.</p> <p>Raises:</p> Type Description <code>HTTPStatusError</code> <p>If the HTTP request results in an error response.</p> Source code in <code>libs/python/shared/py-request/pyrequest/factory.py</code> <pre><code>async def make_request(self, method: str, endpoint: str, data: Dict[str, any] = None, params: Dict[str, any] = None) -&gt; Dict[str, any]:\n    \"\"\"\n    Make an asynchronous HTTP request with rate limiting.\n\n    This method sends an HTTP request using the specified method, endpoint, data, and parameters.\n    Rate limiting is enforced to prevent exceeding the maximum number of calls within the specified period.\n\n    Args:\n        method (str): The HTTP request method (e.g., 'GET', 'POST').\n        endpoint (str): The endpoint to request, relative to the base URL.\n        data (dict, optional): A dictionary of data to send in the request body (as JSON).\n        params (dict, optional): A dictionary of query parameters to include in the request.\n\n    Returns:\n        dict: A dictionary representing the JSON response from the HTTP request.\n\n    Raises:\n        httpx.HTTPStatusError: If the HTTP request results in an error response.\n\n    \"\"\"\n    url = self.base_url + endpoint\n    async with self.semaphore:\n        async with httpx.AsyncClient() as client:\n            response = await client.request(method, url, json=data, params=params)\n            response.raise_for_status()\n            return response.json()\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/","title":"py-sd","text":"<p><code>py-sd</code> is a Python library for service discovery and environment variable management. It provides a convenient way to access service endpoints and environment variables needed for a distributed system.</p>"},{"location":"reference/libs/python/shared/py-sd/#installation","title":"Installation","text":"<p>You can install <code>py-sd</code> using <code>nx</code>:</p> <pre><code>npx nx add &lt;project&gt; --name python-shared-py-sd --local\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/#usage","title":"Usage","text":""},{"location":"reference/libs/python/shared/py-sd/#importing-the-library","title":"Importing the Library","text":"<pre><code>from pysd.service_discovery import new_from_env\n\nsd = new_from_env()\n\n# Get the RabbitMQ endpoint\nrabbitmq_endpoint = sd.rabbitmq_endpoint()\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/#handling-exceptions","title":"Handling Exceptions","text":"<p><code>py-sd</code> provides two custom exceptions:</p> <ul> <li><code>UnrecoverableError</code>: Raised when environment variables are not set.</li> <li><code>ServiceUnavailableError</code>: Raised when a required environment variable is not set. You can handle these exceptions in your code to provide appropriate error handling.</li> </ul>"},{"location":"reference/libs/python/shared/py-sd/#examples","title":"Examples","text":"<p>Here are some examples of how to use the py-sd library:</p> <pre><code>import os\nfrom pysd import ServiceDiscovery, UnrecoverableError, ServiceUnavailableError\n\n# Create a ServiceDiscovery instance using environment variables\nservice_discovery = ServiceDiscovery(os.environ)\n\ntry:\n    # Get the RabbitMQ endpoint\n    rabbitmq_endpoint = service_discovery.rabbitmq_endpoint()\n    print(f\"RabbitMQ endpoint: {rabbitmq_endpoint}\")\n\n    # Get the Minio access key\n    minio_access_key = service_discovery.minio_access_key()\n    print(f\"Minio access key: {minio_access_key}\")\n\nexcept UnrecoverableError as e:\n    print(f\"Unrecoverable error: {str(e)}\")\n\nexcept ServiceUnavailableError as e:\n    print(f\"Service unavailable: {str(e)}\")\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/code_reference/pysd/service_discovery/","title":"Service discovery","text":""},{"location":"reference/libs/python/shared/py-sd/code_reference/pysd/service_discovery/#libs.python.shared.py-sd.pysd.service_discovery.UnrecoverableError","title":"<code>UnrecoverableError</code>","text":"<p>             Bases: <code>Exception</code></p> Source code in <code>libs/python/shared/py-sd/pysd/service_discovery.py</code> <pre><code>class UnrecoverableError(Exception):\n    def __init__(self, *args: object) -&gt; None:\n        \"\"\"\n        Initializes an UnrecoverableError.\n\n        Args:\n            args (object): Any additional arguments for the exception.\n        \"\"\"\n        super().__init__(*args)\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/code_reference/pysd/service_discovery/#libs.python.shared.py-sd.pysd.service_discovery.UnrecoverableError.__init__","title":"<code>__init__(*args)</code>","text":"<p>Initializes an UnrecoverableError.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>object</code> <p>Any additional arguments for the exception.</p> <code>()</code> Source code in <code>libs/python/shared/py-sd/pysd/service_discovery.py</code> <pre><code>def __init__(self, *args: object) -&gt; None:\n    \"\"\"\n    Initializes an UnrecoverableError.\n\n    Args:\n        args (object): Any additional arguments for the exception.\n    \"\"\"\n    super().__init__(*args)\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/code_reference/pysd/service_discovery/#libs.python.shared.py-sd.pysd.service_discovery.ServiceUnavailableError","title":"<code>ServiceUnavailableError</code>","text":"<p>             Bases: <code>Exception</code></p> Source code in <code>libs/python/shared/py-sd/pysd/service_discovery.py</code> <pre><code>class ServiceUnavailableError(Exception):\n    def __init__(self, *args: object) -&gt; None:\n        \"\"\"\n        Initializes a ServiceUnavailableError.\n\n        Args:\n            args (object): Any additional arguments for the exception.\n        \"\"\"\n        super().__init__(*args)\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/code_reference/pysd/service_discovery/#libs.python.shared.py-sd.pysd.service_discovery.ServiceUnavailableError.__init__","title":"<code>__init__(*args)</code>","text":"<p>Initializes a ServiceUnavailableError.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>object</code> <p>Any additional arguments for the exception.</p> <code>()</code> Source code in <code>libs/python/shared/py-sd/pysd/service_discovery.py</code> <pre><code>def __init__(self, *args: object) -&gt; None:\n    \"\"\"\n    Initializes a ServiceUnavailableError.\n\n    Args:\n        args (object): Any additional arguments for the exception.\n    \"\"\"\n    super().__init__(*args)\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/code_reference/pysd/service_discovery/#libs.python.shared.py-sd.pysd.service_discovery.ServiceDiscovery","title":"<code>ServiceDiscovery</code>","text":"Source code in <code>libs/python/shared/py-sd/pysd/service_discovery.py</code> <pre><code>class ServiceDiscovery:\n    def __init__(self, envvars):\n        \"\"\"\n        Initializes a ServiceDiscovery instance.\n\n        Args:\n            envvars (dict): A dictionary of environment variables.\n\n        Raises:\n            UnrecoverableError: If environment variables are not set.\n        \"\"\"\n        if envvars is None:\n            raise UnrecoverableError('Environment variables not set')\n        self._vars = envvars\n        self._service_vars = ServiceVars()\n\n    def _get_endpoint(self, var_name: str, service_name: str, protocol: str = \"http\") -&gt; str:\n        \"\"\"\n        Gets the endpoint for a service.\n\n        Args:\n            var_name (str): The name of the environment variable containing the service endpoint.\n            service_name (str): The name of the service.\n            protocol (str): The protocol to use (default is \"http\").\n\n        Returns:\n            str: The service endpoint.\n\n        Raises:\n            ServiceUnavailableError: If the environment variable is not set.\n        \"\"\"\n        if var_name not in self._vars:\n            raise ServiceUnavailableError(f'Environment variable {var_name} not set')\n        tcp_addr = self._vars[var_name]\n        gt_host = self._get_gateway_host(service_name)\n        return tcp_addr.replace(\"tcp\", protocol).replace(\"gateway_host\", gt_host)\n\n    def _get_gateway_host(self, service_name: str) -&gt; str:\n        \"\"\"\n        Gets the gateway host for a service.\n\n        Args:\n            service_name (str): The name of the service.\n\n        Returns:\n            str: The gateway host.\n\n        Notes:\n            If the 'GATEWAY_ENVIRONMENT' environment variable is not set, 'localhost' is returned.\n        \"\"\"\n        if os.getenv('GATEWAY_ENVIRONMENT') is None:\n            return 'localhost'\n        return os.getenv(f'{service_name}_GATEWAY_HOST')\n\n    def rabbitmq_endpoint(self) -&gt; str:\n        \"\"\"\n        Gets the RabbitMQ endpoint.\n\n        Returns:\n            str: The RabbitMQ endpoint in 'amqp' protocol.\n        \"\"\"\n        service_name = self._service_vars.rabbitmq\n        return self._get_endpoint(\"RABBITMQ_PORT_6572_TCP\", service_name, protocol=\"amqp\")\n\n    def services_rabbitmq_exchange(self) -&gt; str:\n        \"\"\"\n        Gets the services RabbitMQ exchange.\n\n        Returns:\n            str: The name of the services RabbitMQ exchange.\n        \"\"\"\n        return self._service_vars.services_rabbitmq_exchange\n\n    def services_config_handler_endpoint(self):\n        \"\"\"\n        Gets the services config handler endpoint.\n\n        Returns:\n            str: The services config handler endpoint.\n        \"\"\"\n        service_name = self._service_vars.configHandler\n        endpoint = self._get_endpoint(\"CONFIG_HANDLER_PORT_8000_TCP\", service_name)\n        if \"localhost\" in endpoint:\n            endpoint = endpoint.replace(\"8000\", \"8002\")\n        return endpoint\n\n    def services_schemas_handler_endpoint(self):\n        \"\"\"\n        Gets the services schemas handler endpoint.\n\n        Returns:\n            str: The services schemas handler endpoint.\n        \"\"\"\n        service_name = self._service_vars.schemasHandler\n        endpoint = self._get_endpoint(\"SCHEMA_HANDLER_PORT_8000_TCP\", service_name)\n        if \"localhost\" in endpoint:\n            endpoint = endpoint.replace(\"8000\", \"8003\")\n        return endpoint\n\n    def services_file_catalog_handler_endpoint(self):\n        \"\"\"\n        Gets the services file catalog handler endpoint.\n\n        Returns:\n            str: The services file catalog handler endpoint.\n        \"\"\"\n        service_name = self._service_vars.fileCatalogHandler\n        endpoint = self._get_endpoint(\"FILE_CATALOG_HANDLER_PORT_8000_TCP\", service_name)\n        if \"localhost\" in endpoint:\n            endpoint = endpoint.replace(\"8000\", \"8006\")\n        return endpoint\n\n    def minio_endpoint(self):\n        \"\"\"\n        Gets the Minio endpoint.\n\n        Returns:\n            str: The Minio endpoint.\n        \"\"\"\n        service_name = self._service_vars.minio\n        endpoint = self._get_endpoint(\"MINIO_PORT_9000_TCP\", service_name)\n        return endpoint\n\n    def minio_access_key(self):\n        \"\"\"\n        Gets the Minio access key.\n\n        Returns:\n            str: The Minio access key.\n        \"\"\"\n        return os.getenv(\"MINIO_ACCESS_KEY\")\n\n    def minio_secret_key(self):\n        \"\"\"\n        Gets the Minio secret key.\n\n        Returns:\n            str: The Minio secret key.\n        \"\"\"\n        return os.getenv(\"MINIO_SECRET_KEY\")\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/code_reference/pysd/service_discovery/#libs.python.shared.py-sd.pysd.service_discovery.ServiceDiscovery.__init__","title":"<code>__init__(envvars)</code>","text":"<p>Initializes a ServiceDiscovery instance.</p> <p>Parameters:</p> Name Type Description Default <code>envvars</code> <code>dict</code> <p>A dictionary of environment variables.</p> required <p>Raises:</p> Type Description <code>UnrecoverableError</code> <p>If environment variables are not set.</p> Source code in <code>libs/python/shared/py-sd/pysd/service_discovery.py</code> <pre><code>def __init__(self, envvars):\n    \"\"\"\n    Initializes a ServiceDiscovery instance.\n\n    Args:\n        envvars (dict): A dictionary of environment variables.\n\n    Raises:\n        UnrecoverableError: If environment variables are not set.\n    \"\"\"\n    if envvars is None:\n        raise UnrecoverableError('Environment variables not set')\n    self._vars = envvars\n    self._service_vars = ServiceVars()\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/code_reference/pysd/service_discovery/#libs.python.shared.py-sd.pysd.service_discovery.ServiceDiscovery.rabbitmq_endpoint","title":"<code>rabbitmq_endpoint()</code>","text":"<p>Gets the RabbitMQ endpoint.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The RabbitMQ endpoint in 'amqp' protocol.</p> Source code in <code>libs/python/shared/py-sd/pysd/service_discovery.py</code> <pre><code>def rabbitmq_endpoint(self) -&gt; str:\n    \"\"\"\n    Gets the RabbitMQ endpoint.\n\n    Returns:\n        str: The RabbitMQ endpoint in 'amqp' protocol.\n    \"\"\"\n    service_name = self._service_vars.rabbitmq\n    return self._get_endpoint(\"RABBITMQ_PORT_6572_TCP\", service_name, protocol=\"amqp\")\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/code_reference/pysd/service_discovery/#libs.python.shared.py-sd.pysd.service_discovery.ServiceDiscovery.services_rabbitmq_exchange","title":"<code>services_rabbitmq_exchange()</code>","text":"<p>Gets the services RabbitMQ exchange.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The name of the services RabbitMQ exchange.</p> Source code in <code>libs/python/shared/py-sd/pysd/service_discovery.py</code> <pre><code>def services_rabbitmq_exchange(self) -&gt; str:\n    \"\"\"\n    Gets the services RabbitMQ exchange.\n\n    Returns:\n        str: The name of the services RabbitMQ exchange.\n    \"\"\"\n    return self._service_vars.services_rabbitmq_exchange\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/code_reference/pysd/service_discovery/#libs.python.shared.py-sd.pysd.service_discovery.ServiceDiscovery.services_config_handler_endpoint","title":"<code>services_config_handler_endpoint()</code>","text":"<p>Gets the services config handler endpoint.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The services config handler endpoint.</p> Source code in <code>libs/python/shared/py-sd/pysd/service_discovery.py</code> <pre><code>def services_config_handler_endpoint(self):\n    \"\"\"\n    Gets the services config handler endpoint.\n\n    Returns:\n        str: The services config handler endpoint.\n    \"\"\"\n    service_name = self._service_vars.configHandler\n    endpoint = self._get_endpoint(\"CONFIG_HANDLER_PORT_8000_TCP\", service_name)\n    if \"localhost\" in endpoint:\n        endpoint = endpoint.replace(\"8000\", \"8002\")\n    return endpoint\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/code_reference/pysd/service_discovery/#libs.python.shared.py-sd.pysd.service_discovery.ServiceDiscovery.services_schemas_handler_endpoint","title":"<code>services_schemas_handler_endpoint()</code>","text":"<p>Gets the services schemas handler endpoint.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The services schemas handler endpoint.</p> Source code in <code>libs/python/shared/py-sd/pysd/service_discovery.py</code> <pre><code>def services_schemas_handler_endpoint(self):\n    \"\"\"\n    Gets the services schemas handler endpoint.\n\n    Returns:\n        str: The services schemas handler endpoint.\n    \"\"\"\n    service_name = self._service_vars.schemasHandler\n    endpoint = self._get_endpoint(\"SCHEMA_HANDLER_PORT_8000_TCP\", service_name)\n    if \"localhost\" in endpoint:\n        endpoint = endpoint.replace(\"8000\", \"8003\")\n    return endpoint\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/code_reference/pysd/service_discovery/#libs.python.shared.py-sd.pysd.service_discovery.ServiceDiscovery.services_file_catalog_handler_endpoint","title":"<code>services_file_catalog_handler_endpoint()</code>","text":"<p>Gets the services file catalog handler endpoint.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The services file catalog handler endpoint.</p> Source code in <code>libs/python/shared/py-sd/pysd/service_discovery.py</code> <pre><code>def services_file_catalog_handler_endpoint(self):\n    \"\"\"\n    Gets the services file catalog handler endpoint.\n\n    Returns:\n        str: The services file catalog handler endpoint.\n    \"\"\"\n    service_name = self._service_vars.fileCatalogHandler\n    endpoint = self._get_endpoint(\"FILE_CATALOG_HANDLER_PORT_8000_TCP\", service_name)\n    if \"localhost\" in endpoint:\n        endpoint = endpoint.replace(\"8000\", \"8006\")\n    return endpoint\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/code_reference/pysd/service_discovery/#libs.python.shared.py-sd.pysd.service_discovery.ServiceDiscovery.minio_endpoint","title":"<code>minio_endpoint()</code>","text":"<p>Gets the Minio endpoint.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The Minio endpoint.</p> Source code in <code>libs/python/shared/py-sd/pysd/service_discovery.py</code> <pre><code>def minio_endpoint(self):\n    \"\"\"\n    Gets the Minio endpoint.\n\n    Returns:\n        str: The Minio endpoint.\n    \"\"\"\n    service_name = self._service_vars.minio\n    endpoint = self._get_endpoint(\"MINIO_PORT_9000_TCP\", service_name)\n    return endpoint\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/code_reference/pysd/service_discovery/#libs.python.shared.py-sd.pysd.service_discovery.ServiceDiscovery.minio_access_key","title":"<code>minio_access_key()</code>","text":"<p>Gets the Minio access key.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The Minio access key.</p> Source code in <code>libs/python/shared/py-sd/pysd/service_discovery.py</code> <pre><code>def minio_access_key(self):\n    \"\"\"\n    Gets the Minio access key.\n\n    Returns:\n        str: The Minio access key.\n    \"\"\"\n    return os.getenv(\"MINIO_ACCESS_KEY\")\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/code_reference/pysd/service_discovery/#libs.python.shared.py-sd.pysd.service_discovery.ServiceDiscovery.minio_secret_key","title":"<code>minio_secret_key()</code>","text":"<p>Gets the Minio secret key.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The Minio secret key.</p> Source code in <code>libs/python/shared/py-sd/pysd/service_discovery.py</code> <pre><code>def minio_secret_key(self):\n    \"\"\"\n    Gets the Minio secret key.\n\n    Returns:\n        str: The Minio secret key.\n    \"\"\"\n    return os.getenv(\"MINIO_SECRET_KEY\")\n</code></pre>"},{"location":"reference/libs/python/shared/py-sd/code_reference/pysd/service_discovery/#libs.python.shared.py-sd.pysd.service_discovery.new_from_env","title":"<code>new_from_env()</code>","text":"<p>Creates a ServiceDiscovery instance using environment variables.</p> <p>Returns:</p> Name Type Description <code>ServiceDiscovery</code> <p>A new ServiceDiscovery instance.</p> Source code in <code>libs/python/shared/py-sd/pysd/service_discovery.py</code> <pre><code>def new_from_env():\n    \"\"\"\n    Creates a ServiceDiscovery instance using environment variables.\n\n    Returns:\n        ServiceDiscovery: A new ServiceDiscovery instance.\n    \"\"\"\n    return ServiceDiscovery(os.environ)\n</code></pre>"},{"location":"reference/libs/python/shared/py-serializer/","title":"py-serializer","text":"<p><code>py-serializer</code> is a Python library that provides functionality to serialize and deserialize dataclass objects to and from JSON and dictionaries. It simplifies the process of converting dataclass objects into a format that can be easily stored or transmitted, such as JSON.</p>"},{"location":"reference/libs/python/shared/py-serializer/#installation","title":"Installation","text":"<p>You can install <code>py-serializer</code> using <code>nx</code>:</p> <pre><code>npx nx add &lt;project&gt; --name python-shared-py-serializer --local\n</code></pre>"},{"location":"reference/libs/python/shared/py-serializer/#usage","title":"Usage","text":""},{"location":"reference/libs/python/shared/py-serializer/#importing-the-library","title":"Importing the Library","text":"<pre><code>from pyserializer.serializer import serialize_to_json, serialize_to_dict, serialize_to_dataclass\n</code></pre>"},{"location":"reference/libs/python/shared/py-serializer/#serializing-a-dataclass-object-to-json","title":"Serializing a Dataclass Object to JSON","text":"<pre><code># Serialize a dataclass object to a JSON string\ndataclass_obj = YourDataclass(...)\njson_string = serialize_to_json(dataclass_obj)\n</code></pre>"},{"location":"reference/libs/python/shared/py-serializer/#serializing-a-dataclass-object-to-a-dictionary","title":"Serializing a Dataclass Object to a Dictionary","text":"<pre><code># Serialize a dataclass object to a dictionary\ndataclass_obj = YourDataclass(...)\ndata_dict = serialize_to_dict(dataclass_obj)\n</code></pre>"},{"location":"reference/libs/python/shared/py-serializer/#deserializing-data-to-a-dataclass-object","title":"Deserializing Data to a Dataclass Object","text":"<pre><code># Deserialize data from a dictionary to a dataclass object\ndata = {...}  # Your data in dictionary form\ndataclass_obj = serialize_to_dataclass(data, YourDataclass)\n</code></pre>"},{"location":"reference/libs/python/shared/py-serializer/#examples","title":"Examples","text":"<p>Here are some examples of how to use the library:</p> <pre><code>from dataclasses import dataclass\nfrom pyserializer.serializer import serialize_to_json, serialize_to_dict, serialize_to_dataclass\n\n# Define a sample dataclass\n@dataclass\nclass Person:\n    name: str\n    age: int\n\n# Create a Person object\nperson = Person(name=\"Alice\", age=30)\n\n# Serialize the object to JSON\njson_data = serialize_to_json(person)\nprint(json_data)  # Output: {\"name\": \"Alice\", \"age\": 30}\n\n# Serialize the object to a dictionary\ndict_data = serialize_to_dict(person)\nprint(dict_data)  # Output: {\"name\": \"Alice\", \"age\": 30}\n\n# Deserialize data to a dataclass object\ndata = {\"name\": \"Bob\", \"age\": 25}\nnew_person = serialize_to_dataclass(data, Person)\nprint(new_person)  # Output: Person(name='Bob', age=25)\n</code></pre>"},{"location":"reference/libs/python/shared/py-serializer/#developing","title":"Developing","text":""},{"location":"reference/libs/python/shared/py-serializer/#run-tests","title":"Run tests","text":"<pre><code>npx nx test python-shared-py-serializer\n</code></pre>"},{"location":"reference/libs/python/shared/py-serializer/code_reference/pyserializer/serializer/","title":"Serializer","text":""},{"location":"reference/libs/python/shared/py-serializer/code_reference/pyserializer/serializer/#libs.python.shared.py-serializer.pyserializer.serializer.serialize_to_json","title":"<code>serialize_to_json(obj)</code>","text":"<p>Serializes a dataclass object to a JSON string.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>dataclass</code> <p>A dataclass object to be serialized.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A JSON string representing the serialized data from the dataclass object.</p> Source code in <code>libs/python/shared/py-serializer/pyserializer/serializer.py</code> <pre><code>def serialize_to_json(obj: dataclass) -&gt; str:\n    \"\"\"\n    Serializes a dataclass object to a JSON string.\n\n    Args:\n        obj: A dataclass object to be serialized.\n\n    Returns:\n        str: A JSON string representing the serialized data from the dataclass object.\n    \"\"\"\n    data = _get_serialized_object(obj)\n    return json.dumps(data, sort_keys=True)\n</code></pre>"},{"location":"reference/libs/python/shared/py-serializer/code_reference/pyserializer/serializer/#libs.python.shared.py-serializer.pyserializer.serializer.serialize_to_dict","title":"<code>serialize_to_dict(obj)</code>","text":"<p>Serializes a dataclass object to a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>dataclass</code> <p>A dataclass object to be serialized.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>Dict[str, any]</code> <p>A dictionary containing the serialized data from the dataclass object.</p> Source code in <code>libs/python/shared/py-serializer/pyserializer/serializer.py</code> <pre><code>def serialize_to_dict(obj: dataclass) -&gt; Dict[str, any]:\n    \"\"\"\n    Serializes a dataclass object to a dictionary.\n\n    Args:\n        obj: A dataclass object to be serialized.\n\n    Returns:\n        dict: A dictionary containing the serialized data from the dataclass object.\n    \"\"\"\n    return _get_serialized_object(obj)\n</code></pre>"},{"location":"reference/libs/python/shared/py-serializer/code_reference/pyserializer/serializer/#libs.python.shared.py-serializer.pyserializer.serializer.serialize_to_dataclass","title":"<code>serialize_to_dataclass(data, cls)</code>","text":"<p>Deserializes data from a dictionary into a dataclass object.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, any]</code> <p>A dictionary containing data to be deserialized.</p> required <code>cls</code> <code>Type</code> <p>The dataclass type to which the data should be deserialized.</p> required <p>Returns:</p> Name Type Description <code>cls</code> <code>dataclass</code> <p>An instance of the specified dataclass type with data deserialized from the input dictionary.</p> Source code in <code>libs/python/shared/py-serializer/pyserializer/serializer.py</code> <pre><code>def serialize_to_dataclass(data: Dict[str, any], cls: Type) -&gt; dataclass:\n    \"\"\"\n    Deserializes data from a dictionary into a dataclass object.\n\n    Args:\n        data: A dictionary containing data to be deserialized.\n        cls: The dataclass type to which the data should be deserialized.\n\n    Returns:\n        cls: An instance of the specified dataclass type with data deserialized from the input dictionary.\n    \"\"\"\n    args = {}\n    for field_obj in fields(cls):\n        field_name = field_obj.name\n        field_metadata = field_obj.metadata\n        json_name = field_metadata.get(\"json_name\", field_name)\n\n        if json_name in data:\n            args[field_name] = data[json_name]\n\n    return cls(**args)\n</code></pre>"},{"location":"reference/libs/python/shared/py-youtube/","title":"py-youtube","text":"<p><code>py-youtube</code> is a Python library that allows you to easily download YouTube videos from their URLs. It uses the PyTube library to retrieve the highest quality MP4 video stream available and save it as bytes data in a buffer. This library is helpful for various use cases, such as downloading YouTube videos for offline viewing or further processing.</p>"},{"location":"reference/libs/python/shared/py-youtube/#installation","title":"Installation","text":"<p>You can install <code>py-youtube</code> using <code>nx</code>:</p> <pre><code>npx nx add &lt;project&gt; --name python-shared-py-youtube --local\n</code></pre>"},{"location":"reference/libs/python/shared/py-youtube/#usage","title":"Usage","text":"<p>To download a YouTube video, you can use the <code>download_to_buffer</code> function provided by this library. Here's how to use it:</p> <pre><code>from pyyoutube import download_to_buffer\n\n# Specify the URL of the YouTube video you want to download\nvideo_url = \"https://www.youtube.com/watch?v=example_video_id\"\n\n# Download the video and get the video data as bytes\nvideo_data = download_to_buffer(video_url)\n\n# Save the video data to a file (e.g., downloaded_video.mp4)\nwith open(\"downloaded_video.mp4\", \"wb\") as file:\n    file.write(video_data)\n</code></pre>"},{"location":"reference/libs/python/shared/py-youtube/#exception-handling","title":"Exception Handling","text":"<p>The library defines an <code>YoutubeDownloaderError</code> exception that is raised if there is an error during the download process. You can catch and handle this exception in your code to deal with download failures gracefully.</p> <pre><code>from pyyoutube import download_to_buffer, YoutubeDownloaderError\n\ntry:\n    video_data = download_to_buffer(video_url)\nexcept YoutubeDownloaderError as e:\n    # Handle the download error\n    print(f\"Download error: {e}\")\n</code></pre>"},{"location":"reference/libs/python/shared/py-youtube/#contributions","title":"Contributions","text":"<p>Contributions and bug reports are welcome! If you find any issues or have suggestions for improvements, please feel free to create a GitHub issue or submit a pull request.</p>"},{"location":"reference/libs/typescript/nest/services/admin-videos-catalog/config-setup/","title":"config-setup","text":"<p>The <code>config-setup</code> library provides a module for easy configuration setup in a NestJS application. It uses the <code>@nestjs/config</code> module and <code>joi</code> for environment variable validation. This library is particularly useful for managing configurations related to database connections, logging, and other application-specific settings.</p>"},{"location":"reference/libs/typescript/nest/services/admin-videos-catalog/config-setup/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/nest/services/admin-videos-catalog/config-setup/#configmodule","title":"ConfigModule","text":"<p>The <code>ConfigModule</code> extends <code>NestConfigModule</code> and provides a flexible way to set up environment variables and validation schemas.</p>"},{"location":"reference/libs/typescript/nest/services/admin-videos-catalog/config-setup/#example","title":"Example","text":"<pre><code>import { Module } from '@nestjs/common';\nimport { ConfigModuleOptions } from '@nestjs/config';\nimport { ConfigModule as NestConfigModule } from '@nestlib/services/admin-videos-catalog/config-setup';\nimport Joi from 'joi';\nimport { join } from 'path';\n\ntype DB_SCHEMA_TYPE = {\n  DB_VENDOR: 'mysql' | 'sqlite';\n  DB_HOST: string;\n  DB_PORT: number;\n  DB_USERNAME: string;\n  DB_PASSWORD: string;\n  DB_DATABASE: string;\n  DB_LOGGING: boolean;\n  DB_AUTO_LOAD_MODELS: boolean;\n};\n\nexport const CONFIG_DB_SCHEMA: Joi.StrictSchemaMap&lt;DB_SCHEMA_TYPE&gt; = {\n  // ... Define your DB_SCHEMA_TYPE validation here\n};\n\nexport type CONFIG_SCHEMA_TYPE = DB_SCHEMA_TYPE;\n\n@Module({})\nexport class ConfigModule extends NestConfigModule {\n  static override forRoot(options: ConfigModuleOptions = {}) {\n\n    const { envFilePath, ...otherOptions } = options;\n\n    return super.forRoot({\n      isGlobal: true,\n      envFilePath: [\n        ...(Array.isArray(envFilePath) ? envFilePath : [envFilePath]),\n        join(process.cwd(), 'path/to/env/files', `.env.${process.env['NODE_ENV']}`),\n        join(process.cwd(), 'path/to/env/files', `.env`),\n      ],\n      validationSchema: Joi.object({\n        ...CONFIG_DB_SCHEMA,\n      }),\n      ...otherOptions,\n    });\n  }\n}\n</code></pre>"},{"location":"reference/libs/typescript/nest/services/admin-videos-catalog/config-setup/#unit-tests","title":"Unit Tests","text":"<p>You can use <code>jest</code> testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test typescript-nest-services-admin-videos-catalog-config-setup\n</code></pre>"},{"location":"reference/libs/typescript/nest/services/admin-videos-catalog/config-setup/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/nest/services/admin-videos-catalog/database/","title":"database","text":"<p>The <code>database</code> library is designed to simplify database setup in a NestJS application. It leverages the <code>@nestjs/sequelize</code> module and provides a flexible way to configure and connect to different databases, such as SQLite and MySQL. This library is particularly useful for managing database connections and models.</p>"},{"location":"reference/libs/typescript/nest/services/admin-videos-catalog/database/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/nest/services/admin-videos-catalog/database/#databasemodule","title":"DatabaseModule","text":"<p>The <code>DatabaseModule</code> simplifies the configuration and connection to databases. It supports both SQLite and MySQL configurations based on the <code>DB_VENDOR</code> environment variable.</p>"},{"location":"reference/libs/typescript/nest/services/admin-videos-catalog/database/#example","title":"Example","text":"<pre><code>import { Module } from '@nestjs/common';\nimport { ConfigService } from '@nestjs/config';\nimport { SequelizeModule } from '@nestjs/sequelize';\nimport { CONFIG_SCHEMA_TYPE } from '@nestlib/services/admin-videos-catalog/config-setup';\n\nconst models = [/* ... Add your Sequelize models here */];\n\n@Module({\n  imports: [\n    SequelizeModule.forRootAsync({\n      useFactory: (configService: ConfigService&lt;CONFIG_SCHEMA_TYPE&gt;) =&gt; {\n        const dbVendor = configService.get('DB_VENDOR');\n        // Configure for SQLite\n        if (dbVendor === 'sqlite') {\n          return {\n            dialect: 'sqlite',\n            host: configService.get('DB_HOST'),\n            models,\n            logging: configService.get('DB_LOGGING'),\n            autoLoadModels: configService.get('DB_AUTO_LOAD_MODELS'),\n          };\n        }\n        // Configure for MySQL\n        if (dbVendor === 'mysql') {\n          return {\n            dialect: 'mysql',\n            host: configService.get('DB_HOST'),\n            port: configService.get('DB_PORT'),\n            database: configService.get('DB_DATABASE'),\n            username: configService.get('DB_USERNAME'),\n            password: configService.get('DB_PASSWORD'),\n            models,\n            logging: configService.get('DB_LOGGING'),\n            autoLoadModels: configService.get('DB_AUTO_LOAD_MODELS'),\n          };\n        }\n\n        throw new Error(`Unsupported database configuration: ${dbVendor}`);\n      },\n      inject: [ConfigService],\n    }),\n  ],\n})\nexport class DatabaseModule {}\n</code></pre>"},{"location":"reference/libs/typescript/nest/services/admin-videos-catalog/database/#migrationsmodule","title":"MigrationsModule","text":"<p>The <code>MigrationsModule</code> integrates the <code>ConfigModule</code> and <code>DatabaseModule</code> for easy migration setup.</p>"},{"location":"reference/libs/typescript/nest/services/admin-videos-catalog/database/#example_1","title":"Example","text":"<pre><code>import { Module } from '@nestjs/common';\nimport { ConfigModule } from '@nestlib/services/admin-videos-catalog/config-setup';\nimport { DatabaseModule } from '@nestlib/services/admin-videos-catalog/database';\n\n@Module({\n  imports: [ConfigModule.forRoot(), DatabaseModule],\n})\nexport class MigrationsModule {}\n</code></pre>"},{"location":"reference/libs/typescript/nest/services/admin-videos-catalog/database/#unit-tests","title":"Unit Tests","text":"<p>You can use <code>jest</code> testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test typescript-nest-services-admin-videos-catalog-database\n</code></pre>"},{"location":"reference/libs/typescript/nest/services/admin-videos-catalog/database/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/nest/services/admin-videos-catalog/features/categories/","title":"categories","text":""},{"location":"reference/libs/typescript/nest/shared/filters/","title":"filters","text":"<p>The <code>filters</code> library provides custom exception filters for handling specific exceptions in a NestJS application. These filters can be used to provide consistent error responses for different types of exceptions.</p>"},{"location":"reference/libs/typescript/nest/shared/filters/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/nest/shared/filters/#notfounderrorfilter","title":"NotFoundErrorFilter","text":"<p>The <code>NotFoundErrorFilter</code> is an exception filter for handling <code>NotFoundError</code> exceptions. It returns a JSON response with a 404 status code.</p>"},{"location":"reference/libs/typescript/nest/shared/filters/#example","title":"Example","text":"<pre><code>import { NotFoundErrorFilter } from '@nestlib/shared/filters';\n\n// In your NestJS application module\napp.useGlobalFilters(new NotFoundErrorFilter());\n</code></pre>"},{"location":"reference/libs/typescript/nest/shared/filters/#entityvalidationerrorfilter","title":"EntityValidationErrorFilter","text":"<p>The <code>EntityValidationErrorFilter</code> is an exception filter for handling <code>EntityValidationError</code> exceptions. It returns a JSON response with a 422 status code, including detailed error messages.</p>"},{"location":"reference/libs/typescript/nest/shared/filters/#example_1","title":"Example","text":"<pre><code>import { EntityValidationErrorFilter } from '@nestlib/shared/filters';\n\n// In your NestJS application module\napp.useGlobalFilters(new EntityValidationErrorFilter());\n</code></pre>"},{"location":"reference/libs/typescript/nest/shared/filters/#filters_1","title":"Filters","text":""},{"location":"reference/libs/typescript/nest/shared/filters/#notfounderrorfilter_1","title":"NotFoundErrorFilter","text":"<pre><code>import { NotFoundError } from '@nodelib/shared/errors';\nimport { ArgumentsHost, Catch, ExceptionFilter } from '@nestjs/common';\nimport { Response } from 'express';\n\n@Catch(NotFoundError)\nexport class NotFoundErrorFilter implements ExceptionFilter {\n  catch(exception: NotFoundError, host: ArgumentsHost) {\n    const ctx = host.switchToHttp();\n    const response: Response = ctx.getResponse();\n\n    response.status(404).json({\n      statusCode: 404,\n      error: 'Not Found',\n      message: exception.message,\n    });\n  }\n}\n</code></pre>"},{"location":"reference/libs/typescript/nest/shared/filters/#entityvalidationerrorfilter_1","title":"EntityValidationErrorFilter","text":"<pre><code>import { EntityValidationError } from '@nodelib/shared/validators';\nimport { ArgumentsHost, Catch, ExceptionFilter } from '@nestjs/common';\nimport { Response } from 'express';\nimport { union } from 'lodash';\n\n@Catch(EntityValidationError)\nexport class EntityValidationErrorFilter implements ExceptionFilter {\n  catch(exception: EntityValidationError, host: ArgumentsHost) {\n    const ctx = host.switchToHttp();\n    const response = ctx.getResponse&lt;Response&gt;();\n    response.status(422).json({\n      statusCode: 422,\n      error: 'Unprocessable Entity',\n      message: union(\n        ...exception.error.reduce(\n          (acc, error) =&gt;\n            acc.concat(\n              typeof error === 'string' ? [[error]] : Object.values(error),\n            ),\n          [],\n        ),\n      ),\n    });\n  }\n}\n</code></pre>"},{"location":"reference/libs/typescript/nest/shared/filters/#unit-tests","title":"Unit Tests","text":"<p>You can use <code>jest</code> testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test typescript-nest-shared-filters\n</code></pre>"},{"location":"reference/libs/typescript/nest/shared/filters/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/nest/shared/interceptors/wrapper-data/","title":"wrapper-data","text":"<p>The <code>wrapper-data</code> library provides a NestJS interceptor, <code>WrapperDataInterceptor</code>, which wraps the response data in a consistent structure. This is particularly useful for creating a standardized API response format.</p>"},{"location":"reference/libs/typescript/nest/shared/interceptors/wrapper-data/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/nest/shared/interceptors/wrapper-data/#wrapperdatainterceptor","title":"WrapperDataInterceptor","text":"<p>The <code>WrapperDataInterceptor</code> is a NestJS interceptor that wraps the response data in a consistent structure. It checks if the response already contains a \"meta\" key and, if not, wraps the data in a \"data\" key.</p>"},{"location":"reference/libs/typescript/nest/shared/interceptors/wrapper-data/#example","title":"Example","text":"<pre><code>import { WrapperDataInterceptor } from '@nestlib/shared/interceptors/wrapper-data';\n\n// In your NestJS application module\napp.useGlobalInterceptors(new WrapperDataInterceptor());\n</code></pre>"},{"location":"reference/libs/typescript/nest/shared/interceptors/wrapper-data/#interceptor","title":"Interceptor","text":""},{"location":"reference/libs/typescript/nest/shared/interceptors/wrapper-data/#wrapperdatainterceptor_1","title":"WrapperDataInterceptor","text":"<pre><code>import {\n  CallHandler,\n  ExecutionContext,\n  Injectable,\n  NestInterceptor,\n} from '@nestjs/common';\nimport { Observable, map } from 'rxjs';\n\n@Injectable()\nexport class WrapperDataInterceptor implements NestInterceptor {\n  intercept(context: ExecutionContext, next: CallHandler): Observable&lt;any&gt; {\n    return next\n      .handle()\n      .pipe(map((body) =&gt; (!body || 'meta' in body ? body : { data: body })));\n  }\n}\n</code></pre>"},{"location":"reference/libs/typescript/nest/shared/interceptors/wrapper-data/#unit-tests","title":"Unit Tests","text":"<p>You can use <code>jest</code> testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test typescript-nest-shared-interceptors-wrapper-data\n</code></pre>"},{"location":"reference/libs/typescript/nest/shared/interceptors/wrapper-data/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/nest/shared/presenters/","title":"presenters","text":"<p>The <code>presenters</code> library provides abstract presenter classes to structure and present data in a consistent format. Presenters are particularly useful in transforming data, especially when preparing it for API responses.</p>"},{"location":"reference/libs/typescript/nest/shared/presenters/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/nest/shared/presenters/#collectionpresenter","title":"CollectionPresenter","text":"<p>The <code>CollectionPresenter</code> class serves as an abstract base class for presenters that represent collections of data. It includes a <code>PaginationPresenter</code> to handle pagination details.</p>"},{"location":"reference/libs/typescript/nest/shared/presenters/#example","title":"Example","text":"<pre><code>import { CollectionPresenter, PaginationPresenterProps } from '@nestlib/shared/presenters';\n\nclass MyCollectionPresenter extends CollectionPresenter {\n  constructor(props: PaginationPresenterProps) {\n    super(props);\n  }\n\n  get data() {\n    // Implement the logic to retrieve and transform your collection data\n    // ...\n\n    return transformedData;\n  }\n}\n</code></pre>"},{"location":"reference/libs/typescript/nest/shared/presenters/#paginationpresenter","title":"PaginationPresenter","text":"<p>The <code>PaginationPresenter</code> class transforms pagination properties into the desired format.</p>"},{"location":"reference/libs/typescript/nest/shared/presenters/#example_1","title":"Example","text":"<pre><code>import { PaginationPresenter, PaginationPresenterProps } from '@nestlib/shared/presenters';\n\nconst paginationProps: PaginationPresenterProps = {\n  current_page: 1,\n  per_page: 10,\n  last_page: 3,\n  total: 30,\n};\n\nconst paginationPresenter = new PaginationPresenter(paginationProps);\nconst transformedPagination = paginationPresenter; // Access transformed pagination data\n</code></pre>"},{"location":"reference/libs/typescript/nest/shared/presenters/#classes","title":"Classes","text":""},{"location":"reference/libs/typescript/nest/shared/presenters/#collectionpresenter_1","title":"CollectionPresenter","text":"<pre><code>import { Exclude, Expose } from 'class-transformer';\nimport { PaginationPresenter, PaginationPresenterProps } from '@nestlib/shared/presenters';\n\nexport abstract class CollectionPresenter {\n  @Exclude()\n  protected paginationPresenter: PaginationPresenter;\n\n  constructor(props: PaginationPresenterProps) {\n    this.paginationPresenter = new PaginationPresenter(props);\n  }\n\n  @Expose({ name: 'meta' })\n  get meta() {\n    return this.paginationPresenter;\n  }\n\n  abstract get data(): any;\n}\n</code></pre>"},{"location":"reference/libs/typescript/nest/shared/presenters/#paginationpresenter_1","title":"PaginationPresenter","text":"<pre><code>import { Transform } from 'class-transformer';\n\nexport type PaginationPresenterProps = {\n  current_page: number;\n  per_page: number;\n  last_page: number;\n  total: number;\n};\n\nexport class PaginationPresenter {\n  @Transform(({ value }) =&gt; parseInt(value))\n  current_page: number;\n  @Transform(({ value }) =&gt; parseInt(value))\n  per_page: number;\n  @Transform(({ value }) =&gt; parseInt(value))\n  last_page: number;\n  @Transform(({ value }) =&gt; parseInt(value))\n  total: number;\n\n  constructor(props: PaginationPresenterProps) {\n    this.current_page = props.current_page;\n    this.per_page = props.per_page;\n    this.last_page = props.last_page;\n    this.total = props.total;\n  }\n}\n</code></pre>"},{"location":"reference/libs/typescript/nest/shared/presenters/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/common/","title":"common","text":"<p>The <code>common</code> library is a TypeScript utility library that provides shared functionalities and mappers for entities in the context of a video catalog application. It includes output mappers for converting entities to standardized output formats.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/common/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/common/#output-mappers","title":"Output Mappers","text":"<p>The library provides an output mapper, such as <code>CategoryOutputMapper</code>, which is designed to convert entities to a standardized output format.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/common/#example","title":"Example","text":"<pre><code>import { Category } from '@nodelib/services/ddd/admin-videos-catalog/category/entity';\nimport { CategoryOutputMapper } from '@nodelib/services/ddd/admin-videos-catalog/category/application/use-cases/common';\n\nconst entity = Category.create({\n  name: 'Movie',\n  description: 'some description',\n  is_active: true,\n});\n\nconst output = CategoryOutputMapper.toOutput(entity);\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/common/#output-format","title":"Output Format","text":"<p>The output format is defined by the <code>CategoryOutput</code> type, which includes properties like <code>id</code>, <code>name</code>, <code>description</code>, <code>is_active</code>, and <code>created_at</code>.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/common/#example_1","title":"Example","text":"<pre><code>export type CategoryOutput = {\n  id: string;\n  name: string;\n  description: string | null;\n  is_active: boolean;\n  created_at: Date;\n};\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/common/#unit-tests","title":"Unit Tests","text":"<p>You can use <code>jest</code> testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test typescript-node-services-ddd-admin-videos-catalog-category-application-use-cases-common\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/common/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/create-category/","title":"create-category","text":"<p>The <code>create-category</code> library is a TypeScript utility library that provides a use case for creating categories in the context of a video catalog application. It includes validation for input properties and supports integration with different repositories.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/create-category/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/create-category/#input-validation","title":"Input Validation","text":"<p>The library provides an input validation class, <code>CreateCategoryInput</code>, which validates the properties of a category before creating it.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/create-category/#example","title":"Example","text":"<pre><code>import { CreateCategoryInput, ValidateCreateCategoryInput } from '@nodelib/services/ddd/admin-videos-catalog/category/application/use-cases/create-category';\n\nconst input = { name: 'Movie', description: 'some description', is_active: true };\nconst validatedInput = ValidateCreateCategoryInput.validate(new CreateCategoryInput(input));\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/create-category/#use-case","title":"Use Case","text":"<p>The primary use case, <code>CreateCategoryUseCase</code>, is responsible for creating a category entity, validating it, and inserting it into the specified repository.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/create-category/#example_1","title":"Example","text":"<pre><code>import { CategoryInMemoryRepository } from '@nodelib/services/ddd/admin-videos-catalog/category/infra/db/in-memory';\nimport { CreateCategoryUseCase } from '@nodelib/services/ddd/admin-videos-catalog/category/application/use-cases/create-category';\n\nconst repository = new CategoryInMemoryRepository();\nconst useCase = new CreateCategoryUseCase(repository);\n\nconst input = { name: 'Movie', description: 'some description', is_active: true };\nconst output = await useCase.execute(input);\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/create-category/#output-format","title":"Output Format","text":"<p>The output format is similar to the <code>CategoryOutput</code> format provided by the <code>common</code> library.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/create-category/#unit-tests","title":"Unit Tests","text":"<p>You can use <code>jest</code> testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test typescript-node-services-ddd-admin-videos-catalog-category-application-use-cases-create-category\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/create-category/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/delete-category/","title":"delete-category","text":"<p>The <code>delete-category</code> library is a TypeScript utility library that provides a use case for deleting categories in the context of a video catalog application. It includes integration tests for both in-memory and Sequelize repository implementations.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/delete-category/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/delete-category/#use-case","title":"Use Case","text":"<p>The primary use case, <code>DeleteCategoryUseCase</code>, is responsible for deleting a category entity from the specified repository.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/delete-category/#example","title":"Example","text":"<pre><code>import { CategorySequelizeRepository } from '@nodelib/services/ddd/admin-videos-catalog/category/infra/db/sequelize';\nimport { DeleteCategoryUseCase } from '@nodelib/services/ddd/admin-videos-catalog/category/application/use-cases/delete-category';\n\nconst repository = new CategorySequelizeRepository(CategoryModel);\nconst useCase = new DeleteCategoryUseCase(repository);\n\nconst categoryId = '123'; // Replace with the actual category ID\nawait useCase.execute({ id: categoryId });\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/delete-category/#unit-tests","title":"Unit Tests","text":"<p>You can use <code>jest</code> testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test typescript-node-services-ddd-admin-videos-catalog-category-application-use-cases-delete-category\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/delete-category/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/get-category/","title":"get-category","text":"<p>The <code>get-category</code> library is a TypeScript utility library that provides a use case for retrieving category details in the context of a video catalog application. It includes integration tests for both in-memory and Sequelize repository implementations.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/get-category/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/get-category/#use-case","title":"Use Case","text":"<p>The primary use case, <code>GetCategoryUseCase</code>, is responsible for retrieving category details by ID from the specified repository.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/get-category/#example","title":"Example","text":"<pre><code>import { CategorySequelizeRepository } from '@nodelib/services/ddd/admin-videos-catalog/category/infra/db/sequelize';\nimport { GetCategoryUseCase } from '@nodelib/services/ddd/admin-videos-catalog/category/application/use-cases/get-category';\n\nconst repository = new CategorySequelizeRepository(CategoryModel);\nconst useCase = new GetCategoryUseCase(repository);\n\nconst categoryId = '123'; // Replace with the actual category ID\nconst categoryDetails = await useCase.execute({ id: categoryId });\nconsole.log(categoryDetails);\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/get-category/#unit-tests","title":"Unit Tests","text":"<p>You can use <code>jest</code> testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test typescript-node-services-ddd-admin-videos-catalog-category-application-use-cases-get-category\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/get-category/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/list-categories/","title":"list-categories","text":"<p>The <code>list-categories</code> library is a TypeScript utility library that provides a use case for listing categories with pagination, sorting, and filtering in the context of a video catalog application. It includes unit and integration tests for both in-memory and Sequelize repository implementations.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/list-categories/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/list-categories/#use-case","title":"Use Case","text":"<p>The primary use case, <code>ListCategoriesUseCase</code>, is responsible for listing categories based on the provided input parameters, such as page, per_page, sort, sort_dir, and filter.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/list-categories/#example","title":"Example","text":"<pre><code>import { CategorySequelizeRepository } from '@nodelib/services/ddd/admin-videos-catalog/category/infra/db/sequelize';\nimport { ListCategoriesUseCase } from '@nodelib/services/ddd/admin-videos-catalog/category/application/use-cases/list-categories';\n\nconst repository = new CategorySequelizeRepository(CategoryModel);\nconst useCase = new ListCategoriesUseCase(repository);\n\nconst listParams = {\n  page: 1,\n  per_page: 10,\n  sort: 'name',\n  sort_dir: 'asc',\n  filter: 'action',\n};\n\nconst categoryList = await useCase.execute(listParams);\nconsole.log(categoryList);\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/list-categories/#unit-tests","title":"Unit Tests","text":"<p>You can use <code>jest</code> testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test typescript-node-services-ddd-admin-videos-catalog-category-application-use-cases-list-categories\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/list-categories/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/update-category/","title":"update-category","text":"<p>The <code>update-category</code> library is a TypeScript utility library that provides a use case for updating categories in the context of a video catalog application. It includes unit and integration tests for both in-memory and Sequelize repository implementations.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/update-category/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/update-category/#use-case","title":"Use Case","text":"<p>The primary use case, <code>UpdateCategoryUseCase</code>, is responsible for updating categories based on the provided input parameters such as ID, name, description, and is_active.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/update-category/#example","title":"Example","text":"<pre><code>import { CategorySequelizeRepository } from '@nodelib/services/ddd/admin-videos-catalog/category/infra/db/sequelize';\nimport { UpdateCategoryUseCase } from '@nodelib/services/ddd/admin-videos-catalog/category/application/use-cases/update-category';\n\nconst repository = new CategorySequelizeRepository(CategoryModel);\nconst useCase = new UpdateCategoryUseCase(repository);\n\nconst updateParams = {\n  id: 'category-id',\n  name: 'Updated Category',\n  description: 'Updated category description',\n  is_active: true,\n};\n\nconst updatedCategory = await useCase.execute(updateParams);\nconsole.log(updatedCategory);\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/update-category/#unit-tests","title":"Unit Tests","text":"<p>You can use <code>jest</code> testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test typescript-node-services-ddd-admin-videos-catalog-category-application-use-cases-update-category\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/application/use-cases/update-category/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/entity/","title":"entity","text":"<p>The <code>entity</code> library is a TypeScript library designed to facilitate the creation and management of entities in a domain-driven design (DDD) context. It provides a base class for entities, value objects, and various utilities for creating and validating entities.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/entity/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/entity/#entity-class","title":"Entity Class","text":"<p>The core of the library is the <code>Entity</code> class, which serves as the base class for entities in your application. Entities are objects that have a distinct identity and are defined by their attributes.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/entity/#example","title":"Example","text":"<pre><code>import { Entity, Uuid } from '@nodelib/shared/value-objects/uuid';\n\nexport class Category extends Entity {\n  category_id: Uuid;\n  name: string;\n  description: string | null;\n  is_active: boolean;\n  created_at: Date;\n\n  constructor(props: CategoryConstructorProps) {\n    super();\n    // ... constructor implementation\n  }\n\n  // ... additional methods and properties\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/entity/#valueobject-class","title":"ValueObject Class","text":"<p>The library also provides a <code>ValueObject</code> class for defining value objects in your domain model.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/entity/#example_1","title":"Example","text":"<pre><code>import { ValueObject } from '@nodelib/shared/value-object';\n\nexport class ExampleValueObject extends ValueObject {\n  // ... value object implementation\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/entity/#validation","title":"Validation","text":"<p>The library includes a validation mechanism using class-validator. You can define validation rules for your entities using decorators.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/entity/#example_2","title":"Example","text":"<pre><code>import { MaxLength } from 'class-validator';\n\nexport class CategoryRules {\n  @MaxLength(255, { groups: ['name'] })\n  name: string;\n\n  // ... other validation rules\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/entity/#validator-class","title":"Validator Class","text":"<p>To validate entities, the library provides a <code>ClassValidatorFields</code> class that extends the functionality of class-validator.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/entity/#example_3","title":"Example","text":"<pre><code>import { ClassValidatorFields, Notification } from \"@nodelib/shared/validators\";\n\nexport class CategoryValidator extends ClassValidatorFields {\n  override validate(notification: Notification, data: any, fields?: string[]): boolean {\n    // ... validation logic\n  }\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/entity/#factory-class","title":"Factory Class","text":"<p>A factory class, such as <code>CategoryValidatorFactory</code>, can be used to create instances of the validator.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/entity/#example_4","title":"Example","text":"<pre><code>import { CategoryValidatorFactory } from '@nodelib/services/ddd/admin-videos-catalog/category/entity';\n\nconst validator = CategoryValidatorFactory.create();\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/entity/#fakebuilder-class","title":"FakeBuilder Class","text":"<p>For testing purposes, the library provides a <code>CategoryFakeBuilder</code> class that allows you to create fake instances of your entities with customizable properties.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/entity/#example_5","title":"Example","text":"<pre><code>import { CategoryFakeBuilder } from '@nodelib/services/ddd/admin-videos-catalog/category/entity';\n\nconst fakeCategory = CategoryFakeBuilder.aCategory().build();\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/entity/#unit-tests","title":"Unit Tests","text":"<p>You can use <code>jest</code> testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test typescript-node-services-ddd-admin-videos-catalog-category-entity\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/entity/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/infra/db/in-memory/","title":"in-memory","text":"<p>The <code>in-memory</code> library provides an in-memory repository implementation specifically designed for managing <code>Category</code> entities in the context of the <code>admin-videos-catalog</code> service. This implementation extends the generic <code>InMemorySearchableRepository</code> from <code>ddd-utils</code> and includes sorting and filtering capabilities.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/infra/db/in-memory/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/infra/db/in-memory/#categoryinmemoryrepository","title":"CategoryInMemoryRepository","text":"<p>The <code>CategoryInMemoryRepository</code> class extends the <code>InMemorySearchableRepository</code> and is tailored for handling <code>Category</code> entities. It includes specific sorting and filtering logic for these entities.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/infra/db/in-memory/#example","title":"Example:","text":"<pre><code>import { CategoryInMemoryRepository } from '@nodelib/services/ddd/admin-videos-catalog/category/infra/db/in-memory';\n\n// Create an instance of the repository\nconst categoryRepository = new CategoryInMemoryRepository();\n\n// Use repository methods for managing Category entities\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/infra/db/in-memory/#example_1","title":"Example","text":"<p>Here is an example of how to use the <code>CategoryInMemoryRepository</code> in your project:</p> <pre><code>import { CategoryInMemoryRepository } from '@nodelib/services/ddd/admin-videos-catalog/category/infra/db/in-memory';\nimport { Category } from '@nodelib/services/ddd/admin-videos-catalog/category/entity';\n\n// Create an instance of the repository\nconst categoryRepository = new CategoryInMemoryRepository();\n\n// Create and insert Category entities\nconst category1 = new Category({ /* Category properties */ });\nconst category2 = new Category({ /* Category properties */ });\n\nawait categoryRepository.insert(category1);\nawait categoryRepository.insert(category2);\n\n// Search and filter Category entities\nconst filteredCategories = await categoryRepository.search({\n  filter: 'SomeFilter',\n  // Add other search parameters as needed\n});\n\nconsole.log(filteredCategories);\n\n// Sorting Category entities\nconst sortedCategories = await categoryRepository.search({\n  sort: 'name',\n  sort_dir: 'asc',\n});\n\nconsole.log(sortedCategories);\n\n// ... Other repository operations ...\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/infra/db/in-memory/#unit-tests","title":"Unit Tests","text":"<p>You can use <code>jest</code> testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test typescript-node-services-ddd-admin-videos-catalog-category-infra-db-in-memory\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/infra/db/in-memory/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/infra/db/sequelize/","title":"sequelize","text":"<p>The <code>sequelize</code> library provides a Sequelize-based repository implementation for managing <code>Category</code> entities within the <code>admin-videos-catalog</code> service. This implementation allows you to interact with a relational database using the Sequelize ORM. It includes methods for CRUD operations, searching, and pagination.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/infra/db/sequelize/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/infra/db/sequelize/#categorymodel","title":"CategoryModel","text":"<p>The <code>CategoryModel</code> class represents the Sequelize model for the <code>categories</code> table. It defines the structure of the table, including data types, constraints, and relationships.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/infra/db/sequelize/#categorysequelizerepository","title":"CategorySequelizeRepository","text":"<p>The <code>CategorySequelizeRepository</code> class implements the repository interface (<code>ICategoryRepository</code>) using Sequelize. It provides methods for inserting, updating, deleting, and searching for <code>Category</code> entities in the database.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/infra/db/sequelize/#categorymodelmapper","title":"CategoryModelMapper","text":"<p>The <code>CategoryModelMapper</code> class contains static methods for converting between <code>Category</code> entities and Sequelize <code>CategoryModel</code> instances. It ensures a seamless transition between your application's business logic and the database layer.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/infra/db/sequelize/#unit-tests","title":"Unit Tests","text":"<p>You can use <code>jest</code> testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test typescript-node-services-ddd-admin-videos-catalog-category-infra-db-sequelize\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/infra/db/sequelize/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/repository/","title":"repository","text":"<p>The <code>repository</code> library provides an interface and related classes for working with repositories, specifically designed for managing <code>Category</code> entities in the context of the <code>admin-videos-catalog</code> service. It leverages the common repository patterns and interfaces from <code>ddd-utils</code>.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/repository/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/repository/#icategoryrepository-interface","title":"ICategoryRepository Interface","text":"<p>The <code>ICategoryRepository</code> interface extends the <code>ISearchableRepository</code> from <code>ddd-utils</code> and provides specific methods for managing <code>Category</code> entities. It defines methods for searching, creating, updating, and deleting <code>Category</code> entities.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/repository/#example","title":"Example:","text":"<pre><code>import { ICategoryRepository, CategoryFilter, CategorySearchParams, CategorySearchResult } from '@nodelib/services/ddd/admin-videos-catalog/category/repository';\nimport { Category } from '@nodelib/services/ddd/admin-videos-catalog/category/entity';\nimport { Uuid } from '@nodelib/shared/value-objects/uuid';\n\nclass MyCategoryRepository implements ICategoryRepository {\n  // Implement the interface methods here\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/repository/#categorysearchparams-and-categorysearchresult","title":"CategorySearchParams and CategorySearchResult","text":"<p>The <code>CategorySearchParams</code> and <code>CategorySearchResult</code> classes extend the generic <code>SearchParams</code> and <code>SearchResult</code> classes from <code>ddd-utils</code>. They provide specific types for working with search parameters and search results related to <code>Category</code> entities.</p>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/repository/#example_1","title":"Example:","text":"<pre><code>import { CategorySearchParams, CategorySearchResult } from '@nodelib/services/ddd/admin-videos-catalog/category/repository';\n\n// Create an instance of search parameters\nconst searchParams = new CategorySearchParams({\n  filter: 'SomeFilter',\n  // Add other parameters as needed\n});\n\n// Create an instance of search results\nconst searchResult = new CategorySearchResult({\n  items: [/* Category entities */],\n  total: 10,\n  current_page: 1,\n  per_page: 5,\n});\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/repository/#example_2","title":"Example","text":"<p>Here is an example of how to use the <code>repository</code> library in your project:</p> <pre><code>import { ICategoryRepository, CategoryFilter, CategorySearchParams, CategorySearchResult } from '@nodelib/services/ddd/admin-videos-catalog/category/repository';\nimport { Category } from '@nodelib/services/ddd/admin-videos-catalog/category/entity';\nimport { Uuid } from '@nodelib/shared/value-objects/uuid';\n\nclass MyCategoryRepository implements ICategoryRepository {\n  async search(params: CategorySearchParams): Promise&lt;CategorySearchResult&gt; {\n    // Implement search logic here\n    // Return a SearchResult object\n  }\n\n  async create(entity: Category): Promise&lt;void&gt; {\n    // Implement creation logic here\n  }\n\n  async update(entity: Category): Promise&lt;void&gt; {\n    // Implement update logic here\n  }\n\n  async delete(entityId: Uuid): Promise&lt;void&gt; {\n    // Implement delete logic here\n  }\n\n  async findById(entityId: Uuid): Promise&lt;Category | null&gt; {\n    // Implement find by ID logic here\n    // Return null if not found\n  }\n\n  async findAll(): Promise&lt;Category[]&gt; {\n    // Implement find all logic here\n    // Return an array of Category entities\n  }\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/services/ddd/admin-videos-catalog/category/repository/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/entity/","title":"entity","text":"<p>The <code>entity</code> library provides an abstract class <code>Entity</code> that serves as a base for creating entities in TypeScript. Entities represent objects with a distinct identity and encapsulate business logic.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/entity/#usage","title":"Usage","text":"<p>To create an entity, extend the <code>Entity</code> class provided by this library:</p> <pre><code>import { Entity } from \"@nodelib/shared/ddd-utils/entity\";\nimport { ValueObject } from '@nodelib/shared/value-object';\n\nclass MyEntity extends Entity {\n  private _entity_id: ValueObject;\n\n  constructor(entityId: ValueObject) {\n    super();\n    this._entity_id = entityId;\n  }\n\n  get entity_id(): ValueObject {\n    return this._entity_id;\n  }\n\n  toJSON(): any {\n    // Your custom logic for converting the entity to JSON\n  }\n}\n\n// Example usage\nconst entityId = new ValueObject(/* pass values for initialization */);\nconst myEntity = new MyEntity(entityId);\n\nconsole.log(myEntity.entity_id);\nconsole.log(myEntity.toJSON());\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/entity/#note","title":"Note","text":"<ul> <li>Ensure that your entity class has an <code>entity_id</code> property of type <code>ValueObject</code> and implements the <code>toJSON</code> method based on your application requirements.</li> </ul>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/entity/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/db/in-memory/","title":"in-memory","text":"<p>The <code>in-memory</code> library provides a simple implementation of an in-memory repository for managing entities. It is particularly useful for testing or scenarios where a persistent data store is not required.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/db/in-memory/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/db/in-memory/#inmemoryrepository","title":"InMemoryRepository","text":"<p>The <code>InMemoryRepository</code> class is an abstract base class that provides basic CRUD operations for entities. To use this class, extend it and implement the <code>getEntity</code> method.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/db/in-memory/#example","title":"Example:","text":"<pre><code>import { InMemoryRepository, Entity, NotFoundError, ValueObject } from '@nodelib/shared/ddd-utils';\n\nexport abstract class MyEntity extends Entity {\n  // Define your entity properties here\n}\n\nexport class MyEntityRepository extends InMemoryRepository&lt;MyEntity, ValueObject&gt; {\n  getEntity(): new (...args: any[]) =&gt; MyEntity {\n    return MyEntity;\n  }\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/db/in-memory/#inmemorysearchablerepository","title":"InMemorySearchableRepository","text":"<p>The <code>InMemorySearchableRepository</code> class extends the functionality of <code>InMemoryRepository</code> by adding support for searching, sorting, and pagination of entities.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/db/in-memory/#example_1","title":"Example:","text":"<pre><code>import { InMemorySearchableRepository, Entity, NotFoundError, ValueObject } from '@nodelib/shared/ddd-utils';\n\nexport abstract class MySearchableEntityRepository extends InMemorySearchableRepository&lt;MyEntity, ValueObject, string&gt; {\n  sortableFields: string[] = ['name', 'createdAt'];\n\n  protected async applyFilter(items: MyEntity[], filter: string | null): Promise&lt;MyEntity[]&gt; {\n    // Implement your filtering logic here\n    return items.filter(item =&gt; item.name.includes(filter));\n  }\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/db/in-memory/#example_2","title":"Example","text":"<p>Here is an example of how to use the <code>in-memory</code> library:</p> <pre><code>import { StubEntity, StubInMemoryRepository, Uuid } from '@nodelib/shared/ddd-utils/infra/db/in-memory';\n\n// Create an instance of the repository\nconst repo = new StubInMemoryRepository();\n\n// Insert a new entity\nconst entity = new StubEntity({ entity_id: new Uuid(), name: 'Test', price: 100 });\nawait repo.insert(entity);\n\n// Find all entities\nconst entities = await repo.findAll();\nconsole.log(entities);\n\n// Search entities with a filter\nconst searchResult = await repo.search({ filter: 'Test', sort: 'name', sort_dir: 'asc', page: 1, per_page: 10 });\nconsole.log(searchResult);\n\n// Update an entity\nconst updatedEntity = new StubEntity({ entity_id: entity.entity_id, name: 'UpdatedTest', price: 150 });\nawait repo.update(updatedEntity);\n\n// Delete an entity\nawait repo.delete(entity.entity_id);\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/db/in-memory/#testing","title":"Testing","text":"<p>You can use <code>jest</code> testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test typescript-node-shared-ddd-utils-infra-db-in-memory\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/db/in-memory/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/db/sequelize/","title":"sequelize","text":"<p>The <code>sequelize</code> library provides a utility for managing database migrations using Sequelize and Umzug. This library is particularly useful for maintaining the schema of your database across different versions of your application.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/db/sequelize/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/db/sequelize/#migrator","title":"Migrator","text":"<p>The <code>migrator</code> function facilitates the creation of an Umzug instance configured for Sequelize migrations.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/db/sequelize/#example","title":"Example:","text":"<pre><code>import { Sequelize } from 'sequelize';\nimport { migrator } from '@nodelib/shared/ddd-utils/infra/db/sequelize';\n\n// Create a Sequelize instance\nconst sequelize = new Sequelize('database', 'username', 'password', {\n  host: 'localhost',\n  dialect: 'postgres',\n  // Add other Sequelize configurations as needed\n});\n\n// Create a migrator instance\nconst umzug = migrator(sequelize, {\n  // Customize Umzug options if needed\n});\n\n// To run migrations\numzug.up().then(() =&gt; {\n  console.log('Migrations have been executed successfully.');\n}).catch((error) =&gt; {\n  console.error('Error executing migrations:', error);\n});\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/db/sequelize/#example_1","title":"Example","text":"<p>Here is an example of how to use the <code>sequelize</code> library in your project:</p> <pre><code>import { Sequelize } from 'sequelize';\nimport { migrator } from '@nodelib/shared/ddd-utils/infra/db/sequelize';\n\n// Create a Sequelize instance\nconst sequelize = new Sequelize('database', 'username', 'password', {\n  host: 'localhost',\n  dialect: 'postgres',\n  // Add other Sequelize configurations as needed\n});\n\n// Create a migrator instance\nconst umzug = migrator(sequelize);\n\n// To run migrations\numzug.up().then(() =&gt; {\n  console.log('Migrations have been executed successfully.');\n}).catch((error) =&gt; {\n  console.error('Error executing migrations:', error);\n});\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/db/sequelize/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/testing/","title":"testing","text":"<p>The <code>testing</code> library provides utility functions and configurations for testing applications. It includes functionality for handling environment configurations, Sequelize setup for database testing, and custom Jest matchers for assertions.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/testing/#configuration","title":"Configuration","text":""},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/testing/#environment-configuration","title":"Environment Configuration","text":"<p>The <code>Config</code> class provides methods to read environment variables, specifically tailored for testing. The <code>readEnv</code> method reads environment variables from a specified file path, allowing you to customize the environment for different testing scenarios.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/testing/#example","title":"Example:","text":"<pre><code>import { Config } from '@nodelib/shared/ddd-utils/infra/testing';\n\n// Read environment variables for the 'admin-videos-catalog' service\nConfig.readEnv('admin-videos-catalog');\n\n// Access the configured environment variables\nconsole.log(Config.env.DB_HOST);\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/testing/#sequelize-setup","title":"Sequelize Setup","text":"<p>The <code>setupSequelize</code> function simplifies the setup and teardown of a Sequelize instance for testing purposes. It takes Sequelize options as parameters and returns an object containing the Sequelize instance.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/testing/#example_1","title":"Example:","text":"<pre><code>import { setupSequelize } from '@nodelib/shared/ddd-utils/infra/testing';\n\n// Setup Sequelize for testing\nconst { sequelize } = setupSequelize();\n\n// Use the sequelize instance for testing database operations\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/testing/#custom-jest-matchers","title":"Custom Jest Matchers","text":"<p>The library provides a custom Jest matcher for assertions related to error messages in a <code>Notification</code> object. The <code>notificationContainsErrorMessages</code> matcher can be used to assert that a <code>Notification</code> instance contains specific error messages.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/testing/#example_2","title":"Example:","text":"<pre><code>import { expect } from '@jest/globals';\nimport { Notification } from '@nodelib/shared/validators';\n\nconst notification = new Notification();\nnotification.addError('field1', 'Error message for field1');\n\n// Assert that the Notification contains specific error messages\nexpect(notification).notificationContainsErrorMessages([\n  'Error message for field1',\n]);\n\n// Assert that the Notification does not contain specific error messages\nexpect(notification).not.notificationContainsErrorMessages([\n  'Error message for field2',\n]);\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/testing/#example_3","title":"Example","text":"<p>Here is an example of how to use the <code>testing</code> library in your project:</p> <pre><code>import { Config, setupSequelize } from '@nodelib/shared/ddd-utils/infra/testing';\n\n// Read environment variables for the 'admin-videos-catalog' service\nConfig.readEnv('admin-videos-catalog');\n\n// Setup Sequelize for testing\nconst { sequelize } = setupSequelize();\n\n// Use the sequelize instance for testing database operations\n\n// ... Your test code here ...\n\n// Close the Sequelize connection after testing\nawait sequelize.close();\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/infra/testing/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/repository/","title":"repository","text":"<p>The <code>repository</code> library provides TypeScript interfaces and utility classes for creating repositories that interact with entities. Additionally, it includes a <code>search-params</code> class for defining search parameters and a <code>search-result</code> class for representing the results of a search.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/repository/#irepository-interface","title":"IRepository Interface","text":"<p>The <code>IRepository</code> interface defines a set of methods for basic CRUD (Create, Read, Update, Delete) operations on entities.</p> <pre><code>import { Entity } from '@nodelib/shared/ddd-utils/entity';\nimport { ValueObject } from '@nodelib/shared/value-object';\n\nexport interface IRepository&lt;E extends Entity, EntityId extends ValueObject&gt; {\n  insert(entity: E): Promise&lt;void&gt;;\n  bulkInsert(entities: E[]): Promise&lt;void&gt;;\n  update(entity: E): Promise&lt;void&gt;;\n  delete(entity_id: EntityId): Promise&lt;void&gt;;\n\n  findById(entity_id: EntityId): Promise&lt;E | null&gt;;\n  findAll(): Promise&lt;E[]&gt;;\n\n  getEntity(): new (...args: any[]) =&gt; E;\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/repository/#isearchablerepository-interface","title":"ISearchableRepository Interface","text":"<p>The <code>ISearchableRepository</code> interface extends <code>IRepository</code> and adds additional methods for searching entities based on specified parameters.</p> <pre><code>import { Entity } from '@nodelib/shared/ddd-utils/entity';\nimport { ValueObject } from '@nodelib/shared/value-object';\n\nexport interface ISearchableRepository&lt;\n  E extends Entity,\n  EntityId extends ValueObject,\n  Filter = string,\n  SearchInput = SearchParams&lt;Filter&gt;,\n  SearchOutput = SearchResult\n&gt; extends IRepository&lt;E, EntityId&gt; {\n  sortableFields: string[];\n  search(props: SearchInput): Promise&lt;SearchOutput&gt;;\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/repository/#searchparams-class","title":"SearchParams Class","text":"<p>The <code>SearchParams</code> class provides a way to define search parameters, including pagination, sorting, and filtering.</p> <pre><code>import { ValueObject } from '@nodelib/shared/value-object';\n\nexport type SortDirection = 'asc' | 'desc';\n\nexport type SearchParamsConstructorProps&lt;Filter = string&gt; = {\n  page?: number;\n  per_page?: number;\n  sort?: string | null;\n  sort_dir?: SortDirection | null;\n  filter?: Filter | null;\n};\n\nexport class SearchParams&lt;Filter = string&gt; extends ValueObject {\n  // Implementation details...\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/repository/#searchresult-class","title":"SearchResult Class","text":"<p>The <code>SearchResult</code> class represents the result of a search operation, including paginated items and metadata.</p> <pre><code>import { Entity } from '@nodelib/shared/ddd-utils/entity';\nimport { ValueObject } from '@nodelib/shared/value-object';\n\ntype SearchResultConstructorProps&lt;E extends Entity&gt; = {\n  items: E[];\n  total: number;\n  current_page: number;\n  per_page: number;\n};\n\nexport class SearchResult&lt;A extends Entity = Entity&gt; extends ValueObject {\n  // Implementation details...\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/repository/#unit-tests","title":"Unit Tests","text":"<p>You can use <code>jest</code> testing framework for this purpose and you can run it with <code>nx</code>:</p> <pre><code>npx nx test typescript-node-shared-ddd-utils-repository\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/repository/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/use-case/","title":"use-case","text":"<p>The <code>use-case</code> library provides a base interface and utility class for defining and executing use cases in TypeScript. Additionally, it includes a utility for mapping search results to a standardized pagination output.</p>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/use-case/#iusecase-interface","title":"IUseCase Interface","text":"<p>The <code>IUseCase</code> interface defines a generic structure for implementing use cases. Use cases encapsulate the business logic of an application and can be executed with specific input parameters to produce output.</p> <pre><code>export interface IUseCase&lt;Input, Output&gt; {\n  execute(input: Input): Promise&lt;Output&gt;;\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/use-case/#paginationoutputmapper-class","title":"PaginationOutputMapper Class","text":"<p>The <code>PaginationOutputMapper</code> class provides a utility method for mapping search results to a standardized pagination output format.</p> <pre><code>import { SearchResult } from '@nodelib/shared/ddd-utils/repository';\n\nexport type PaginationOutput&lt;Item = any&gt; = {\n  items: Item[];\n  total: number;\n  current_page: number;\n  last_page: number;\n  per_page: number;\n};\n\nexport class PaginationOutputMapper {\n  static toOutput&lt;Item = any&gt;(\n    items: Item[],\n    props: Omit&lt;SearchResult, 'items'&gt;\n  ): PaginationOutput&lt;Item&gt; {\n    return {\n      items,\n      total: props.total,\n      current_page: props.current_page,\n      last_page: props.last_page,\n      per_page: props.per_page,\n    };\n  }\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/use-case/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/node/shared/ddd-utils/use-case/#creating-a-use-case","title":"Creating a Use Case","text":"<p>To create a use case, implement the <code>IUseCase</code> interface with specific input and output types.</p> <pre><code>import { IUseCase } from '@nodelib/shared/ddd-utils/use-case';\n\ninterface MyUseCaseInput {\n  // Define your input properties\n}\n\ninterface MyUseCaseOutput {\n  // Define your output properties\n}\n\nclass MyUseCase implements IUseCase&lt;MyUseCaseInput, MyUseCaseOutput&gt; {\n  async execute(input: MyUseCaseInput): Promise&lt;MyUseCaseOutput&gt; {\n    // Implement your business logic here\n    return Promise.resolve(/* your output */);\n  }\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/use-case/#using-pagination-output-mapper","title":"Using Pagination Output Mapper","text":"<p>The <code>PaginationOutputMapper</code> class can be used to transform search results into a standardized pagination output format.</p> <pre><code>import { PaginationOutputMapper, PaginationOutput } from '@nodelib/shared/ddd-utils/use-case';\nimport { SearchResult } from '@nodelib/shared/ddd-utils/repository';\n\n// Example usage with search results\nconst searchResults: SearchResult&lt;MyEntityType&gt; = /* your search results */;\nconst paginationOutput: PaginationOutput&lt;MyEntityType&gt; = PaginationOutputMapper.toOutput(\n  searchResults.items,\n  {\n    total: searchResults.total,\n    current_page: searchResults.current_page,\n    last_page: searchResults.last_page,\n    per_page: searchResults.per_page,\n  }\n);\n\nconsole.log(paginationOutput);\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/ddd-utils/use-case/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/shared/errors/","title":"errors","text":"<p>The <code>errors</code> library provides custom error classes for handling various error scenarios in TypeScript applications.</p>"},{"location":"reference/libs/typescript/node/shared/errors/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/node/shared/errors/#notfounderror","title":"NotFoundError","text":"<p>The <code>NotFoundError</code> class is designed to be thrown when an entity is not found, typically in cases where a query for an entity by its ID fails.</p> <p>Example:</p> <pre><code>import { NotFoundError } from '@nodelib/shared/ddd-utils/errors';\nimport { Entity } from '@nodelib/shared/ddd-utils/entity';\n\nclass MyEntity extends Entity {\n  // Your entity-specific properties and methods go here\n}\n\nconst entityId = 123;\ntry {\n  throw new NotFoundError(entityId, MyEntity);\n} catch (error) {\n  if (error instanceof NotFoundError) {\n    console.error(error.message); // Outputs: \"MyEntity Not Found using ID 123\"\n  }\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/errors/#note","title":"Note","text":"<ul> <li>The <code>NotFoundError</code> class expects the entity's ID and its class as parameters during instantiation.</li> <li>The error message is constructed based on the provided entity class and ID.</li> </ul>"},{"location":"reference/libs/typescript/node/shared/errors/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/shared/validators/","title":"Validators","text":"<p>The <code>validators</code> library provides utility classes and functions for validation, including a class for integrating with class-validator and a set of validation rules.</p>"},{"location":"reference/libs/typescript/node/shared/validators/#usage","title":"Usage","text":""},{"location":"reference/libs/typescript/node/shared/validators/#classvalidatorfields","title":"ClassValidatorFields","text":"<p>The <code>ClassValidatorFields</code> class is designed to facilitate integration with class-validator by validating data against specified fields and populating a <code>Notification</code> object with validation errors.</p> <p>Example:</p> <pre><code>import { ClassValidatorFields, Notification } from '@nodelib/shared/validators';\n\nclass MyClassValidator extends ClassValidatorFields {\n  // Your class-specific properties and methods go here\n}\n\nconst notification = new Notification();\nconst myData = { /* your data */ };\nconst fieldsToValidate = ['field1', 'field2'];\n\nconst isValid = new MyClassValidator().validate(notification, myData, fieldsToValidate);\n\nif (!isValid) {\n  console.log(notification.toJSON()); // Outputs validation errors\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/validators/#notification","title":"Notification","text":"<p>The <code>Notification</code> class manages and organizes validation errors. It supports adding, setting, copying errors, and checking for the presence of errors.</p> <p>Example:</p> <pre><code>import { Notification } from '@nodelib/shared/validators';\n\nconst notification = new Notification();\nnotification.addError('Validation error', 'fieldName');\nconsole.log(notification.hasErrors()); // Outputs: true\nconsole.log(notification.toJSON()); // Outputs: Array of errors\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/validators/#validatorrules","title":"ValidatorRules","text":"<p>The <code>ValidatorRules</code> class provides a set of validation rules for common scenarios like required fields, string length, boolean values, etc.</p> <p>Example:</p> <pre><code>import { ValidatorRules, ValidationError } from '@nodelib/shared/validators';\n\nconst myValue = 'example';\nconst propertyName = 'exampleProperty';\n\ntry {\n  ValidatorRules.values(myValue, propertyName).required().string().maxLength(10);\n} catch (error) {\n  if (error instanceof ValidationError) {\n    console.error(error.message); // Outputs: Validation error message\n  }\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/validators/#classvalidatorfields_1","title":"ClassValidatorFields","text":""},{"location":"reference/libs/typescript/node/shared/validators/#validatenotification-notification-data-any-fields-string-boolean","title":"<code>validate(notification: Notification, data: any, fields: string[]): boolean</code>","text":"<p>Validates the provided <code>data</code> against the specified <code>fields</code> and populates the <code>notification</code> with validation errors. Returns <code>true</code> if no errors are found.</p>"},{"location":"reference/libs/typescript/node/shared/validators/#notification_1","title":"Notification","text":""},{"location":"reference/libs/typescript/node/shared/validators/#adderrorerror-string-field-string-void","title":"<code>addError(error: string, field?: string): void</code>","text":"<p>Adds a validation error to the notification, optionally associating it with a specific field.</p>"},{"location":"reference/libs/typescript/node/shared/validators/#seterrorerror-string-string-field-string-void","title":"<code>setError(error: string | string[], field?: string): void</code>","text":"<p>Sets a validation error for the notification, optionally associating it with a specific field.</p>"},{"location":"reference/libs/typescript/node/shared/validators/#haserrors-boolean","title":"<code>hasErrors(): boolean</code>","text":"<p>Returns <code>true</code> if the notification has any validation errors.</p>"},{"location":"reference/libs/typescript/node/shared/validators/#copyerrorsnotification-notification-void","title":"<code>copyErrors(notification: Notification): void</code>","text":"<p>Copies errors from another <code>Notification</code> instance.</p>"},{"location":"reference/libs/typescript/node/shared/validators/#tojson-arraystring-key-string-string","title":"<code>toJSON(): Array&lt;string | { [key: string]: string[] }&gt;</code>","text":"<p>Converts the notification errors to a JSON-friendly format.</p>"},{"location":"reference/libs/typescript/node/shared/validators/#validatorrules_1","title":"ValidatorRules","text":""},{"location":"reference/libs/typescript/node/shared/validators/#required-omitthis-required","title":"<code>required(): Omit&lt;this, 'required'&gt;</code>","text":"<p>Throws a <code>ValidationError</code> if the value is null, undefined, or an empty string.</p>"},{"location":"reference/libs/typescript/node/shared/validators/#string-omitthis-string","title":"<code>string(): Omit&lt;this, 'string'&gt;</code>","text":"<p>Throws a <code>ValidationError</code> if the value is not a string.</p>"},{"location":"reference/libs/typescript/node/shared/validators/#maxlengthmax-number-omitthis-maxlength","title":"<code>maxLength(max: number): Omit&lt;this, 'maxLength'&gt;</code>","text":"<p>Throws a <code>ValidationError</code> if the string length exceeds the specified maximum.</p>"},{"location":"reference/libs/typescript/node/shared/validators/#boolean-omitthis-boolean","title":"<code>boolean(): Omit&lt;this, 'boolean'&gt;</code>","text":"<p>Throws a <code>ValidationError</code> if the value is not a boolean.</p>"},{"location":"reference/libs/typescript/node/shared/validators/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/shared/value-object/","title":"value-object","text":"<p>The <code>value-object</code> library provides a base class for creating value objects in TypeScript. Value objects are immutable objects that represent a descriptive aspect of the system. This library aims to simplify the implementation of value objects by providing a common base class with equality checking.</p>"},{"location":"reference/libs/typescript/node/shared/value-object/#usage","title":"Usage","text":"<p>To create a value object, extend the <code>ValueObject</code> class provided by this library:</p> <pre><code>import isEqual from \"lodash/isEqual\";\nimport { ValueObject } from \"@nodelib/shared/value-object\";\n\nclass MyValueObject extends ValueObject {\n  // Your value object properties and methods go here\n}\n\n// Example usage\nconst obj1 = new MyValueObject(/* pass values for initialization */);\nconst obj2 = new MyValueObject(/* pass values for initialization */);\n\nconsole.log(obj1.equals(obj2)); // Outputs: true or false\n</code></pre> <p>The <code>equals</code> method is provided by the <code>ValueObject</code> class for comparing instances of your value objects. It uses deep equality checking provided by the lodash library.</p>"},{"location":"reference/libs/typescript/node/shared/value-object/#note","title":"Note","text":"<ul> <li>Ensure that your value object class has appropriate properties and methods based on your application requirements.</li> <li>Equality checking is based on the lodash <code>isEqual</code> function, so make sure your class properties are suitable for deep equality comparison.</li> </ul>"},{"location":"reference/libs/typescript/node/shared/value-object/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/libs/typescript/node/shared/value-objects/uuid/","title":"uuid","text":"<p>The <code>uuid</code> library provides a TypeScript class <code>Uuid</code> that encapsulates UUID (Universally Unique Identifier) generation and validation. This class extends the <code>ValueObject</code> class from <code>@nodelib/shared/value-object</code> and ensures that UUIDs used in your application are valid.</p>"},{"location":"reference/libs/typescript/node/shared/value-objects/uuid/#usage","title":"Usage","text":"<p>To use the <code>Uuid</code> class, import it into your TypeScript file and create instances as needed:</p> <pre><code>import { Uuid } from \"@nodelib/shared/value-objects/uuid\";\n\n// Example usage\nconst myUuid = new Uuid();\nconsole.log(myUuid.toString()); // Outputs: a valid UUID string\n</code></pre> <p>The <code>Uuid</code> class provides a default constructor that generates a new UUID using the <code>uuidv4</code> function from the \"uuid\" library. You can also pass an existing UUID string to the constructor to create an instance with a specific UUID.</p>"},{"location":"reference/libs/typescript/node/shared/value-objects/uuid/#validation","title":"Validation","text":"<p>The <code>Uuid</code> class validates the provided or generated UUID to ensure it adheres to the UUID standard. If an invalid UUID is detected, an <code>InvalidUuidError</code> is thrown.</p> <pre><code>import { Uuid, InvalidUuidError } from \"@nodelib/shared/value-objects/uuid\";\n\ntry {\n  const invalidUuid = new Uuid(\"invalid-uuid\");\n} catch (error) {\n  if (error instanceof InvalidUuidError) {\n    console.error(error.message); // Outputs: \"ID must be a valid UUID\"\n  }\n}\n</code></pre>"},{"location":"reference/libs/typescript/node/shared/value-objects/uuid/#contributing","title":"Contributing","text":"<p>Contributions to this library are welcome. If you find issues, have suggestions for improvements, or want to add new features, feel free to create an issue or submit a pull request. Your contributions will help improve the library for all users.</p>"},{"location":"reference/node_modules/%40nrwl/nx-cloud/","title":"Nx Cloud","text":"<p>This work is licensed under a Creative Commons Attribution-NoDerivs 3.0 Unported License.  </p> <p>Distributed caching and analytics for your Nx Workspace.</p> <ul> <li>Learn more about Nx at nx.dev.</li> <li>Learn more about Nx Cloud at nx.app.</li> </ul>"},{"location":"reference/node_modules/nx-cloud/","title":"Nx Cloud","text":"<p>This work is licensed under a Creative Commons Attribution-NoDerivs 3.0 Unported License.  </p> <p>Distributed caching and analytics for your Nx Workspace.</p> <ul> <li>Learn more about Nx at nx.dev.</li> <li>Learn more about Nx Cloud at nx.app.</li> </ul>"}]}